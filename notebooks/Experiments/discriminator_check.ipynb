{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "generous-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from ilan_src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "phantom-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from src.dataloader import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-aquarium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impressed-singer",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADRIVE = '/datadrive_ssd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dramatic-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/xarray/core/indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "ds_train = TiggeMRMSDataset(\n",
    "    tigge_dir=f'{DATADRIVE}/tigge/32km/',\n",
    "    tigge_vars=['total_precipitation'],\n",
    "    mrms_dir=f'{DATADRIVE}/mrms/4km/RadarOnly_QPE_06H/',\n",
    "    rq_fn=f'{DATADRIVE}/mrms/4km/RadarQuality.nc',\n",
    "#     const_fn='/datadrive/tigge/32km/constants.nc',\n",
    "#     const_vars=['orog', 'lsm'],\n",
    "    data_period=('2018-01', '2018-12'),\n",
    "    val_days=5,\n",
    "    split='train',\n",
    "    pure_sr_ratio=None, \n",
    "    tp_log=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/xarray/core/indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "ds_valid = TiggeMRMSDataset(\n",
    "    tigge_dir=f'{DATADRIVE}/tigge/32km/',\n",
    "    tigge_vars=['total_precipitation'],\n",
    "    mrms_dir=f'{DATADRIVE}/mrms/4km/RadarOnly_QPE_06H/',\n",
    "    rq_fn=f'{DATADRIVE}/mrms/4km/RadarQuality.nc',\n",
    "#     const_fn='/datadrive/tigge/32km/constants.nc',\n",
    "#     const_vars=['orog', 'lsm'],\n",
    "    data_period=('2018-01', '2018-12'),\n",
    "    val_days=5,\n",
    "    split='valid',\n",
    "    mins=ds_train.mins,\n",
    "    maxs=ds_train.maxs,\n",
    "    pure_sr_ratio=None,\n",
    "    tp_log= 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "utility-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.WeightedRandomSampler(ds_train.compute_weights(), len(ds_train))\n",
    "sampler_valid = torch.utils.data.WeightedRandomSampler(ds_valid.compute_weights(), len(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "residential-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=32, sampler=sampler_train, num_workers=6)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=32, sampler=sampler_valid, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funny-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20988, 656)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train), len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demographic-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dl_train, open(\"./dataset/trainloader_single_forecast_batch32.pkl\", \"wb\"))\n",
    "pickle.dump(dl_valid, open(\"./dataset/validloader__single_forecast_batch32.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = pickle.load(open(\"./dataset/trainloader_single_forecast_batch32.pkl\", \"rb\"))\n",
    "dl_valid = pickle.load(open(\"./dataset/valdloader_single_forecast_batch32.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-ecuador",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "legendary-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastClassifier(LightningModule):\n",
    "    def __init__(self, discriminator, channels_img, num_classes, img_size, features_d, \n",
    "                      b1 = 0.0, b2 = 0.9, lr = 1e-4, cond_idx = 0, real_idx = 1): # fill in\n",
    "        super().__init__()\n",
    "        self.lr, self.b1, self.b2 = lr, b1, b2\n",
    "        self.disc = discriminator(channels_img, features_d, num_classes, img_size)\n",
    "        self.real_idx = real_idx\n",
    "        self.cond_idx = cond_idx\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.output_sigmoid = nn.Sigmoid()\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.valid_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, condition, high_res):\n",
    "        return self.disc(condition, high_res)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        condition, high_res = batch[self.cond_idx], batch[self.real_idx]\n",
    "        half_batch = condition.shape[0]//2\n",
    "        condition = condition[:half_batch, :, :, :]\n",
    "        targets = torch.cat((torch.ones(condition.shape[0], 1, 1, 1,  device = self.device), torch.zeros(condition.shape[0], 1, 1, 1,  device = self.device)), dim=0)\n",
    "        condition = torch.cat((condition, condition), dim=0)\n",
    "        preds = self.disc(condition, high_res)\n",
    "        loss = self.loss(self.output_sigmoid(preds), targets)\n",
    "        self.log('train_loss', loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc_step', self.train_accuracy(self.output_sigmoid(preds), targets.int()))\n",
    "        return loss\n",
    "        \n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log('train_acc_epoch', self.train_accuracy.compute())\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        condition, high_res = batch[self.cond_idx], batch[self.real_idx]\n",
    "        half_batch = condition.shape[0]//2\n",
    "        condition = condition[:half_batch, :, :, :]\n",
    "        targets = torch.cat((torch.ones(condition.shape[0], 1, 1, 1,  device = self.device), torch.zeros(condition.shape[0], 1, 1, 1,  device = self.device)), dim=0)\n",
    "#         print(targets.dtype)\n",
    "        condition = torch.cat((condition, condition), dim=0)\n",
    "        preds = self.disc(condition, high_res)\n",
    "        loss = self.loss(self.output_sigmoid(preds), targets)\n",
    "        self.log('val_loss', loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc_step', self.valid_accuracy(self.output_sigmoid(preds), targets.int()))\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log('val_acc_epoch', self.valid_accuracy.compute())\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        disc_opt = optim.Adam(self.disc.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "#         disc_opt = optim.SGD(self.disc.parameters(), lr=self.lr, momentum=0.9)\n",
    "        return disc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wrapped-cyprus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type            | Params\n",
      "---------------------------------------------------\n",
      "0 | disc           | DSDiscriminator | 4.0 M \n",
      "1 | loss           | BCELoss         | 0     \n",
      "2 | output_sigmoid | Sigmoid         | 0     \n",
      "3 | train_accuracy | Accuracy        | 0     \n",
      "4 | valid_accuracy | Accuracy        | 0     \n",
      "---------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.903    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▍ | 660/780 [06:08<01:07,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▌ | 665/780 [06:09<01:03,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 669/780 [06:10<01:01,  1.80it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 670/780 [06:11<01:00,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▋ | 673/780 [06:11<00:59,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  86%|████████▋ | 674/780 [06:11<00:58,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 676/780 [06:12<00:57,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 678/780 [06:12<00:56,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  87%|████████▋ | 682/780 [06:13<00:53,  1.82it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 683/780 [06:13<00:53,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 687/780 [06:14<00:50,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 689/780 [06:15<00:49,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  88%|████████▊ | 690/780 [06:15<00:48,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 695/780 [06:16<00:46,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  90%|█████████ | 705/780 [06:18<00:40,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 708/780 [06:19<00:38,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 709/780 [06:19<00:38,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 714/780 [06:20<00:35,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 715/780 [06:20<00:34,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 719/780 [06:21<00:32,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  92%|█████████▏| 721/780 [06:22<00:31,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 723/780 [06:22<00:30,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 727/780 [06:23<00:27,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 733/780 [06:24<00:24,  1.90it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 734/780 [06:25<00:24,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 735/780 [06:25<00:23,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  94%|█████████▍| 737/780 [06:25<00:22,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▌| 741/780 [06:26<00:20,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 745/780 [06:27<00:18,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 746/780 [06:27<00:17,  1.92it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 747/780 [06:27<00:17,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 748/780 [06:28<00:16,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▋| 751/780 [06:28<00:15,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 754/780 [06:29<00:13,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 755/780 [06:29<00:12,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 759/780 [06:30<00:10,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  97%|█████████▋| 760/780 [06:30<00:10,  1.94it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 761/780 [06:31<00:09,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 763/780 [06:31<00:08,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 764/780 [06:31<00:08,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 765/780 [06:31<00:07,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  98%|█████████▊| 768/780 [06:32<00:06,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▊| 769/780 [06:32<00:05,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 773/780 [06:33<00:03,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 774/780 [06:33<00:03,  1.96it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 775/780 [06:34<00:02,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0: 100%|█████████▉| 777/780 [06:34<00:01,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0: 100%|█████████▉| 778/780 [06:34<00:01,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.755, train_loss_step=0.438]\n",
      "Epoch 0: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.476, v_num=87, val_loss_epoch=0.406, train_loss_step=0.675, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 3:  12%|█▏        | 90/780 [36:08<4:37:05, 24.09s/it, loss=0.385, v_num=81, val_loss_epoch=0.401, train_loss_step=0.402, train_loss_epoch=0.399, val_loss_step=0.202]\n",
      "Epoch 1:   7%|▋         | 58/780 [28:29<5:54:39, 29.47s/it, loss=0.482, v_num=82, val_loss_epoch=0.506, train_loss_step=0.914, train_loss_epoch=0.685, val_loss_step=0.470]\n",
      "Epoch 0:  11%|█▏        | 89/780 [27:36<3:34:25, 18.62s/it, loss=0.739, v_num=83, val_loss_epoch=0.724, train_loss_step=0.731]\n",
      "Epoch 1:  15%|█▌        | 117/780 [19:09<1:48:32,  9.82s/it, loss=0.694, v_num=85, val_loss_epoch=0.694, train_loss_step=0.691, train_loss_epoch=0.784, val_loss_step=0.694]\n",
      "Epoch 0:  51%|█████     | 396/780 [17:57<17:24,  2.72s/it, loss=0.695, v_num=86, val_loss_epoch=0.762, train_loss_step=0.692]\n",
      "Epoch 1:  84%|████████▍ | 657/780 [06:08<01:08,  1.78it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  84%|████████▍ | 659/780 [06:09<01:07,  1.78it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▍ | 660/780 [06:09<01:07,  1.78it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▍ | 661/780 [06:10<01:06,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▍ | 662/780 [06:10<01:06,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▌ | 663/780 [06:10<01:05,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▌ | 665/780 [06:10<01:04,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 667/780 [06:11<01:02,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 671/780 [06:12<01:00,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▋ | 673/780 [06:12<00:59,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 675/780 [06:13<00:58,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 677/780 [06:13<00:56,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 678/780 [06:13<00:56,  1.81it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 679/780 [06:14<00:55,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 681/780 [06:14<00:54,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 683/780 [06:14<00:53,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 685/780 [06:15<00:52,  1.82it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 689/780 [06:16<00:49,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▊ | 691/780 [06:16<00:48,  1.83it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 693/780 [06:17<00:47,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 695/780 [06:17<00:46,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 696/780 [06:17<00:45,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 697/780 [06:18<00:45,  1.84it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  89%|████████▉ | 698/780 [06:18<00:44,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|████████▉ | 699/780 [06:18<00:43,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|█████████ | 703/780 [06:19<00:41,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|█████████ | 704/780 [06:19<00:40,  1.85it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  90%|█████████ | 705/780 [06:19<00:40,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 706/780 [06:20<00:39,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 707/780 [06:20<00:39,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 709/780 [06:20<00:38,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 710/780 [06:20<00:37,  1.86it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████ | 711/780 [06:21<00:36,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  91%|█████████▏| 713/780 [06:21<00:35,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 715/780 [06:22<00:34,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 717/780 [06:22<00:33,  1.87it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 718/780 [06:22<00:33,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 720/780 [06:23<00:31,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  92%|█████████▏| 721/780 [06:23<00:31,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 723/780 [06:23<00:30,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 725/780 [06:24<00:29,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 727/780 [06:24<00:28,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  93%|█████████▎| 729/780 [06:25<00:26,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▎| 730/780 [06:25<00:26,  1.89it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▎| 731/780 [06:25<00:25,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 733/780 [06:26<00:24,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 735/780 [06:26<00:23,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 736/780 [06:26<00:23,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  94%|█████████▍| 737/780 [06:27<00:22,  1.90it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▍| 738/780 [06:27<00:22,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▍| 739/780 [06:27<00:21,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▌| 741/780 [06:27<00:20,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▌| 743/780 [06:28<00:19,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  95%|█████████▌| 744/780 [06:28<00:18,  1.91it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 745/780 [06:28<00:18,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 746/780 [06:29<00:17,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 747/780 [06:29<00:17,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 749/780 [06:29<00:16,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▌| 750/780 [06:29<00:15,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▋| 751/780 [06:30<00:15,  1.92it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  96%|█████████▋| 752/780 [06:30<00:14,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 753/780 [06:30<00:14,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 755/780 [06:31<00:12,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 757/780 [06:31<00:11,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 758/780 [06:31<00:11,  1.93it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 759/780 [06:31<00:10,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  97%|█████████▋| 760/780 [06:32<00:10,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 761/780 [06:32<00:09,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 763/780 [06:32<00:08,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 765/780 [06:33<00:07,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 767/780 [06:33<00:06,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▊| 769/780 [06:34<00:05,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 771/780 [06:34<00:04,  1.95it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 773/780 [06:35<00:03,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 775/780 [06:35<00:02,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1: 100%|█████████▉| 777/780 [06:35<00:01,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1: 100%|█████████▉| 779/780 [06:36<00:00,  1.97it/s, loss=0.379, v_num=87, val_loss_epoch=0.406, train_loss_step=0.437, train_loss_epoch=0.568, val_loss_step=0.343]\n",
      "Epoch 1: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.379, v_num=87, val_loss_epoch=0.394, train_loss_step=0.390, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 658/780 [06:06<01:07,  1.79it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▌ | 663/780 [06:07<01:04,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▌ | 665/780 [06:08<01:03,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 669/780 [06:09<01:01,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 671/780 [06:09<01:00,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▋ | 673/780 [06:10<00:58,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 681/780 [06:11<00:54,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 683/780 [06:12<00:52,  1.83it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 687/780 [06:13<00:50,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 689/780 [06:13<00:49,  1.84it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▊ | 691/780 [06:14<00:48,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 693/780 [06:14<00:47,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 695/780 [06:14<00:45,  1.85it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 696/780 [06:15<00:45,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 697/780 [06:15<00:44,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|████████▉ | 700/780 [06:16<00:42,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|████████▉ | 701/780 [06:16<00:42,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  90%|█████████ | 705/780 [06:17<00:40,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 709/780 [06:18<00:37,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 715/780 [06:19<00:34,  1.88it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  92%|█████████▏| 721/780 [06:20<00:31,  1.89it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 723/780 [06:21<00:30,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 727/780 [06:22<00:27,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  94%|█████████▍| 737/780 [06:24<00:22,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▌| 741/780 [06:25<00:20,  1.92it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 745/780 [06:26<00:18,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 749/780 [06:26<00:16,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 755/780 [06:28<00:12,  1.94it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 759/780 [06:29<00:10,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 761/780 [06:29<00:09,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 762/780 [06:29<00:09,  1.95it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 763/780 [06:30<00:08,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▊| 769/780 [06:31<00:05,  1.96it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 773/780 [06:32<00:03,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 775/780 [06:32<00:02,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2:  99%|█████████▉| 776/780 [06:32<00:02,  1.97it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2: 100%|█████████▉| 777/780 [06:33<00:01,  1.98it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.41, v_num=87, val_loss_epoch=0.394, train_loss_step=0.400, train_loss_epoch=0.422, val_loss_step=0.590]\n",
      "Epoch 2: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.41, v_num=87, val_loss_epoch=0.370, train_loss_step=0.438, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 658/780 [06:08<01:08,  1.78it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▋ | 673/780 [06:12<00:59,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 683/780 [06:14<00:53,  1.82it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 689/780 [06:15<00:49,  1.83it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  88%|████████▊ | 690/780 [06:15<00:49,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▊ | 691/780 [06:16<00:48,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 695/780 [06:16<00:46,  1.84it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 696/780 [06:17<00:45,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|█████████ | 702/780 [06:18<00:42,  1.85it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  90%|█████████ | 705/780 [06:19<00:40,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 708/780 [06:19<00:38,  1.86it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 709/780 [06:20<00:38,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 715/780 [06:21<00:34,  1.87it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 718/780 [06:22<00:32,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  92%|█████████▏| 721/780 [06:22<00:31,  1.88it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 723/780 [06:23<00:30,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 727/780 [06:24<00:27,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 735/780 [06:25<00:23,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 736/780 [06:26<00:23,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▌| 741/780 [06:27<00:20,  1.91it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 745/780 [06:28<00:18,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 748/780 [06:28<00:16,  1.92it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▌| 750/780 [06:29<00:15,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 755/780 [06:30<00:12,  1.93it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 759/780 [06:31<00:10,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 761/780 [06:31<00:09,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 762/780 [06:31<00:09,  1.94it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 763/780 [06:32<00:08,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 765/780 [06:32<00:07,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▊| 769/780 [06:33<00:05,  1.95it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 773/780 [06:34<00:03,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 775/780 [06:34<00:02,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3:  99%|█████████▉| 776/780 [06:34<00:02,  1.96it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3: 100%|█████████▉| 777/780 [06:35<00:01,  1.97it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.397, v_num=87, val_loss_epoch=0.370, train_loss_step=0.413, train_loss_epoch=0.396, val_loss_step=0.389]\n",
      "Epoch 3: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.397, v_num=87, val_loss_epoch=0.357, train_loss_step=0.446, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▍ | 661/780 [06:06<01:06,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▌ | 663/780 [06:07<01:04,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 669/780 [06:08<01:01,  1.81it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 671/780 [06:09<00:59,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 675/780 [06:09<00:57,  1.82it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 679/780 [06:10<00:55,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 681/780 [06:11<00:53,  1.83it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 687/780 [06:12<00:50,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 689/780 [06:13<00:49,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 693/780 [06:13<00:46,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 697/780 [06:14<00:44,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|████████▉ | 701/780 [06:15<00:42,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 715/780 [06:18<00:34,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 719/780 [06:19<00:32,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  92%|█████████▏| 721/780 [06:20<00:31,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 723/780 [06:20<00:30,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 727/780 [06:21<00:27,  1.90it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 749/780 [06:26<00:15,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▋| 751/780 [06:26<00:14,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 761/780 [06:29<00:09,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▊| 769/780 [06:31<00:05,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 773/780 [06:31<00:03,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 775/780 [06:32<00:02,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.357, train_loss_step=0.224, train_loss_epoch=0.383, val_loss_step=0.293]\n",
      "Epoch 4: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.334, v_num=87, val_loss_epoch=0.372, train_loss_step=0.252, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▍ | 660/780 [06:08<01:07,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 669/780 [06:10<01:01,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▋ | 673/780 [06:11<00:59,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  87%|████████▋ | 682/780 [06:13<00:53,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 683/780 [06:14<00:53,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 687/780 [06:14<00:50,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 689/780 [06:15<00:49,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  88%|████████▊ | 690/780 [06:15<00:48,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 695/780 [06:16<00:46,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  90%|█████████ | 705/780 [06:18<00:40,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 708/780 [06:19<00:38,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 709/780 [06:19<00:38,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 714/780 [06:20<00:35,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 715/780 [06:21<00:34,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  92%|█████████▏| 721/780 [06:22<00:31,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 723/780 [06:22<00:30,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 727/780 [06:23<00:27,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 728/780 [06:24<00:27,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 735/780 [06:25<00:23,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▌| 741/780 [06:26<00:20,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 745/780 [06:27<00:18,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 746/780 [06:27<00:17,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 748/780 [06:28<00:16,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 754/780 [06:29<00:13,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 755/780 [06:29<00:12,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 759/780 [06:30<00:10,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 761/780 [06:31<00:09,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 763/780 [06:31<00:08,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 765/780 [06:32<00:07,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  98%|█████████▊| 768/780 [06:32<00:06,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▊| 769/780 [06:33<00:05,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 773/780 [06:34<00:03,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 775/780 [06:34<00:02,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5: 100%|█████████▉| 777/780 [06:34<00:01,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.372, train_loss_step=0.314, train_loss_epoch=0.366, val_loss_step=0.519]\n",
      "Epoch 5: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.364, train_loss_step=0.365, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  84%|████████▍ | 657/780 [06:04<01:08,  1.80it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  84%|████████▍ | 659/780 [06:05<01:07,  1.80it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▍ | 661/780 [06:06<01:05,  1.80it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▌ | 663/780 [06:06<01:04,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 667/780 [06:07<01:02,  1.81it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 668/780 [06:08<01:01,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 669/780 [06:08<01:01,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 671/780 [06:08<00:59,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 675/780 [06:09<00:57,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 679/780 [06:10<00:55,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 681/780 [06:10<00:53,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 685/780 [06:11<00:51,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 687/780 [06:12<00:50,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 689/780 [06:12<00:49,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 693/780 [06:13<00:46,  1.85it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 697/780 [06:14<00:44,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|████████▉ | 699/780 [06:14<00:43,  1.86it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|████████▉ | 701/780 [06:15<00:42,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|█████████ | 703/780 [06:15<00:41,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 707/780 [06:16<00:38,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████ | 711/780 [06:17<00:36,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  91%|█████████▏| 713/780 [06:18<00:35,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 715/780 [06:18<00:34,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 717/780 [06:18<00:33,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 719/780 [06:19<00:32,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  92%|█████████▏| 721/780 [06:19<00:31,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 723/780 [06:20<00:29,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 725/780 [06:20<00:28,  1.90it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 727/780 [06:21<00:27,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  93%|█████████▎| 729/780 [06:21<00:26,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 733/780 [06:22<00:24,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 735/780 [06:22<00:23,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▍| 739/780 [06:23<00:21,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▌| 743/780 [06:24<00:19,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 747/780 [06:25<00:17,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 749/780 [06:26<00:15,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▋| 751/780 [06:26<00:14,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 753/780 [06:26<00:13,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 757/780 [06:27<00:11,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 759/780 [06:28<00:10,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 761/780 [06:28<00:09,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 765/780 [06:29<00:07,  1.96it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 767/780 [06:29<00:06,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▊| 769/780 [06:30<00:05,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 771/780 [06:30<00:04,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 773/780 [06:31<00:03,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 775/780 [06:31<00:02,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6: 100%|█████████▉| 779/780 [06:32<00:00,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.319, v_num=87, val_loss_epoch=0.364, train_loss_step=0.287, train_loss_epoch=0.354, val_loss_step=0.515]\n",
      "Epoch 6: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.319, v_num=87, val_loss_epoch=0.334, train_loss_step=0.204, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  84%|████████▍ | 657/780 [06:08<01:08,  1.78it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  84%|████████▍ | 659/780 [06:09<01:07,  1.78it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▍ | 662/780 [06:10<01:05,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▌ | 663/780 [06:10<01:05,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▌ | 665/780 [06:10<01:04,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 667/780 [06:11<01:02,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 670/780 [06:11<01:01,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 671/780 [06:12<01:00,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▋ | 673/780 [06:12<00:59,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 675/780 [06:12<00:58,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 677/780 [06:13<00:56,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 678/780 [06:13<00:56,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 681/780 [06:14<00:54,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 683/780 [06:14<00:53,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 684/780 [06:14<00:52,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 685/780 [06:15<00:52,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 689/780 [06:16<00:49,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▊ | 691/780 [06:16<00:48,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 695/780 [06:17<00:46,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 696/780 [06:17<00:45,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 697/780 [06:17<00:44,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  89%|████████▉ | 698/780 [06:18<00:44,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|████████▉ | 699/780 [06:18<00:43,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|█████████ | 702/780 [06:18<00:42,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|█████████ | 703/780 [06:19<00:41,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|█████████ | 704/780 [06:19<00:40,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  90%|█████████ | 705/780 [06:19<00:40,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 707/780 [06:20<00:39,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 709/780 [06:20<00:38,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 710/780 [06:20<00:37,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  91%|█████████▏| 713/780 [06:21<00:35,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 715/780 [06:21<00:34,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 717/780 [06:22<00:33,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 718/780 [06:22<00:33,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  92%|█████████▏| 721/780 [06:23<00:31,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 723/780 [06:23<00:30,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 725/780 [06:24<00:29,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 727/780 [06:24<00:28,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  93%|█████████▎| 729/780 [06:24<00:26,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▎| 730/780 [06:25<00:26,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▎| 731/780 [06:25<00:25,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 735/780 [06:26<00:23,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 736/780 [06:26<00:23,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▍| 738/780 [06:26<00:22,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▍| 739/780 [06:27<00:21,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▌| 741/780 [06:27<00:20,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▌| 742/780 [06:27<00:19,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▌| 743/780 [06:28<00:19,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  95%|█████████▌| 744/780 [06:28<00:18,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 745/780 [06:28<00:18,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 749/780 [06:29<00:16,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▌| 750/780 [06:29<00:15,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  96%|█████████▋| 752/780 [06:30<00:14,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 753/780 [06:30<00:13,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 755/780 [06:30<00:12,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 756/780 [06:30<00:12,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 757/780 [06:31<00:11,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 758/780 [06:31<00:11,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 759/780 [06:31<00:10,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 761/780 [06:32<00:09,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 763/780 [06:32<00:08,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 765/780 [06:33<00:07,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 767/780 [06:33<00:06,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▊| 769/780 [06:33<00:05,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 771/780 [06:34<00:04,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 773/780 [06:34<00:03,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 775/780 [06:35<00:02,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7: 100%|█████████▉| 777/780 [06:35<00:01,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7: 100%|█████████▉| 779/780 [06:36<00:00,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.334, train_loss_step=0.159, train_loss_epoch=0.344, val_loss_step=0.373]\n",
      "Epoch 7: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.337, train_loss_step=0.214, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  84%|████████▍ | 657/780 [06:06<01:08,  1.79it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▍ | 660/780 [06:08<01:06,  1.79it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▍ | 661/780 [06:08<01:06,  1.79it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▌ | 663/780 [06:08<01:05,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▌ | 665/780 [06:09<01:03,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 667/780 [06:09<01:02,  1.80it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 668/780 [06:09<01:02,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 669/780 [06:10<01:01,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 671/780 [06:10<01:00,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▋ | 673/780 [06:11<00:58,  1.81it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  86%|████████▋ | 674/780 [06:11<00:58,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 675/780 [06:11<00:57,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 677/780 [06:11<00:56,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 678/780 [06:12<00:55,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 679/780 [06:12<00:55,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 680/780 [06:12<00:54,  1.82it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 681/780 [06:12<00:54,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  87%|████████▋ | 682/780 [06:13<00:53,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 683/780 [06:13<00:53,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 685/780 [06:13<00:51,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 687/780 [06:14<00:50,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 689/780 [06:14<00:49,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 693/780 [06:15<00:47,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 695/780 [06:16<00:45,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 697/780 [06:16<00:44,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  89%|████████▉ | 698/780 [06:16<00:44,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|████████▉ | 699/780 [06:16<00:43,  1.85it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|████████▉ | 700/780 [06:17<00:43,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|████████▉ | 701/780 [06:17<00:42,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|█████████ | 703/780 [06:17<00:41,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  90%|█████████ | 705/780 [06:18<00:40,  1.86it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 706/780 [06:18<00:39,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 707/780 [06:18<00:39,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 709/780 [06:19<00:37,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████ | 711/780 [06:19<00:36,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████▏| 712/780 [06:19<00:36,  1.87it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  91%|█████████▏| 713/780 [06:19<00:35,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 714/780 [06:20<00:35,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 715/780 [06:20<00:34,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 716/780 [06:20<00:34,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 717/780 [06:20<00:33,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 719/780 [06:21<00:32,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  92%|█████████▏| 721/780 [06:21<00:31,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 723/780 [06:22<00:30,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 725/780 [06:22<00:29,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 727/780 [06:23<00:27,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  93%|█████████▎| 729/780 [06:23<00:26,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▎| 731/780 [06:23<00:25,  1.90it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 732/780 [06:24<00:25,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 733/780 [06:24<00:24,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 735/780 [06:24<00:23,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 736/780 [06:24<00:23,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  94%|█████████▍| 737/780 [06:25<00:22,  1.91it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▍| 738/780 [06:25<00:21,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▍| 739/780 [06:25<00:21,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▌| 741/780 [06:25<00:20,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▌| 743/780 [06:26<00:19,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  95%|█████████▌| 744/780 [06:26<00:18,  1.92it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 745/780 [06:26<00:18,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 746/780 [06:27<00:17,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 747/780 [06:27<00:17,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 749/780 [06:27<00:16,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▋| 751/780 [06:28<00:14,  1.93it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 753/780 [06:28<00:13,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 755/780 [06:29<00:12,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 757/780 [06:29<00:11,  1.94it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 759/780 [06:29<00:10,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  97%|█████████▋| 760/780 [06:30<00:10,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 761/780 [06:30<00:09,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 763/780 [06:30<00:08,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 764/780 [06:30<00:08,  1.95it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 765/780 [06:31<00:07,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 767/780 [06:31<00:06,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▊| 769/780 [06:32<00:05,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 771/780 [06:32<00:04,  1.96it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 773/780 [06:33<00:03,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 775/780 [06:33<00:02,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8: 100%|█████████▉| 777/780 [06:33<00:01,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8: 100%|█████████▉| 778/780 [06:34<00:01,  1.97it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8: 100%|█████████▉| 779/780 [06:34<00:00,  1.98it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.362, v_num=87, val_loss_epoch=0.337, train_loss_step=0.370, train_loss_epoch=0.335, val_loss_step=0.390]\n",
      "Epoch 8: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.362, v_num=87, val_loss_epoch=0.354, train_loss_step=0.337, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▌ | 663/780 [06:07<01:04,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▌ | 664/780 [06:07<01:04,  1.80it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▌ | 665/780 [06:08<01:03,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 669/780 [06:09<01:01,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 671/780 [06:09<01:00,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 681/780 [06:11<00:54,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 683/780 [06:12<00:52,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 687/780 [06:13<00:50,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 689/780 [06:13<00:49,  1.84it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 693/780 [06:14<00:46,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 695/780 [06:14<00:45,  1.85it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 697/780 [06:15<00:44,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|████████▉ | 701/780 [06:16<00:42,  1.86it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 715/780 [06:19<00:34,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  92%|█████████▏| 721/780 [06:20<00:31,  1.89it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 723/780 [06:21<00:30,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 727/780 [06:21<00:27,  1.90it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  94%|█████████▍| 737/780 [06:24<00:22,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▌| 741/780 [06:24<00:20,  1.92it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 749/780 [06:26<00:16,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 755/780 [06:28<00:12,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 761/780 [06:29<00:09,  1.95it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▊| 769/780 [06:31<00:05,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 773/780 [06:32<00:03,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 775/780 [06:32<00:02,  1.97it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.354, train_loss_step=0.396, train_loss_epoch=0.334, val_loss_step=0.442]\n",
      "Epoch 9: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.326, v_num=87, val_loss_epoch=0.326, train_loss_step=0.404, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▍ | 661/780 [06:06<01:06,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▌ | 663/780 [06:07<01:04,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 669/780 [06:08<01:01,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 671/780 [06:08<00:59,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 675/780 [06:09<00:57,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 679/780 [06:10<00:55,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 681/780 [06:11<00:53,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 685/780 [06:11<00:51,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 687/780 [06:12<00:50,  1.84it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 689/780 [06:12<00:49,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 693/780 [06:13<00:46,  1.85it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 697/780 [06:14<00:44,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|████████▉ | 701/780 [06:15<00:42,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 707/780 [06:16<00:38,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████ | 711/780 [06:17<00:36,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 715/780 [06:18<00:34,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 719/780 [06:19<00:32,  1.89it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  92%|█████████▏| 721/780 [06:20<00:31,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 723/780 [06:20<00:29,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 725/780 [06:20<00:28,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 727/780 [06:21<00:27,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  93%|█████████▎| 729/780 [06:21<00:26,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 733/780 [06:22<00:24,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▌| 743/780 [06:24<00:19,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 747/780 [06:25<00:17,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 749/780 [06:26<00:15,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▋| 751/780 [06:26<00:14,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 753/780 [06:27<00:13,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 761/780 [06:28<00:09,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 765/780 [06:29<00:07,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 767/780 [06:30<00:06,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▊| 769/780 [06:30<00:05,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 773/780 [06:31<00:03,  1.97it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 775/780 [06:32<00:02,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10: 100%|█████████▉| 779/780 [06:32<00:00,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.326, train_loss_step=0.209, train_loss_epoch=0.328, val_loss_step=0.384]\n",
      "Epoch 10: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.293, v_num=87, val_loss_epoch=0.336, train_loss_step=0.305, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  84%|████████▍ | 657/780 [06:04<01:08,  1.80it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  84%|████████▍ | 659/780 [06:05<01:07,  1.80it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▍ | 661/780 [06:05<01:05,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▌ | 663/780 [06:06<01:04,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▌ | 665/780 [06:06<01:03,  1.81it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 667/780 [06:06<01:02,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 669/780 [06:07<01:00,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 671/780 [06:07<00:59,  1.82it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▋ | 673/780 [06:08<00:58,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 675/780 [06:08<00:57,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 677/780 [06:09<00:56,  1.83it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 679/780 [06:09<00:54,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 681/780 [06:10<00:53,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 683/780 [06:10<00:52,  1.84it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 685/780 [06:10<00:51,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 687/780 [06:11<00:50,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 689/780 [06:11<00:49,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▊ | 691/780 [06:12<00:47,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 693/780 [06:12<00:46,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 695/780 [06:13<00:45,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 697/780 [06:13<00:44,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|████████▉ | 699/780 [06:14<00:43,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|████████▉ | 701/780 [06:14<00:42,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|█████████ | 703/780 [06:14<00:41,  1.87it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  90%|█████████ | 705/780 [06:15<00:39,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 707/780 [06:15<00:38,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 709/780 [06:16<00:37,  1.88it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████ | 711/780 [06:16<00:36,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  91%|█████████▏| 713/780 [06:17<00:35,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 715/780 [06:17<00:34,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 717/780 [06:18<00:33,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 719/780 [06:18<00:32,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  92%|█████████▏| 721/780 [06:18<00:31,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 723/780 [06:19<00:29,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 725/780 [06:19<00:28,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 727/780 [06:20<00:27,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  93%|█████████▎| 729/780 [06:20<00:26,  1.91it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▎| 731/780 [06:21<00:25,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 733/780 [06:21<00:24,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 735/780 [06:22<00:23,  1.92it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  94%|█████████▍| 737/780 [06:22<00:22,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▍| 739/780 [06:22<00:21,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▌| 741/780 [06:23<00:20,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▌| 743/780 [06:23<00:19,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 745/780 [06:24<00:18,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 747/780 [06:24<00:16,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 749/780 [06:25<00:15,  1.94it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▋| 751/780 [06:25<00:14,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 753/780 [06:26<00:13,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 755/780 [06:26<00:12,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 757/780 [06:26<00:11,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 759/780 [06:27<00:10,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 761/780 [06:27<00:09,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 763/780 [06:28<00:08,  1.96it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 765/780 [06:28<00:07,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 767/780 [06:29<00:06,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▊| 769/780 [06:29<00:05,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▊| 770/780 [06:29<00:05,  1.97it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 771/780 [06:30<00:04,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 773/780 [06:30<00:03,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 775/780 [06:31<00:02,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11: 100%|█████████▉| 777/780 [06:31<00:01,  1.99it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11: 100%|█████████▉| 779/780 [06:31<00:00,  1.99it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.345, v_num=87, val_loss_epoch=0.336, train_loss_step=0.197, train_loss_epoch=0.321, val_loss_step=0.390]\n",
      "Epoch 11: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.345, v_num=87, val_loss_epoch=0.369, train_loss_step=0.569, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  84%|████████▍ | 657/780 [06:08<01:09,  1.78it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  84%|████████▍ | 659/780 [06:09<01:07,  1.78it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▍ | 661/780 [06:10<01:06,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▍ | 662/780 [06:10<01:06,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▌ | 663/780 [06:10<01:05,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▌ | 665/780 [06:11<01:04,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 667/780 [06:11<01:02,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 671/780 [06:12<01:00,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▋ | 673/780 [06:12<00:59,  1.80it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  86%|████████▋ | 674/780 [06:13<00:58,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 675/780 [06:13<00:58,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 677/780 [06:13<00:56,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 679/780 [06:14<00:55,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 681/780 [06:14<00:54,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 683/780 [06:15<00:53,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 685/780 [06:15<00:52,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 687/780 [06:16<00:50,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 689/780 [06:16<00:49,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▊ | 691/780 [06:16<00:48,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▊ | 692/780 [06:17<00:47,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 693/780 [06:17<00:47,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 695/780 [06:17<00:46,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 697/780 [06:18<00:45,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  89%|████████▉ | 698/780 [06:18<00:44,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|████████▉ | 699/780 [06:18<00:43,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|████████▉ | 701/780 [06:19<00:42,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|█████████ | 703/780 [06:19<00:41,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|█████████ | 704/780 [06:19<00:41,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  90%|█████████ | 705/780 [06:20<00:40,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 706/780 [06:20<00:39,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 707/780 [06:20<00:39,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 709/780 [06:20<00:38,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████ | 711/780 [06:21<00:37,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  91%|█████████▏| 713/780 [06:21<00:35,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 715/780 [06:22<00:34,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 717/780 [06:22<00:33,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 719/780 [06:23<00:32,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 720/780 [06:23<00:31,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  92%|█████████▏| 721/780 [06:23<00:31,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 723/780 [06:24<00:30,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 725/780 [06:24<00:29,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 727/780 [06:25<00:28,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  93%|█████████▎| 729/780 [06:25<00:26,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▎| 730/780 [06:25<00:26,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▎| 731/780 [06:25<00:25,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 732/780 [06:26<00:25,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 733/780 [06:26<00:24,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 735/780 [06:26<00:23,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  94%|█████████▍| 737/780 [06:27<00:22,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▍| 738/780 [06:27<00:22,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▍| 739/780 [06:27<00:21,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▌| 741/780 [06:28<00:20,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▌| 743/780 [06:28<00:19,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  95%|█████████▌| 744/780 [06:28<00:18,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 745/780 [06:29<00:18,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 746/780 [06:29<00:17,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 747/780 [06:29<00:17,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 749/780 [06:29<00:16,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▋| 751/780 [06:30<00:15,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  96%|█████████▋| 752/780 [06:30<00:14,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 753/780 [06:30<00:14,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 755/780 [06:31<00:12,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 757/780 [06:31<00:11,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 758/780 [06:31<00:11,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 759/780 [06:32<00:10,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  97%|█████████▋| 760/780 [06:32<00:10,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 761/780 [06:32<00:09,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 763/780 [06:33<00:08,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 765/780 [06:33<00:07,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 767/780 [06:33<00:06,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▊| 769/780 [06:34<00:05,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 771/780 [06:34<00:04,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 773/780 [06:35<00:03,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 775/780 [06:35<00:02,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12: 100%|█████████▉| 777/780 [06:36<00:01,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12: 100%|█████████▉| 779/780 [06:36<00:00,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.285, v_num=87, val_loss_epoch=0.369, train_loss_step=0.128, train_loss_epoch=0.313, val_loss_step=0.389]\n",
      "Epoch 12: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.341, train_loss_step=0.252, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▌ | 663/780 [06:07<01:04,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▌ | 664/780 [06:07<01:04,  1.80it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▌ | 665/780 [06:08<01:03,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 669/780 [06:08<01:01,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 671/780 [06:09<01:00,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 681/780 [06:11<00:54,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 683/780 [06:12<00:52,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 687/780 [06:13<00:50,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 689/780 [06:13<00:49,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 693/780 [06:14<00:46,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 695/780 [06:14<00:45,  1.85it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 697/780 [06:15<00:44,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|████████▉ | 701/780 [06:16<00:42,  1.86it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 715/780 [06:19<00:34,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  92%|█████████▏| 721/780 [06:20<00:31,  1.89it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 723/780 [06:21<00:30,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 727/780 [06:21<00:27,  1.90it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  94%|█████████▍| 737/780 [06:24<00:22,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▌| 741/780 [06:24<00:20,  1.92it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 749/780 [06:26<00:16,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 755/780 [06:28<00:12,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 761/780 [06:29<00:09,  1.95it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▊| 769/780 [06:31<00:05,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 773/780 [06:32<00:03,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 775/780 [06:32<00:02,  1.97it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.341, train_loss_step=0.368, train_loss_epoch=0.313, val_loss_step=0.241]\n",
      "Epoch 13: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.311, v_num=87, val_loss_epoch=0.362, train_loss_step=0.550, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  84%|████████▍ | 657/780 [06:08<01:09,  1.78it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  84%|████████▍ | 659/780 [06:10<01:07,  1.78it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▍ | 661/780 [06:10<01:06,  1.78it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▍ | 662/780 [06:10<01:06,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▌ | 663/780 [06:10<01:05,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▌ | 664/780 [06:11<01:04,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▌ | 665/780 [06:11<01:04,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 667/780 [06:11<01:02,  1.79it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 668/780 [06:12<01:02,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 669/780 [06:12<01:01,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 671/780 [06:12<01:00,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▋ | 673/780 [06:13<00:59,  1.80it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  86%|████████▋ | 674/780 [06:13<00:58,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 675/780 [06:13<00:58,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 677/780 [06:14<00:56,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 679/780 [06:14<00:55,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 680/780 [06:14<00:55,  1.81it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 681/780 [06:14<00:54,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  87%|████████▋ | 682/780 [06:15<00:53,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 683/780 [06:15<00:53,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 685/780 [06:15<00:52,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 686/780 [06:15<00:51,  1.82it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 687/780 [06:16<00:50,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 689/780 [06:16<00:49,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▊ | 691/780 [06:17<00:48,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▊ | 692/780 [06:17<00:47,  1.83it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 693/780 [06:17<00:47,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 695/780 [06:17<00:46,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 697/780 [06:18<00:45,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  89%|████████▉ | 698/780 [06:18<00:44,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|████████▉ | 699/780 [06:18<00:43,  1.84it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|████████▉ | 700/780 [06:19<00:43,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|████████▉ | 701/780 [06:19<00:42,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|█████████ | 703/780 [06:19<00:41,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|█████████ | 704/780 [06:19<00:41,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  90%|█████████ | 705/780 [06:20<00:40,  1.85it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 706/780 [06:20<00:39,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 707/780 [06:20<00:39,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 709/780 [06:21<00:38,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████ | 711/780 [06:21<00:37,  1.86it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  91%|█████████▏| 713/780 [06:21<00:35,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 715/780 [06:22<00:34,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 717/780 [06:22<00:33,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 719/780 [06:23<00:32,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 720/780 [06:23<00:31,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  92%|█████████▏| 721/780 [06:23<00:31,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 723/780 [06:24<00:30,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 725/780 [06:24<00:29,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 727/780 [06:25<00:28,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  93%|█████████▎| 729/780 [06:25<00:26,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▎| 730/780 [06:25<00:26,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▎| 731/780 [06:25<00:25,  1.89it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 732/780 [06:26<00:25,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 733/780 [06:26<00:24,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 735/780 [06:26<00:23,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  94%|█████████▍| 737/780 [06:27<00:22,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▍| 738/780 [06:27<00:22,  1.90it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▍| 739/780 [06:27<00:21,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▌| 741/780 [06:28<00:20,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▌| 743/780 [06:28<00:19,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  95%|█████████▌| 744/780 [06:28<00:18,  1.91it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 745/780 [06:29<00:18,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 746/780 [06:29<00:17,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 747/780 [06:29<00:17,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 749/780 [06:29<00:16,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▋| 751/780 [06:30<00:15,  1.92it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  96%|█████████▋| 752/780 [06:30<00:14,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 753/780 [06:30<00:14,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 755/780 [06:31<00:12,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 757/780 [06:31<00:11,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 758/780 [06:31<00:11,  1.93it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 759/780 [06:32<00:10,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  97%|█████████▋| 760/780 [06:32<00:10,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 761/780 [06:32<00:09,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 763/780 [06:33<00:08,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 765/780 [06:33<00:07,  1.94it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 767/780 [06:33<00:06,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▊| 769/780 [06:34<00:05,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 771/780 [06:34<00:04,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 773/780 [06:35<00:03,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 775/780 [06:35<00:02,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14: 100%|█████████▉| 777/780 [06:36<00:01,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14: 100%|█████████▉| 779/780 [06:36<00:00,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.358, v_num=87, val_loss_epoch=0.362, train_loss_step=0.348, train_loss_epoch=0.303, val_loss_step=0.322]\n",
      "Epoch 14: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.358, v_num=87, val_loss_epoch=0.352, train_loss_step=0.500, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  84%|████████▍ | 658/780 [06:08<01:08,  1.78it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  84%|████████▍ | 659/780 [06:09<01:07,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▋ | 673/780 [06:12<00:59,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 683/780 [06:14<00:53,  1.82it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 689/780 [06:15<00:49,  1.83it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  88%|████████▊ | 690/780 [06:15<00:49,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 695/780 [06:16<00:46,  1.84it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 696/780 [06:17<00:45,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|█████████ | 702/780 [06:18<00:42,  1.85it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  90%|█████████ | 705/780 [06:19<00:40,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 708/780 [06:19<00:38,  1.86it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 709/780 [06:20<00:38,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 715/780 [06:21<00:34,  1.87it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 718/780 [06:22<00:32,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  92%|█████████▏| 721/780 [06:22<00:31,  1.88it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 723/780 [06:23<00:30,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 727/780 [06:24<00:27,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 735/780 [06:25<00:23,  1.90it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 736/780 [06:26<00:23,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▌| 741/780 [06:27<00:20,  1.91it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 745/780 [06:28<00:18,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 748/780 [06:28<00:16,  1.92it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▌| 750/780 [06:29<00:15,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 755/780 [06:30<00:12,  1.93it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 759/780 [06:31<00:10,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 761/780 [06:31<00:09,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 762/780 [06:31<00:09,  1.94it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 763/780 [06:31<00:08,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 765/780 [06:32<00:07,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▊| 769/780 [06:33<00:05,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 773/780 [06:34<00:03,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 775/780 [06:34<00:02,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15:  99%|█████████▉| 776/780 [06:34<00:02,  1.96it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15: 100%|█████████▉| 777/780 [06:35<00:01,  1.97it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.28, v_num=87, val_loss_epoch=0.352, train_loss_step=0.159, train_loss_epoch=0.305, val_loss_step=0.415]\n",
      "Epoch 15: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.28, v_num=87, val_loss_epoch=0.315, train_loss_step=0.313, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▍ | 661/780 [06:06<01:06,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▌ | 663/780 [06:07<01:04,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 669/780 [06:08<01:01,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 671/780 [06:09<00:59,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 679/780 [06:10<00:55,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 681/780 [06:11<00:53,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 687/780 [06:12<00:50,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 689/780 [06:13<00:49,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 693/780 [06:14<00:46,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 697/780 [06:14<00:44,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|████████▉ | 701/780 [06:15<00:42,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 715/780 [06:19<00:34,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 719/780 [06:19<00:32,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  92%|█████████▏| 721/780 [06:20<00:31,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 723/780 [06:20<00:30,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 727/780 [06:21<00:27,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 733/780 [06:22<00:24,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 749/780 [06:26<00:15,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▋| 751/780 [06:26<00:14,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 761/780 [06:29<00:09,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 765/780 [06:29<00:07,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▊| 769/780 [06:30<00:05,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 773/780 [06:31<00:03,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 774/780 [06:31<00:03,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 775/780 [06:32<00:02,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16: 100%|█████████▉| 779/780 [06:32<00:00,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.315, train_loss_step=0.239, train_loss_epoch=0.297, val_loss_step=0.482]\n",
      "Epoch 16: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.287, v_num=87, val_loss_epoch=0.363, train_loss_step=0.299, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 658/780 [06:08<01:08,  1.78it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▋ | 673/780 [06:11<00:59,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  87%|████████▋ | 682/780 [06:13<00:53,  1.82it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 683/780 [06:14<00:53,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 689/780 [06:15<00:49,  1.83it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  88%|████████▊ | 690/780 [06:15<00:49,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 695/780 [06:16<00:46,  1.84it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 696/780 [06:17<00:45,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  90%|█████████ | 705/780 [06:18<00:40,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 708/780 [06:19<00:38,  1.86it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 709/780 [06:19<00:38,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 714/780 [06:20<00:35,  1.87it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 715/780 [06:21<00:34,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  92%|█████████▏| 721/780 [06:22<00:31,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 723/780 [06:22<00:30,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 727/780 [06:23<00:27,  1.89it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 728/780 [06:24<00:27,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 735/780 [06:25<00:23,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▌| 741/780 [06:26<00:20,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 745/780 [06:27<00:18,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 748/780 [06:28<00:16,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 754/780 [06:29<00:13,  1.93it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 755/780 [06:30<00:12,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 759/780 [06:30<00:10,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 761/780 [06:31<00:09,  1.94it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 763/780 [06:31<00:08,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 765/780 [06:32<00:07,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  98%|█████████▊| 768/780 [06:32<00:06,  1.95it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▊| 769/780 [06:33<00:05,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 773/780 [06:33<00:03,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 775/780 [06:34<00:02,  1.96it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17: 100%|█████████▉| 777/780 [06:34<00:01,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.363, train_loss_step=0.227, train_loss_epoch=0.300, val_loss_step=0.200]\n",
      "Epoch 17: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.278, v_num=87, val_loss_epoch=0.355, train_loss_step=0.567, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▍ | 661/780 [06:06<01:06,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▌ | 663/780 [06:07<01:04,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 667/780 [06:07<01:02,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 669/780 [06:08<01:01,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 671/780 [06:08<00:59,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 675/780 [06:09<00:57,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 679/780 [06:10<00:55,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 681/780 [06:11<00:53,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 685/780 [06:11<00:51,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 687/780 [06:12<00:50,  1.84it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 689/780 [06:12<00:49,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 693/780 [06:13<00:46,  1.85it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 697/780 [06:14<00:44,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|████████▉ | 701/780 [06:15<00:42,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|█████████ | 703/780 [06:15<00:41,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 707/780 [06:16<00:38,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████ | 711/780 [06:17<00:36,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  91%|█████████▏| 713/780 [06:18<00:35,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 715/780 [06:18<00:34,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 719/780 [06:19<00:32,  1.89it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  92%|█████████▏| 721/780 [06:19<00:31,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 723/780 [06:20<00:29,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 725/780 [06:20<00:28,  1.90it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 727/780 [06:21<00:27,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  93%|█████████▎| 729/780 [06:21<00:26,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 733/780 [06:22<00:24,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▍| 739/780 [06:23<00:21,  1.92it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▌| 743/780 [06:24<00:19,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 747/780 [06:25<00:17,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 749/780 [06:26<00:15,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▋| 751/780 [06:26<00:14,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 753/780 [06:27<00:13,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 757/780 [06:27<00:11,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 761/780 [06:28<00:09,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 765/780 [06:29<00:07,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 767/780 [06:30<00:06,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▊| 769/780 [06:30<00:05,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 771/780 [06:30<00:04,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 773/780 [06:31<00:03,  1.97it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 775/780 [06:31<00:02,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18: 100%|█████████▉| 779/780 [06:32<00:00,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18: 100%|██████████| 780/780 [06:32<00:00,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.355, train_loss_step=0.188, train_loss_epoch=0.285, val_loss_step=0.740]\n",
      "Epoch 18: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.263, v_num=87, val_loss_epoch=0.367, train_loss_step=0.359, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  84%|████████▍ | 657/780 [06:05<01:08,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  84%|████████▍ | 659/780 [06:06<01:07,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▌ | 663/780 [06:07<01:04,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▌ | 665/780 [06:07<01:03,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 667/780 [06:08<01:02,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 669/780 [06:08<01:01,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 671/780 [06:09<00:59,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▋ | 673/780 [06:09<00:58,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 677/780 [06:10<00:56,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 681/780 [06:11<00:54,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 683/780 [06:11<00:52,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 685/780 [06:12<00:51,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 687/780 [06:12<00:50,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 689/780 [06:13<00:49,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▊ | 691/780 [06:13<00:48,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 693/780 [06:14<00:46,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 695/780 [06:14<00:45,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 697/780 [06:15<00:44,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|████████▉ | 699/780 [06:15<00:43,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|████████▉ | 701/780 [06:15<00:42,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|█████████ | 703/780 [06:16<00:41,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  90%|█████████ | 705/780 [06:16<00:40,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 707/780 [06:17<00:38,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 709/780 [06:17<00:37,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  91%|█████████▏| 713/780 [06:18<00:35,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 715/780 [06:19<00:34,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 717/780 [06:19<00:33,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  92%|█████████▏| 721/780 [06:20<00:31,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 723/780 [06:20<00:30,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 727/780 [06:21<00:27,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  93%|█████████▎| 729/780 [06:22<00:26,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▎| 731/780 [06:22<00:25,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 735/780 [06:23<00:23,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  94%|█████████▍| 737/780 [06:23<00:22,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▍| 739/780 [06:24<00:21,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▌| 741/780 [06:24<00:20,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 745/780 [06:25<00:18,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 749/780 [06:26<00:16,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 753/780 [06:27<00:13,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 755/780 [06:27<00:12,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 757/780 [06:28<00:11,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 759/780 [06:28<00:10,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 761/780 [06:29<00:09,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 763/780 [06:29<00:08,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 767/780 [06:30<00:06,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▊| 769/780 [06:31<00:05,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 771/780 [06:31<00:04,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 773/780 [06:31<00:03,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 775/780 [06:32<00:02,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19: 100%|█████████▉| 777/780 [06:32<00:01,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.367, train_loss_step=0.246, train_loss_epoch=0.283, val_loss_step=0.240]\n",
      "Epoch 19: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.314, train_loss_step=0.257, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  84%|████████▍ | 657/780 [06:06<01:08,  1.79it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  84%|████████▍ | 659/780 [06:07<01:07,  1.79it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▌ | 663/780 [06:08<01:04,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▌ | 665/780 [06:08<01:03,  1.80it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 667/780 [06:09<01:02,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 669/780 [06:09<01:01,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 671/780 [06:10<01:00,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▋ | 673/780 [06:10<00:58,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 677/780 [06:11<00:56,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 681/780 [06:12<00:54,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 683/780 [06:12<00:52,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 685/780 [06:13<00:51,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 687/780 [06:13<00:50,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 689/780 [06:13<00:49,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▊ | 691/780 [06:14<00:48,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 693/780 [06:14<00:47,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 695/780 [06:15<00:45,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 697/780 [06:15<00:44,  1.85it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|████████▉ | 699/780 [06:16<00:43,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|████████▉ | 701/780 [06:16<00:42,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|█████████ | 703/780 [06:17<00:41,  1.86it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  90%|█████████ | 705/780 [06:17<00:40,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 707/780 [06:17<00:39,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 709/780 [06:18<00:37,  1.87it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  91%|█████████▏| 713/780 [06:19<00:35,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 715/780 [06:19<00:34,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 716/780 [06:19<00:33,  1.88it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 717/780 [06:20<00:33,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  92%|█████████▏| 721/780 [06:21<00:31,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 723/780 [06:21<00:30,  1.89it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 727/780 [06:22<00:27,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  93%|█████████▎| 729/780 [06:22<00:26,  1.90it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▎| 730/780 [06:23<00:26,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▎| 731/780 [06:23<00:25,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 735/780 [06:24<00:23,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  94%|█████████▍| 737/780 [06:24<00:22,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▍| 739/780 [06:25<00:21,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▌| 741/780 [06:25<00:20,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▌| 743/780 [06:25<00:19,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 745/780 [06:26<00:18,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 749/780 [06:27<00:16,  1.93it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 753/780 [06:28<00:13,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 755/780 [06:28<00:12,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 757/780 [06:29<00:11,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 759/780 [06:29<00:10,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 761/780 [06:29<00:09,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 763/780 [06:30<00:08,  1.95it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 767/780 [06:31<00:06,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▊| 769/780 [06:31<00:05,  1.96it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 771/780 [06:32<00:04,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 773/780 [06:32<00:03,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 775/780 [06:32<00:02,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20: 100%|█████████▉| 777/780 [06:33<00:01,  1.98it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20: 100%|█████████▉| 779/780 [06:33<00:00,  1.98it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.303, v_num=87, val_loss_epoch=0.314, train_loss_step=0.252, train_loss_epoch=0.282, val_loss_step=0.466]\n",
      "Epoch 20: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.303, v_num=87, val_loss_epoch=0.335, train_loss_step=0.402, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  84%|████████▍ | 657/780 [06:06<01:08,  1.79it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  84%|████████▍ | 659/780 [06:07<01:07,  1.79it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▍ | 661/780 [06:07<01:06,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▌ | 663/780 [06:08<01:04,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▌ | 665/780 [06:08<01:03,  1.80it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 667/780 [06:09<01:02,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 669/780 [06:09<01:01,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 671/780 [06:09<01:00,  1.81it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▋ | 673/780 [06:10<00:58,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 675/780 [06:10<00:57,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 677/780 [06:11<00:56,  1.82it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 679/780 [06:11<00:55,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 681/780 [06:12<00:54,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 683/780 [06:12<00:52,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 685/780 [06:13<00:51,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 687/780 [06:13<00:50,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 689/780 [06:13<00:49,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▊ | 691/780 [06:14<00:48,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 693/780 [06:14<00:47,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 695/780 [06:15<00:45,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 697/780 [06:15<00:44,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|████████▉ | 699/780 [06:16<00:43,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|████████▉ | 701/780 [06:16<00:42,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|█████████ | 703/780 [06:17<00:41,  1.86it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  90%|█████████ | 705/780 [06:17<00:40,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 707/780 [06:17<00:39,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 709/780 [06:18<00:37,  1.87it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████ | 711/780 [06:18<00:36,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  91%|█████████▏| 713/780 [06:19<00:35,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 715/780 [06:19<00:34,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 716/780 [06:19<00:33,  1.88it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 717/780 [06:20<00:33,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 719/780 [06:20<00:32,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  92%|█████████▏| 721/780 [06:21<00:31,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 723/780 [06:21<00:30,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 725/780 [06:21<00:28,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 727/780 [06:22<00:27,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  93%|█████████▎| 729/780 [06:22<00:26,  1.90it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▎| 730/780 [06:23<00:26,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▎| 731/780 [06:23<00:25,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 733/780 [06:23<00:24,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 735/780 [06:24<00:23,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  94%|█████████▍| 737/780 [06:24<00:22,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▍| 739/780 [06:25<00:21,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▌| 741/780 [06:25<00:20,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▌| 743/780 [06:25<00:19,  1.92it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 745/780 [06:26<00:18,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 747/780 [06:26<00:17,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 749/780 [06:27<00:16,  1.93it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▋| 751/780 [06:27<00:14,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 753/780 [06:28<00:13,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 755/780 [06:28<00:12,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 757/780 [06:29<00:11,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 759/780 [06:29<00:10,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 761/780 [06:30<00:09,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 763/780 [06:30<00:08,  1.95it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 765/780 [06:30<00:07,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 767/780 [06:31<00:06,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▊| 769/780 [06:31<00:05,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 771/780 [06:32<00:04,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 773/780 [06:32<00:03,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 775/780 [06:33<00:02,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21: 100%|█████████▉| 777/780 [06:33<00:01,  1.97it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21: 100%|█████████▉| 779/780 [06:34<00:00,  1.98it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.306, v_num=87, val_loss_epoch=0.335, train_loss_step=0.155, train_loss_epoch=0.282, val_loss_step=0.191]\n",
      "Epoch 21: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.306, v_num=87, val_loss_epoch=0.365, train_loss_step=0.225, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▍ | 660/780 [06:08<01:07,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▌ | 664/780 [06:09<01:04,  1.79it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 669/780 [06:11<01:01,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▋ | 673/780 [06:11<00:59,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  87%|████████▋ | 682/780 [06:13<00:53,  1.82it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 683/780 [06:14<00:53,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 687/780 [06:15<00:50,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 689/780 [06:15<00:49,  1.83it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  88%|████████▊ | 690/780 [06:15<00:49,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▊ | 691/780 [06:15<00:48,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 693/780 [06:16<00:47,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 695/780 [06:16<00:46,  1.84it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 696/780 [06:17<00:45,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 697/780 [06:17<00:44,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|████████▉ | 699/780 [06:17<00:43,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|████████▉ | 701/780 [06:18<00:42,  1.85it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|█████████ | 703/780 [06:18<00:41,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  90%|█████████ | 705/780 [06:19<00:40,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 707/780 [06:19<00:39,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 708/780 [06:19<00:38,  1.86it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 709/780 [06:19<00:38,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████ | 711/780 [06:20<00:36,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  91%|█████████▏| 713/780 [06:20<00:35,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 715/780 [06:21<00:34,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 717/780 [06:21<00:33,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 719/780 [06:22<00:32,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  92%|█████████▏| 721/780 [06:22<00:31,  1.88it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 723/780 [06:23<00:30,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 725/780 [06:23<00:29,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 727/780 [06:23<00:27,  1.89it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 728/780 [06:24<00:27,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  93%|█████████▎| 729/780 [06:24<00:26,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▎| 731/780 [06:24<00:25,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 733/780 [06:25<00:24,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 735/780 [06:25<00:23,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  94%|█████████▍| 737/780 [06:26<00:22,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▍| 739/780 [06:26<00:21,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▌| 741/780 [06:27<00:20,  1.91it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▌| 743/780 [06:27<00:19,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 745/780 [06:27<00:18,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 747/780 [06:28<00:17,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 748/780 [06:28<00:16,  1.92it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 749/780 [06:28<00:16,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▌| 750/780 [06:29<00:15,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▋| 751/780 [06:29<00:15,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 753/780 [06:29<00:13,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 754/780 [06:29<00:13,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 755/780 [06:30<00:12,  1.93it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 757/780 [06:30<00:11,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 759/780 [06:31<00:10,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 761/780 [06:31<00:09,  1.94it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 763/780 [06:31<00:08,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 765/780 [06:32<00:07,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 767/780 [06:32<00:06,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▊| 769/780 [06:33<00:05,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 771/780 [06:33<00:04,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 773/780 [06:34<00:03,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 775/780 [06:34<00:02,  1.96it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22: 100%|█████████▉| 777/780 [06:35<00:01,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22: 100%|█████████▉| 779/780 [06:35<00:00,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.365, train_loss_step=0.271, train_loss_epoch=0.277, val_loss_step=0.547]\n",
      "Epoch 22: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.287, v_num=87, val_loss_epoch=0.347, train_loss_step=0.162, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  84%|████████▍ | 657/780 [06:07<01:08,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  84%|████████▍ | 659/780 [06:08<01:07,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▍ | 661/780 [06:09<01:06,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▌ | 663/780 [06:09<01:05,  1.79it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▌ | 665/780 [06:10<01:04,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 667/780 [06:10<01:02,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 669/780 [06:10<01:01,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 671/780 [06:11<01:00,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▋ | 673/780 [06:11<00:59,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 675/780 [06:12<00:57,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 677/780 [06:12<00:56,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 679/780 [06:13<00:55,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 681/780 [06:13<00:54,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  87%|████████▋ | 682/780 [06:13<00:53,  1.82it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 683/780 [06:14<00:53,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 685/780 [06:14<00:51,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 687/780 [06:14<00:50,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23:  88%|████████▊ | 690/780 [06:15<00:48,  1.84it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:16,  5.39it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:17,  4.89it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:17,  4.79it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 23:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.73it/s]\u001b[A\n",
      "Epoch 23:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.66it/s]\u001b[A\n",
      "Epoch 23:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 706/780 [06:18<00:39,  1.86it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.51it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 708/780 [06:19<00:38,  1.87it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.27it/s]\u001b[A\n",
      "Epoch 23:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 714/780 [06:20<00:35,  1.88it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.29it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.57it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.48it/s]\u001b[A\n",
      "Epoch 23:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.54it/s]\u001b[A\n",
      "Epoch 23:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:13,  4.29it/s]\u001b[A\n",
      "Epoch 23:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 23:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 734/780 [06:25<00:24,  1.91it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.40it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.42it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▌| 746/780 [06:27<00:17,  1.92it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▌| 748/780 [06:28<00:16,  1.93it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 754/780 [06:29<00:13,  1.94it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.57it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 760/780 [06:30<00:10,  1.94it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 764/780 [06:31<00:08,  1.95it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.28it/s]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 768/780 [06:32<00:06,  1.96it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.43it/s]\u001b[A\n",
      "Epoch 23:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 23:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.29it/s]\u001b[A\n",
      "Epoch 23:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.54it/s]\u001b[A\n",
      "Epoch 23:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 23: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.28it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.262, v_num=87, val_loss_epoch=0.347, train_loss_step=0.255, train_loss_epoch=0.271, val_loss_step=0.340]\n",
      "Epoch 23: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.262, v_num=87, val_loss_epoch=0.359, train_loss_step=0.234, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Epoch 24:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:04,  1.89it/s]\u001b[A\n",
      "Epoch 24:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 24:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.84it/s]\u001b[A\n",
      "Epoch 24:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.01it/s]\u001b[A\n",
      "Epoch 24:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 24:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 24:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.60it/s]\u001b[A\n",
      "Epoch 24:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.30it/s]\u001b[A\n",
      "Epoch 24:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.52it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 676/780 [06:10<00:56,  1.82it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.32it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.48it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.40it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.61it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.39it/s]\u001b[A\n",
      "Epoch 24:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 24:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 24:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.36it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 24:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.37it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.50it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:14,  4.24it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.73it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.74it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 24:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  4.76it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.65it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.42it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.40it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.38it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.81it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.77it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:02,  5.50it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.93it/s]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.47it/s]\u001b[A\n",
      "Epoch 24:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 24:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 24:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.39it/s]\u001b[A\n",
      "Epoch 24:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 24: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.66it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.226, v_num=87, val_loss_epoch=0.359, train_loss_step=0.303, train_loss_epoch=0.269, val_loss_step=0.567]\n",
      "Epoch 24: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.226, v_num=87, val_loss_epoch=0.370, train_loss_step=0.172, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Epoch 25:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  84%|████████▍ | 658/780 [06:06<01:08,  1.79it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.91it/s]\u001b[A\n",
      "Epoch 25:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.03it/s]\u001b[A\n",
      "Epoch 25:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 25:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.20it/s]\u001b[A\n",
      "Epoch 25:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.29it/s]\u001b[A\n",
      "Epoch 25:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.52it/s]\u001b[A\n",
      "Epoch 25:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:26,  4.21it/s]\u001b[A\n",
      "Epoch 25:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 25:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.50it/s]\u001b[A\n",
      "Epoch 25:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 25:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 25:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.40it/s]\u001b[A\n",
      "Epoch 25:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.65it/s]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.34it/s]\u001b[A\n",
      "Epoch 25:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 25:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 25:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.30it/s]\u001b[A\n",
      "Epoch 25:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 25:  90%|████████▉ | 700/780 [06:16<00:42,  1.86it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.66it/s]\u001b[A\n",
      "Epoch 25:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 25:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 25:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 25:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 25:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.33it/s]\u001b[A\n",
      "Epoch 25:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.31it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 25:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.39it/s]\u001b[A\n",
      "Epoch 25:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 25:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 25:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 25:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.48it/s]\u001b[A\n",
      "Epoch 25:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 25:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.41it/s]\u001b[A\n",
      "Epoch 25:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 25:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 25:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 25:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.40it/s]\u001b[A\n",
      "Epoch 25:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.71it/s]\u001b[A\n",
      "Epoch 25:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 25:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 25:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 25:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.47it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.65it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 25:  98%|█████████▊| 762/780 [06:29<00:09,  1.95it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 25:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 25:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 25:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.45it/s]\u001b[A\n",
      "Epoch 25:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.57it/s]\u001b[A\n",
      "Epoch 25:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 25:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 25:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 25: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.41it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.268, v_num=87, val_loss_epoch=0.370, train_loss_step=0.154, train_loss_epoch=0.266, val_loss_step=0.269]\n",
      "Epoch 25: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.268, v_num=87, val_loss_epoch=0.338, train_loss_step=0.197, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Epoch 26:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.85it/s]\u001b[A\n",
      "Epoch 26:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.15it/s]\u001b[A\n",
      "Epoch 26:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.90it/s]\u001b[A\n",
      "Epoch 26:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.09it/s]\u001b[A\n",
      "Epoch 26:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.48it/s]\u001b[A\n",
      "Epoch 26:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 26:  86%|████████▌ | 670/780 [06:07<01:00,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.38it/s]\u001b[A\n",
      "Epoch 26:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 26:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 26:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.39it/s]\u001b[A\n",
      "Epoch 26:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 26:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 26:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.40it/s]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 26:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 26:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 26:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.29it/s]\u001b[A\n",
      "Epoch 26:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.49it/s]\u001b[A\n",
      "Epoch 26:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 26:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 26:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 26:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 26:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 26:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 26:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 714/780 [06:16<00:34,  1.89it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.64it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.45it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.66it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 26:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 26:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 26:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.63it/s]\u001b[A\n",
      "Epoch 26:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.42it/s]\u001b[A\n",
      "Epoch 26:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 26:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 26:  94%|█████████▍| 734/780 [06:21<00:23,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 26:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 26:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 26:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 26:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 26:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 26:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 26:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.45it/s]\u001b[A\n",
      "Epoch 26:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 26:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.36it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 760/780 [06:26<00:10,  1.96it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 26:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 26:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.35it/s]\u001b[A\n",
      "Epoch 26:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 26:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.59it/s]\u001b[A\n",
      "Epoch 26:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 26:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.44it/s]\u001b[A\n",
      "Epoch 26:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 26:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.55it/s]\u001b[A\n",
      "Epoch 26: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.35it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.285, v_num=87, val_loss_epoch=0.338, train_loss_step=0.357, train_loss_epoch=0.265, val_loss_step=0.382]\n",
      "Epoch 26: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.285, v_num=87, val_loss_epoch=0.344, train_loss_step=0.285, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Epoch 27:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.05it/s]\u001b[A\n",
      "Epoch 27:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.27it/s]\u001b[A\n",
      "Epoch 27:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.78it/s]\u001b[A\n",
      "Epoch 27:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 27:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.17it/s]\u001b[A\n",
      "Epoch 27:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.61it/s]\u001b[A\n",
      "Epoch 27:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 27:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.28it/s]\u001b[A\n",
      "Epoch 27:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 27:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 27:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.33it/s]\u001b[A\n",
      "Epoch 27:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.49it/s]\u001b[A\n",
      "Epoch 27:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.31it/s]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.45it/s]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.54it/s]\u001b[A\n",
      "Epoch 27:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.26it/s]\u001b[A\n",
      "Epoch 27:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.46it/s]\u001b[A\n",
      "Epoch 27:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 27:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:19,  4.31it/s]\u001b[A\n",
      "Epoch 27:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 27:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 27:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 27:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 27:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.56it/s]\u001b[A\n",
      "Epoch 27:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 27:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.72it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.74it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.89it/s]\u001b[A\n",
      "Epoch 27:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.78it/s]\u001b[A\n",
      "Epoch 27:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.37it/s]\u001b[A\n",
      "Epoch 27:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.80it/s]\u001b[A\n",
      "Epoch 27:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 27:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.28it/s]\u001b[A\n",
      "Epoch 27:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 27:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 27:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.30it/s]\u001b[A\n",
      "Epoch 27:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.44it/s]\u001b[A\n",
      "Epoch 27:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 27:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.31it/s]\u001b[A\n",
      "Epoch 27:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 27:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 27:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 27:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.71it/s]\u001b[A\n",
      "Epoch 27:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.50it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.28it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.53it/s]\u001b[A\n",
      "Epoch 27:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.35it/s]\u001b[A\n",
      "Epoch 27:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 27:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.66it/s]\u001b[A\n",
      "Epoch 27:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.40it/s]\u001b[A\n",
      "Epoch 27:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 27:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 27:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 27:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 27: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.291, v_num=87, val_loss_epoch=0.344, train_loss_step=0.331, train_loss_epoch=0.259, val_loss_step=0.221]\n",
      "Epoch 27: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.291, v_num=87, val_loss_epoch=0.482, train_loss_step=0.440, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Epoch 28:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.98it/s]\u001b[A\n",
      "Epoch 28:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:40,  2.97it/s]\u001b[A\n",
      "Epoch 28:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.75it/s]\u001b[A\n",
      "Epoch 28:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.23it/s]\u001b[A\n",
      "Epoch 28:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.18it/s]\u001b[A\n",
      "Epoch 28:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 28:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.44it/s]\u001b[A\n",
      "Epoch 28:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.31it/s]\u001b[A\n",
      "Epoch 28:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 28:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 28:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 28:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 28:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.53it/s]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.34it/s]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 28:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 28:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 28:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 28:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 28:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 28:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 28:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.71it/s]\u001b[A\n",
      "Epoch 28:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.51it/s]\u001b[A\n",
      "Epoch 28:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 28:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 28:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.69it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.70it/s]\u001b[A\n",
      "Epoch 28:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 28:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 28:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.72it/s]\u001b[A\n",
      "Epoch 28:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.43it/s]\u001b[A\n",
      "Epoch 28:  94%|█████████▎| 730/780 [06:21<00:26,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.68it/s]\u001b[A\n",
      "Epoch 28:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.78it/s]\u001b[A\n",
      "Epoch 28:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 28:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.74it/s]\u001b[A\n",
      "Epoch 28:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 28:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 28:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.67it/s]\u001b[A\n",
      "Epoch 28:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 28:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 28:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 28:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 28:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.28it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.35it/s]\u001b[A\n",
      "Epoch 28:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 28:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 28:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.37it/s]\u001b[A\n",
      "Epoch 28:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 28:  99%|█████████▊| 770/780 [06:29<00:05,  1.97it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 28:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 28:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.32it/s]\u001b[A\n",
      "Epoch 28:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.46it/s]\u001b[A\n",
      "Epoch 28: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.253, v_num=87, val_loss_epoch=0.482, train_loss_step=0.225, train_loss_epoch=0.258, val_loss_step=0.504]\n",
      "Epoch 28: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.253, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Epoch 29:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 29:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 29:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.84it/s]\u001b[A\n",
      "Epoch 29:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.23it/s]\u001b[A\n",
      "Epoch 29:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.16it/s]\u001b[A\n",
      "Epoch 29:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.45it/s]\u001b[A\n",
      "Epoch 29:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 29:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.38it/s]\u001b[A\n",
      "Epoch 29:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.71it/s]\u001b[A\n",
      "Epoch 29:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.65it/s]\u001b[A\n",
      "Epoch 29:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.44it/s]\u001b[A\n",
      "Epoch 29:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 29:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.44it/s]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.69it/s]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.66it/s]\u001b[A\n",
      "Epoch 29:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.43it/s]\u001b[A\n",
      "Epoch 29:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.71it/s]\u001b[A\n",
      "Epoch 29:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.66it/s]\u001b[A\n",
      "Epoch 29:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 29:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 29:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 29:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.43it/s]\u001b[A\n",
      "Epoch 29:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 29:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 29:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.42it/s]\u001b[A\n",
      "Epoch 29:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.59it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.64it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.29it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 29:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.55it/s]\u001b[A\n",
      "Epoch 29:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.39it/s]\u001b[A\n",
      "Epoch 29:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.68it/s]\u001b[A\n",
      "Epoch 29:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 29:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 29:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 29:  94%|█████████▍| 734/780 [06:21<00:23,  1.93it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 29:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 29:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 29:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 29:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.35it/s]\u001b[A\n",
      "Epoch 29:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.38it/s]\u001b[A\n",
      "Epoch 29:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 29:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 29:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 29:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 29:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 29:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.47it/s]\u001b[A\n",
      "Epoch 29:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 29:  97%|█████████▋| 760/780 [06:26<00:10,  1.96it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.52it/s]\u001b[A\n",
      "Epoch 29:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.43it/s]\u001b[A\n",
      "Epoch 29:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 29:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.48it/s]\u001b[A\n",
      "Epoch 29:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.67it/s]\u001b[A\n",
      "Epoch 29:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.71it/s]\u001b[A\n",
      "Epoch 29:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.55it/s]\u001b[A\n",
      "Epoch 29:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 29:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 29: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.266, v_num=87, val_loss_epoch=0.347, train_loss_step=0.234, train_loss_epoch=0.253, val_loss_step=0.234]\n",
      "Epoch 29: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.266, v_num=87, val_loss_epoch=0.334, train_loss_step=0.160, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Epoch 30:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 30:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.22it/s]\u001b[A\n",
      "Epoch 30:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.91it/s]\u001b[A\n",
      "Epoch 30:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.16it/s]\u001b[A\n",
      "Epoch 30:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 30:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 30:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 30:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:21,  4.98it/s]\u001b[A\n",
      "Epoch 30:  86%|████████▋ | 674/780 [06:08<00:58,  1.83it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:21,  4.95it/s]\u001b[A\n",
      "Epoch 30:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  16%|█▌        | 20/124 [00:04<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 30:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.69it/s]\u001b[A\n",
      "Epoch 30:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 30:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.35it/s]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.53it/s]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.55it/s]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.29it/s]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 30:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 30:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 30:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.24it/s]\u001b[A\n",
      "Epoch 30:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.49it/s]\u001b[A\n",
      "Epoch 30:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 30:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 30:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 30:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 30:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.40it/s]\u001b[A\n",
      "Epoch 30:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 30:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.60it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.46it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 30:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 30:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.65it/s]\u001b[A\n",
      "Epoch 30:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 30:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.36it/s]\u001b[A\n",
      "Epoch 30:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 30:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 30:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.45it/s]\u001b[A\n",
      "Epoch 30:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 30:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 30:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 30:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 30:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.31it/s]\u001b[A\n",
      "Epoch 30:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.49it/s]\u001b[A\n",
      "Epoch 30:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 30:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.33it/s]\u001b[A\n",
      "Epoch 30:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 30:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 30:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.67it/s]\u001b[A\n",
      "Epoch 30:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.36it/s]\u001b[A\n",
      "Epoch 30:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 30:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 30:  98%|█████████▊| 764/780 [06:28<00:08,  1.96it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.28it/s]\u001b[A\n",
      "Epoch 30:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 30:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.49it/s]\u001b[A\n",
      "Epoch 30:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.25it/s]\u001b[A\n",
      "Epoch 30:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 30:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.53it/s]\u001b[A\n",
      "Epoch 30:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.37it/s]\u001b[A\n",
      "Epoch 30: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.26, v_num=87, val_loss_epoch=0.334, train_loss_step=0.198, train_loss_epoch=0.255, val_loss_step=0.394]\n",
      "Epoch 30: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.26, v_num=87, val_loss_epoch=0.337, train_loss_step=0.385, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Epoch 31:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 31:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.32it/s]\u001b[A\n",
      "Epoch 31:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:31,  3.73it/s]\u001b[A\n",
      "Epoch 31:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.25it/s]\u001b[A\n",
      "Epoch 31:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 31:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 31:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.26it/s]\u001b[A\n",
      "Epoch 31:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 31:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 31:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.29it/s]\u001b[A\n",
      "Epoch 31:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.44it/s]\u001b[A\n",
      "Epoch 31:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.49it/s]\u001b[A\n",
      "Epoch 31:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.37it/s]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 31:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.44it/s]\u001b[A\n",
      "Epoch 31:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.43it/s]\u001b[A\n",
      "Epoch 31:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.43it/s]\u001b[A\n",
      "Epoch 31:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 31:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 31:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.47it/s]\u001b[A\n",
      "Epoch 31:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 31:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 31:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 31:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 31:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.68it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.37it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.71it/s]\u001b[A\n",
      "Epoch 31:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 31:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 31:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 31:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 31:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 31:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 31:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 31:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.54it/s]\u001b[A\n",
      "Epoch 31:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 31:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 31:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:07,  5.07it/s]\u001b[A\n",
      "Epoch 31:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.89it/s]\u001b[A\n",
      "Epoch 31:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 31:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 31:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 31:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.44it/s]\u001b[A\n",
      "Epoch 31:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 31:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 31:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 31:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.31it/s]\u001b[A\n",
      "Epoch 31:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 31:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 31:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.44it/s]\u001b[A\n",
      "Epoch 31:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 31:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 31:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.46it/s]\u001b[A\n",
      "Epoch 31:  99%|█████████▉| 774/780 [06:31<00:03,  1.97it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 31:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.48it/s]\u001b[A\n",
      "Epoch 31: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.217, v_num=87, val_loss_epoch=0.337, train_loss_step=0.103, train_loss_epoch=0.251, val_loss_step=0.248]\n",
      "Epoch 31: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.217, v_num=87, val_loss_epoch=0.312, train_loss_step=0.239, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Epoch 32:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  84%|████████▍ | 658/780 [06:06<01:07,  1.79it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 32:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.24it/s]\u001b[A\n",
      "Epoch 32:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.70it/s]\u001b[A\n",
      "Epoch 32:  85%|████████▌ | 664/780 [06:07<01:04,  1.80it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 32:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.49it/s]\u001b[A\n",
      "Epoch 32:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.20it/s]\u001b[A\n",
      "Epoch 32:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.67it/s]\u001b[A\n",
      "Epoch 32:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.55it/s]\u001b[A\n",
      "Epoch 32:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 32:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 32:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.48it/s]\u001b[A\n",
      "Epoch 32:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 32:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.63it/s]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.64it/s]\u001b[A\n",
      "Epoch 32:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.74it/s]\u001b[A\n",
      "Epoch 32:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.52it/s]\u001b[A\n",
      "Epoch 32:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.76it/s]\u001b[A\n",
      "Epoch 32:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.77it/s]\u001b[A\n",
      "Epoch 32:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 32:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.70it/s]\u001b[A\n",
      "Epoch 32:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.53it/s]\u001b[A\n",
      "Epoch 32:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 32:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 32:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 32:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.38it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.57it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 32:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 32:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.70it/s]\u001b[A\n",
      "Epoch 32:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.34it/s]\u001b[A\n",
      "Epoch 32:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.48it/s]\u001b[A\n",
      "Epoch 32:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 32:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 32:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 32:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.47it/s]\u001b[A\n",
      "Epoch 32:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 32:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.28it/s]\u001b[A\n",
      "Epoch 32:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 32:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 32:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 32:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.49it/s]\u001b[A\n",
      "Epoch 32:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 32:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 32:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.47it/s]\u001b[A\n",
      "Epoch 32:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 32:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 32:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 32:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 32:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.38it/s]\u001b[A\n",
      "Epoch 32:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 32:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 32:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 32:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.27it/s]\u001b[A\n",
      "Epoch 32:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.44it/s]\u001b[A\n",
      "Epoch 32:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.53it/s]\u001b[A\n",
      "Epoch 32: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.36it/s]\u001b[A\n",
      "Epoch 32: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.246, v_num=87, val_loss_epoch=0.312, train_loss_step=0.117, train_loss_epoch=0.253, val_loss_step=0.132]\n",
      "Epoch 32: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.246, v_num=87, val_loss_epoch=0.377, train_loss_step=0.234, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Epoch 33:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 33:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.28it/s]\u001b[A\n",
      "Epoch 33:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 33:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 33:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.47it/s]\u001b[A\n",
      "Epoch 33:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.30it/s]\u001b[A\n",
      "Epoch 33:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.42it/s]\u001b[A\n",
      "Epoch 33:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.55it/s]\u001b[A\n",
      "Epoch 33:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.25it/s]\u001b[A\n",
      "Epoch 33:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.44it/s]\u001b[A\n",
      "Epoch 33:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 33:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.30it/s]\u001b[A\n",
      "Epoch 33:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.61it/s]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.41it/s]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 33:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 33:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.30it/s]\u001b[A\n",
      "Epoch 33:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.48it/s]\u001b[A\n",
      "Epoch 33:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 33:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.35it/s]\u001b[A\n",
      "Epoch 33:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 33:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 33:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 33:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 33:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.57it/s]\u001b[A\n",
      "Epoch 33:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.33it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.45it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.51it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 33:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 33:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 33:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 33:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 33:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.42it/s]\u001b[A\n",
      "Epoch 33:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 33:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.53it/s]\u001b[A\n",
      "Epoch 33:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.27it/s]\u001b[A\n",
      "Epoch 33:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 33:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 33:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.32it/s]\u001b[A\n",
      "Epoch 33:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 33:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 33:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.32it/s]\u001b[A\n",
      "Epoch 33:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 33:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:05,  4.75it/s]\u001b[A\n",
      "Epoch 33:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 33:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 33:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 33:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.74it/s]\u001b[A\n",
      "Epoch 33:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 33:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.75it/s]\u001b[A\n",
      "Epoch 33:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.72it/s]\u001b[A\n",
      "Epoch 33:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.41it/s]\u001b[A\n",
      "Epoch 33:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.81it/s]\u001b[A\n",
      "Epoch 33:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.74it/s]\u001b[A\n",
      "Epoch 33:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 33:  99%|█████████▉| 776/780 [06:30<00:02,  1.98it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.61it/s]\u001b[A\n",
      "Epoch 33: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.61it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.254, v_num=87, val_loss_epoch=0.377, train_loss_step=0.341, train_loss_epoch=0.244, val_loss_step=0.269]\n",
      "Epoch 33: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.254, v_num=87, val_loss_epoch=0.389, train_loss_step=0.271, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Epoch 34:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.06it/s]\u001b[A\n",
      "Epoch 34:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.32it/s]\u001b[A\n",
      "Epoch 34:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 34:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.11it/s]\u001b[A\n",
      "Epoch 34:  85%|████████▌ | 666/780 [06:08<01:02,  1.81it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.54it/s]\u001b[A\n",
      "Epoch 34:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 34:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.32it/s]\u001b[A\n",
      "Epoch 34:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:22,  4.76it/s]\u001b[A\n",
      "Epoch 34:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 34:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.29it/s]\u001b[A\n",
      "Epoch 34:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.47it/s]\u001b[A\n",
      "Epoch 34:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.47it/s]\u001b[A\n",
      "Epoch 34:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.27it/s]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.43it/s]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 34:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 34:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.39it/s]\u001b[A\n",
      "Epoch 34:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.60it/s]\u001b[A\n",
      "Epoch 34:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.81it/s]\u001b[A\n",
      "Epoch 34:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.66it/s]\u001b[A\n",
      "Epoch 34:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.42it/s]\u001b[A\n",
      "Epoch 34:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.53it/s]\u001b[A\n",
      "Epoch 34:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 34:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.33it/s]\u001b[A\n",
      "Epoch 34:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 34:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 34:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.67it/s]\u001b[A\n",
      "Epoch 34:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 34:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 34:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.39it/s]\u001b[A\n",
      "Epoch 34:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 34:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 34:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.35it/s]\u001b[A\n",
      "Epoch 34:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 34:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 34:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 34:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.71it/s]\u001b[A\n",
      "Epoch 34:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 34:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.40it/s]\u001b[A\n",
      "Epoch 34:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 34:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.67it/s]\u001b[A\n",
      "Epoch 34:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.48it/s]\u001b[A\n",
      "Epoch 34:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 34:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 34:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 34:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 34:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 34:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 34:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.35it/s]\u001b[A\n",
      "Epoch 34:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.49it/s]\u001b[A\n",
      "Epoch 34:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.40it/s]\u001b[A\n",
      "Epoch 34:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 34:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.68it/s]\u001b[A\n",
      "Epoch 34:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.48it/s]\u001b[A\n",
      "Epoch 34: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.66it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.281, v_num=87, val_loss_epoch=0.389, train_loss_step=0.272, train_loss_epoch=0.245, val_loss_step=0.237]\n",
      "Epoch 34: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.281, v_num=87, val_loss_epoch=0.443, train_loss_step=0.332, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Epoch 35:  84%|████████▍ | 656/780 [06:07<01:09,  1.78it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  2.00it/s]\u001b[A\n",
      "Epoch 35:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.10it/s]\u001b[A\n",
      "Epoch 35:  85%|████████▍ | 662/780 [06:10<01:05,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.83it/s]\u001b[A\n",
      "Epoch 35:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 35:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.18it/s]\u001b[A\n",
      "Epoch 35:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.46it/s]\u001b[A\n",
      "Epoch 35:  86%|████████▌ | 670/780 [06:11<01:01,  1.80it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.42it/s]\u001b[A\n",
      "Epoch 35:  86%|████████▌ | 672/780 [06:12<00:59,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 35:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 35:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 35:  87%|████████▋ | 678/780 [06:13<00:56,  1.81it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 35:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.46it/s]\u001b[A\n",
      "Epoch 35:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 684/780 [06:14<00:52,  1.82it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.51it/s]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.29it/s]\u001b[A\n",
      "Epoch 35:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.74it/s]\u001b[A\n",
      "Epoch 35:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.71it/s]\u001b[A\n",
      "Epoch 35:  89%|████████▉ | 696/780 [06:17<00:45,  1.84it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 35:  89%|████████▉ | 698/780 [06:18<00:44,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 35:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 35:  90%|█████████ | 702/780 [06:18<00:42,  1.85it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 35:  90%|█████████ | 704/780 [06:19<00:40,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:15,  4.81it/s]\u001b[A\n",
      "Epoch 35:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 35:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 35:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 35:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 716/780 [06:21<00:34,  1.87it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 718/780 [06:22<00:33,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.49it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.65it/s]\u001b[A\n",
      "Epoch 35:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.47it/s]\u001b[A\n",
      "Epoch 35:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 35:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.75it/s]\u001b[A\n",
      "Epoch 35:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.52it/s]\u001b[A\n",
      "Epoch 35:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.68it/s]\u001b[A\n",
      "Epoch 35:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.70it/s]\u001b[A\n",
      "Epoch 35:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 35:  94%|█████████▍| 736/780 [06:26<00:23,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.76it/s]\u001b[A\n",
      "Epoch 35:  95%|█████████▍| 738/780 [06:26<00:22,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 35:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.79it/s]\u001b[A\n",
      "Epoch 35:  95%|█████████▌| 742/780 [06:27<00:19,  1.91it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 35:  95%|█████████▌| 744/780 [06:28<00:18,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.39it/s]\u001b[A\n",
      "Epoch 35:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 35:  96%|█████████▌| 748/780 [06:28<00:16,  1.92it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 35:  96%|█████████▌| 750/780 [06:29<00:15,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.44it/s]\u001b[A\n",
      "Epoch 35:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 35:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 35:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 35:  97%|█████████▋| 758/780 [06:31<00:11,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.61it/s]\u001b[A\n",
      "Epoch 35:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 35:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 35:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.73it/s]\u001b[A\n",
      "Epoch 35:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 35:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.66it/s]\u001b[A\n",
      "Epoch 35:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 35:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.75it/s]\u001b[A\n",
      "Epoch 35:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.67it/s]\u001b[A\n",
      "Epoch 35:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 35: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.72it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.443, train_loss_step=0.248, train_loss_epoch=0.245, val_loss_step=0.233]\n",
      "Epoch 35: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.269, v_num=87, val_loss_epoch=0.371, train_loss_step=0.224, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Epoch 36:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.95it/s]\u001b[A\n",
      "Epoch 36:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.27it/s]\u001b[A\n",
      "Epoch 36:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.89it/s]\u001b[A\n",
      "Epoch 36:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.13it/s]\u001b[A\n",
      "Epoch 36:  85%|████████▌ | 666/780 [06:08<01:02,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.54it/s]\u001b[A\n",
      "Epoch 36:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.47it/s]\u001b[A\n",
      "Epoch 36:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.62it/s]\u001b[A\n",
      "Epoch 36:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.62it/s]\u001b[A\n",
      "Epoch 36:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.47it/s]\u001b[A\n",
      "Epoch 36:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.72it/s]\u001b[A\n",
      "Epoch 36:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.78it/s]\u001b[A\n",
      "Epoch 36:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.43it/s]\u001b[A\n",
      "Epoch 36:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.76it/s]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.65it/s]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.70it/s]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 36:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.56it/s]\u001b[A\n",
      "Epoch 36:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.61it/s]\u001b[A\n",
      "Epoch 36:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.44it/s]\u001b[A\n",
      "Epoch 36:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 36:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.43it/s]\u001b[A\n",
      "Epoch 36:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 36:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 36:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 36:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.76it/s]\u001b[A\n",
      "Epoch 36:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.70it/s]\u001b[A\n",
      "Epoch 36:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.63it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 36:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.55it/s]\u001b[A\n",
      "Epoch 36:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 36:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.37it/s]\u001b[A\n",
      "Epoch 36:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 36:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 36:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.30it/s]\u001b[A\n",
      "Epoch 36:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 36:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 36:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.35it/s]\u001b[A\n",
      "Epoch 36:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 36:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 36:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.39it/s]\u001b[A\n",
      "Epoch 36:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 36:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 36:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 36:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.31it/s]\u001b[A\n",
      "Epoch 36:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 36:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 36:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.31it/s]\u001b[A\n",
      "Epoch 36:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 36:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.66it/s]\u001b[A\n",
      "Epoch 36:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 36:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 36:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 36:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 36:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.70it/s]\u001b[A\n",
      "Epoch 36:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 36:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.40it/s]\u001b[A\n",
      "Epoch 36: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.68it/s]\u001b[A\n",
      "Epoch 36: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.224, v_num=87, val_loss_epoch=0.371, train_loss_step=0.305, train_loss_epoch=0.237, val_loss_step=0.320]\n",
      "Epoch 36: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.224, v_num=87, val_loss_epoch=0.430, train_loss_step=0.161, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Epoch 37:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 37:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 37:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:26,  4.51it/s]\u001b[A\n",
      "Epoch 37:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:24,  4.73it/s]\u001b[A\n",
      "Epoch 37:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:24,  4.65it/s]\u001b[A\n",
      "Epoch 37:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.60it/s]\u001b[A\n",
      "Epoch 37:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.44it/s]\u001b[A\n",
      "Epoch 37:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.57it/s]\u001b[A\n",
      "Epoch 37:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 37:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.40it/s]\u001b[A\n",
      "Epoch 37:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 37:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 37:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.72it/s]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.75it/s]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.32it/s]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.73it/s]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.72it/s]\u001b[A\n",
      "Epoch 37:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.36it/s]\u001b[A\n",
      "Epoch 37:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 37:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.59it/s]\u001b[A\n",
      "Epoch 37:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:19,  4.26it/s]\u001b[A\n",
      "Epoch 37:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 37:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.65it/s]\u001b[A\n",
      "Epoch 37:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 37:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 37:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 37:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.74it/s]\u001b[A\n",
      "Epoch 37:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.58it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.35it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.77it/s]\u001b[A\n",
      "Epoch 37:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.70it/s]\u001b[A\n",
      "Epoch 37:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.34it/s]\u001b[A\n",
      "Epoch 37:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 37:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 37:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.31it/s]\u001b[A\n",
      "Epoch 37:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 37:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.70it/s]\u001b[A\n",
      "Epoch 37:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 37:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 37:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 37:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 37:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:08,  4.39it/s]\u001b[A\n",
      "Epoch 37:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 37:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 37:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:07,  4.27it/s]\u001b[A\n",
      "Epoch 37:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.48it/s]\u001b[A\n",
      "Epoch 37:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.51it/s]\u001b[A\n",
      "Epoch 37:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.44it/s]\u001b[A\n",
      "Epoch 37:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 37:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.63it/s]\u001b[A\n",
      "Epoch 37:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 37:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.77it/s]\u001b[A\n",
      "Epoch 37:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 37:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.70it/s]\u001b[A\n",
      "Epoch 37:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.30it/s]\u001b[A\n",
      "Epoch 37:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 37:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.72it/s]\u001b[A\n",
      "Epoch 37:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  97%|█████████▋| 120/124 [00:26<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 37: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.55it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.221, v_num=87, val_loss_epoch=0.430, train_loss_step=0.166, train_loss_epoch=0.239, val_loss_step=0.439]\n",
      "Epoch 37: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.221, v_num=87, val_loss_epoch=0.350, train_loss_step=0.225, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Epoch 38:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.95it/s]\u001b[A\n",
      "Epoch 38:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.17it/s]\u001b[A\n",
      "Epoch 38:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.70it/s]\u001b[A\n",
      "Epoch 38:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 38:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.31it/s]\u001b[A\n",
      "Epoch 38:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.46it/s]\u001b[A\n",
      "Epoch 38:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 38:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.44it/s]\u001b[A\n",
      "Epoch 38:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.69it/s]\u001b[A\n",
      "Epoch 38:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.44it/s]\u001b[A\n",
      "Epoch 38:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.56it/s]\u001b[A\n",
      "Epoch 38:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 38:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.48it/s]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.72it/s]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.74it/s]\u001b[A\n",
      "Epoch 38:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 38:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:17,  4.79it/s]\u001b[A\n",
      "Epoch 38:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 38:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.37it/s]\u001b[A\n",
      "Epoch 38:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.52it/s]\u001b[A\n",
      "Epoch 38:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 38:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.36it/s]\u001b[A\n",
      "Epoch 38:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 38:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 38:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 38:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.32it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.52it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.24it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 38:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 38:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:13,  4.29it/s]\u001b[A\n",
      "Epoch 38:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.59it/s]\u001b[A\n",
      "Epoch 38:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 38:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.38it/s]\u001b[A\n",
      "Epoch 38:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:09,  4.97it/s]\u001b[A\n",
      "Epoch 38:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  5.04it/s]\u001b[A\n",
      "Epoch 38:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.81it/s]\u001b[A\n",
      "Epoch 38:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 38:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 38:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 38:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.64it/s]\u001b[A\n",
      "Epoch 38:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 38:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 38:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 38:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.39it/s]\u001b[A\n",
      "Epoch 38:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 38:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.42it/s]\u001b[A\n",
      "Epoch 38:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.64it/s]\u001b[A\n",
      "Epoch 38:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.69it/s]\u001b[A\n",
      "Epoch 38:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 38:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.71it/s]\u001b[A\n",
      "Epoch 38:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.71it/s]\u001b[A\n",
      "Epoch 38:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.33it/s]\u001b[A\n",
      "Epoch 38:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.71it/s]\u001b[A\n",
      "Epoch 38:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 38:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 38:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.66it/s]\u001b[A\n",
      "Epoch 38: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.252, v_num=87, val_loss_epoch=0.350, train_loss_step=0.280, train_loss_epoch=0.234, val_loss_step=0.116]\n",
      "Epoch 38: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.252, v_num=87, val_loss_epoch=0.362, train_loss_step=0.193, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Epoch 39:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.96it/s]\u001b[A\n",
      "Epoch 39:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.22it/s]\u001b[A\n",
      "Epoch 39:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  4.01it/s]\u001b[A\n",
      "Epoch 39:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.15it/s]\u001b[A\n",
      "Epoch 39:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.46it/s]\u001b[A\n",
      "Epoch 39:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.62it/s]\u001b[A\n",
      "Epoch 39:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 39:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 39:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 39:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.35it/s]\u001b[A\n",
      "Epoch 39:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 39:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 39:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.32it/s]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:19,  4.72it/s]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.69it/s]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:21,  4.24it/s]\u001b[A\n",
      "Epoch 39:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 39:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.60it/s]\u001b[A\n",
      "Epoch 39:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.28it/s]\u001b[A\n",
      "Epoch 39:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.43it/s]\u001b[A\n",
      "Epoch 39:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 39:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 39:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 39:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 39:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.42it/s]\u001b[A\n",
      "Epoch 39:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.57it/s]\u001b[A\n",
      "Epoch 39:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 39:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.42it/s]\u001b[A\n",
      "Epoch 39:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.53it/s]\u001b[A\n",
      "Epoch 39:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.60it/s]\u001b[A\n",
      "Epoch 39:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.40it/s]\u001b[A\n",
      "Epoch 39:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 39:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.47it/s]\u001b[A\n",
      "Epoch 39:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 39:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 39:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.41it/s]\u001b[A\n",
      "Epoch 39:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 39:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 39:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 39:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 39:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 39:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 39:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 39:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 39:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 39:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.28it/s]\u001b[A\n",
      "Epoch 39:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.49it/s]\u001b[A\n",
      "Epoch 39:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 39:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.33it/s]\u001b[A\n",
      "Epoch 39:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 39:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 39:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.35it/s]\u001b[A\n",
      "Epoch 39:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 39:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 39:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 39: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.279, v_num=87, val_loss_epoch=0.362, train_loss_step=0.377, train_loss_epoch=0.234, val_loss_step=0.428]\n",
      "Epoch 39: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.279, v_num=87, val_loss_epoch=0.387, train_loss_step=0.163, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Epoch 40:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.86it/s]\u001b[A\n",
      "Epoch 40:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 40:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.68it/s]\u001b[A\n",
      "Epoch 40:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.05it/s]\u001b[A\n",
      "Epoch 40:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.41it/s]\u001b[A\n",
      "Epoch 40:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.27it/s]\u001b[A\n",
      "Epoch 40:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 40:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 40:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.25it/s]\u001b[A\n",
      "Epoch 40:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 40:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 40:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.20it/s]\u001b[A\n",
      "Epoch 40:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.92it/s]\u001b[A\n",
      "Epoch 40:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.73it/s]\u001b[A\n",
      "Epoch 40:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:20,  4.30it/s]\u001b[A\n",
      "Epoch 40:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.49it/s]\u001b[A\n",
      "Epoch 40:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 40:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.26it/s]\u001b[A\n",
      "Epoch 40:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 40:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 40:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.37it/s]\u001b[A\n",
      "Epoch 40:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 40:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.57it/s]\u001b[A\n",
      "Epoch 40:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.46it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.39it/s]\u001b[A\n",
      "Epoch 40:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.49it/s]\u001b[A\n",
      "Epoch 40:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 40:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.43it/s]\u001b[A\n",
      "Epoch 40:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 40:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 40:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.49it/s]\u001b[A\n",
      "Epoch 40:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 40:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 40:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 40:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 40:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.33it/s]\u001b[A\n",
      "Epoch 40:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 40:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 40:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.36it/s]\u001b[A\n",
      "Epoch 40:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 40:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:05,  4.75it/s]\u001b[A\n",
      "Epoch 40:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.67it/s]\u001b[A\n",
      "Epoch 40:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.37it/s]\u001b[A\n",
      "Epoch 40:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.76it/s]\u001b[A\n",
      "Epoch 40:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 40:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.35it/s]\u001b[A\n",
      "Epoch 40:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 40:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 40:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.31it/s]\u001b[A\n",
      "Epoch 40:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.48it/s]\u001b[A\n",
      "Epoch 40:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 40:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.35it/s]\u001b[A\n",
      "Epoch 40:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.53it/s]\u001b[A\n",
      "Epoch 40: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.201, v_num=87, val_loss_epoch=0.387, train_loss_step=0.212, train_loss_epoch=0.229, val_loss_step=0.477]\n",
      "Epoch 40: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.201, v_num=87, val_loss_epoch=0.371, train_loss_step=0.216, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Epoch 41:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]\u001b[A\n",
      "Epoch 41:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.20it/s]\u001b[A\n",
      "Epoch 41:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.85it/s]\u001b[A\n",
      "Epoch 41:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.26it/s]\u001b[A\n",
      "Epoch 41:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.16it/s]\u001b[A\n",
      "Epoch 41:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 41:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 41:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.27it/s]\u001b[A\n",
      "Epoch 41:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.53it/s]\u001b[A\n",
      "Epoch 41:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 41:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.41it/s]\u001b[A\n",
      "Epoch 41:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 41:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.39it/s]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.54it/s]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 41:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 41:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 41:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 41:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.39it/s]\u001b[A\n",
      "Epoch 41:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 41:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 41:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.42it/s]\u001b[A\n",
      "Epoch 41:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 41:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 41:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 41:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.68it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.28it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:14,  4.25it/s]\u001b[A\n",
      "Epoch 41:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 41:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 41:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 41:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 41:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 41:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 41:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.29it/s]\u001b[A\n",
      "Epoch 41:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 41:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 41:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.27it/s]\u001b[A\n",
      "Epoch 41:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.44it/s]\u001b[A\n",
      "Epoch 41:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 41:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.30it/s]\u001b[A\n",
      "Epoch 41:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 41:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 41:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.44it/s]\u001b[A\n",
      "Epoch 41:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.68it/s]\u001b[A\n",
      "Epoch 41:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 41:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 41:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 41:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 41:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 41:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.21it/s]\u001b[A\n",
      "Epoch 41:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.45it/s]\u001b[A\n",
      "Epoch 41:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.54it/s]\u001b[A\n",
      "Epoch 41:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 41:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.57it/s]\u001b[A\n",
      "Epoch 41:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 41: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.38it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.215, v_num=87, val_loss_epoch=0.371, train_loss_step=0.122, train_loss_epoch=0.232, val_loss_step=0.367]\n",
      "Epoch 41: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.215, v_num=87, val_loss_epoch=0.336, train_loss_step=0.171, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Epoch 42:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.86it/s]\u001b[A\n",
      "Epoch 42:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 42:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.62it/s]\u001b[A\n",
      "Epoch 42:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.37it/s]\u001b[A\n",
      "Epoch 42:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.52it/s]\u001b[A\n",
      "Epoch 42:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.26it/s]\u001b[A\n",
      "Epoch 42:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 42:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.38it/s]\u001b[A\n",
      "Epoch 42:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 42:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 42:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.68it/s]\u001b[A\n",
      "Epoch 42:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.68it/s]\u001b[A\n",
      "Epoch 42:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.54it/s]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.32it/s]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 42:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 42:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.34it/s]\u001b[A\n",
      "Epoch 42:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 42:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 42:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 42:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.69it/s]\u001b[A\n",
      "Epoch 42:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 42:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 42:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.30it/s]\u001b[A\n",
      "Epoch 42:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 42:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.39it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.52it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.37it/s]\u001b[A\n",
      "Epoch 42:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.54it/s]\u001b[A\n",
      "Epoch 42:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.53it/s]\u001b[A\n",
      "Epoch 42:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.35it/s]\u001b[A\n",
      "Epoch 42:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 42:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.38it/s]\u001b[A\n",
      "Epoch 42:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 42:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.49it/s]\u001b[A\n",
      "Epoch 42:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 42:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.47it/s]\u001b[A\n",
      "Epoch 42:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 42:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 42:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.28it/s]\u001b[A\n",
      "Epoch 42:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 42:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 42:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 42:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 42:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 42:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.27it/s]\u001b[A\n",
      "Epoch 42:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 42:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.49it/s]\u001b[A\n",
      "Epoch 42:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 42:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 42:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 42:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 42:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.37it/s]\u001b[A\n",
      "Epoch 42:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 42:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 42:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.34it/s]\u001b[A\n",
      "Epoch 42: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.61it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.205, v_num=87, val_loss_epoch=0.336, train_loss_step=0.218, train_loss_epoch=0.222, val_loss_step=0.237]\n",
      "Epoch 42: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.205, v_num=87, val_loss_epoch=0.430, train_loss_step=0.153, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Epoch 43:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.94it/s]\u001b[A\n",
      "Epoch 43:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.11it/s]\u001b[A\n",
      "Epoch 43:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.83it/s]\u001b[A\n",
      "Epoch 43:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.96it/s]\u001b[A\n",
      "Epoch 43:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.56it/s]\u001b[A\n",
      "Epoch 43:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.62it/s]\u001b[A\n",
      "Epoch 43:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.28it/s]\u001b[A\n",
      "Epoch 43:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 43:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 43:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 43:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.50it/s]\u001b[A\n",
      "Epoch 43:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 43:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.28it/s]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.70it/s]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.73it/s]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.32it/s]\u001b[A\n",
      "Epoch 43:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.77it/s]\u001b[A\n",
      "Epoch 43:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.73it/s]\u001b[A\n",
      "Epoch 43:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.47it/s]\u001b[A\n",
      "Epoch 43:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:16,  4.87it/s]\u001b[A\n",
      "Epoch 43:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.78it/s]\u001b[A\n",
      "Epoch 43:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.43it/s]\u001b[A\n",
      "Epoch 43:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:15,  4.81it/s]\u001b[A\n",
      "Epoch 43:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 43:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.39it/s]\u001b[A\n",
      "Epoch 43:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.49it/s]\u001b[A\n",
      "Epoch 43:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 716/780 [06:19<00:33,  1.88it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:15,  4.26it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 43:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.30it/s]\u001b[A\n",
      "Epoch 43:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.46it/s]\u001b[A\n",
      "Epoch 43:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.47it/s]\u001b[A\n",
      "Epoch 43:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.34it/s]\u001b[A\n",
      "Epoch 43:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 43:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 43:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.47it/s]\u001b[A\n",
      "Epoch 43:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 43:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 43:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 43:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 43:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 43:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 43:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.40it/s]\u001b[A\n",
      "Epoch 43:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 43:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 43:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 43:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 43:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 43:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.37it/s]\u001b[A\n",
      "Epoch 43:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 43:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.45it/s]\u001b[A\n",
      "Epoch 43:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 43:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 43:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.30it/s]\u001b[A\n",
      "Epoch 43:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.49it/s]\u001b[A\n",
      "Epoch 43:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 43:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 43: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.47it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.236, v_num=87, val_loss_epoch=0.430, train_loss_step=0.346, train_loss_epoch=0.221, val_loss_step=0.903]\n",
      "Epoch 43: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.236, v_num=87, val_loss_epoch=0.453, train_loss_step=0.482, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Epoch 44:  84%|████████▍ | 656/780 [06:07<01:09,  1.79it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.85it/s]\u001b[A\n",
      "Epoch 44:  85%|████████▍ | 660/780 [06:08<01:07,  1.79it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.11it/s]\u001b[A\n",
      "Epoch 44:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.84it/s]\u001b[A\n",
      "Epoch 44:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.06it/s]\u001b[A\n",
      "Epoch 44:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.55it/s]\u001b[A\n",
      "Epoch 44:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.65it/s]\u001b[A\n",
      "Epoch 44:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 44:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 44:  86%|████████▋ | 674/780 [06:11<00:58,  1.81it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.55it/s]\u001b[A\n",
      "Epoch 44:  87%|████████▋ | 676/780 [06:12<00:57,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.40it/s]\u001b[A\n",
      "Epoch 44:  87%|████████▋ | 678/780 [06:12<00:56,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.68it/s]\u001b[A\n",
      "Epoch 44:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 44:  87%|████████▋ | 682/780 [06:13<00:53,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.50it/s]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.53it/s]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 690/780 [06:15<00:48,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.35it/s]\u001b[A\n",
      "Epoch 44:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 44:  89%|████████▉ | 694/780 [06:16<00:46,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.69it/s]\u001b[A\n",
      "Epoch 44:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.44it/s]\u001b[A\n",
      "Epoch 44:  89%|████████▉ | 698/780 [06:16<00:44,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 44:  90%|████████▉ | 700/780 [06:17<00:43,  1.85it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.67it/s]\u001b[A\n",
      "Epoch 44:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 44:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.75it/s]\u001b[A\n",
      "Epoch 44:  91%|█████████ | 706/780 [06:18<00:39,  1.86it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 44:  91%|█████████ | 708/780 [06:19<00:38,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.41it/s]\u001b[A\n",
      "Epoch 44:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.71it/s]\u001b[A\n",
      "Epoch 44:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 714/780 [06:20<00:35,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 716/780 [06:20<00:34,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.62it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.50it/s]\u001b[A\n",
      "Epoch 44:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.31it/s]\u001b[A\n",
      "Epoch 44:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 44:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.63it/s]\u001b[A\n",
      "Epoch 44:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.45it/s]\u001b[A\n",
      "Epoch 44:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.66it/s]\u001b[A\n",
      "Epoch 44:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 44:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 44:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.71it/s]\u001b[A\n",
      "Epoch 44:  95%|█████████▍| 738/780 [06:25<00:21,  1.91it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 44:  95%|█████████▍| 740/780 [06:26<00:20,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.42it/s]\u001b[A\n",
      "Epoch 44:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 44:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 44:  96%|█████████▌| 746/780 [06:27<00:17,  1.92it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 44:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 44:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 44:  96%|█████████▋| 752/780 [06:28<00:14,  1.93it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 44:  97%|█████████▋| 754/780 [06:29<00:13,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 44:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.75it/s]\u001b[A\n",
      "Epoch 44:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.66it/s]\u001b[A\n",
      "Epoch 44:  97%|█████████▋| 760/780 [06:30<00:10,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 44:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.66it/s]\u001b[A\n",
      "Epoch 44:  98%|█████████▊| 764/780 [06:31<00:08,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 44:  98%|█████████▊| 766/780 [06:31<00:07,  1.95it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 44:  98%|█████████▊| 768/780 [06:32<00:06,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 44:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 44:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.50it/s]\u001b[A\n",
      "Epoch 44:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.64it/s]\u001b[A\n",
      "Epoch 44:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  97%|█████████▋| 120/124 [00:26<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 44: 100%|█████████▉| 778/780 [06:34<00:01,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.48it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 780/780 [06:34<00:00,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.453, train_loss_step=0.215, train_loss_epoch=0.222, val_loss_step=0.466]\n",
      "Epoch 44: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.224, v_num=87, val_loss_epoch=0.350, train_loss_step=0.195, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Epoch 45:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.98it/s]\u001b[A\n",
      "Epoch 45:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 45:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.90it/s]\u001b[A\n",
      "Epoch 45:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.05it/s]\u001b[A\n",
      "Epoch 45:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.56it/s]\u001b[A\n",
      "Epoch 45:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.55it/s]\u001b[A\n",
      "Epoch 45:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.37it/s]\u001b[A\n",
      "Epoch 45:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 45:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 45:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.24it/s]\u001b[A\n",
      "Epoch 45:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 45:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 45:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.53it/s]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.40it/s]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 45:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Epoch 45:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:16,  5.28it/s]\u001b[A\n",
      "Epoch 45:  89%|████████▉ | 696/780 [06:12<00:45,  1.87it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.91it/s]\u001b[A\n",
      "Epoch 45:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 45:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 45:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 45:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.41it/s]\u001b[A\n",
      "Epoch 45:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 45:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.55it/s]\u001b[A\n",
      "Epoch 45:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.43it/s]\u001b[A\n",
      "Epoch 45:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.68it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.34it/s]\u001b[A\n",
      "Epoch 45:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.49it/s]\u001b[A\n",
      "Epoch 45:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 45:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 45:  93%|█████████▎| 728/780 [06:20<00:27,  1.92it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.28it/s]\u001b[A\n",
      "Epoch 45:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.66it/s]\u001b[A\n",
      "Epoch 45:  94%|█████████▍| 732/780 [06:21<00:24,  1.92it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.72it/s]\u001b[A\n",
      "Epoch 45:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.45it/s]\u001b[A\n",
      "Epoch 45:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.81it/s]\u001b[A\n",
      "Epoch 45:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.74it/s]\u001b[A\n",
      "Epoch 45:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.35it/s]\u001b[A\n",
      "Epoch 45:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:07,  4.77it/s]\u001b[A\n",
      "Epoch 45:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 45:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.39it/s]\u001b[A\n",
      "Epoch 45:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.76it/s]\u001b[A\n",
      "Epoch 45:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.71it/s]\u001b[A\n",
      "Epoch 45:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 45:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 45:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 45:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 45:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 45:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 45:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 45:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.44it/s]\u001b[A\n",
      "Epoch 45:  98%|█████████▊| 768/780 [06:28<00:06,  1.97it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 45:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 45:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.55it/s]\u001b[A\n",
      "Epoch 45:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.71it/s]\u001b[A\n",
      "Epoch 45:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 45: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.49it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.238, v_num=87, val_loss_epoch=0.350, train_loss_step=0.208, train_loss_epoch=0.229, val_loss_step=0.470]\n",
      "Epoch 45: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.238, v_num=87, val_loss_epoch=0.370, train_loss_step=0.166, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Epoch 46:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.94it/s]\u001b[A\n",
      "Epoch 46:  85%|████████▍ | 660/780 [06:07<01:06,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.19it/s]\u001b[A\n",
      "Epoch 46:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.68it/s]\u001b[A\n",
      "Epoch 46:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 46:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.30it/s]\u001b[A\n",
      "Epoch 46:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.52it/s]\u001b[A\n",
      "Epoch 46:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.27it/s]\u001b[A\n",
      "Epoch 46:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:21,  5.05it/s]\u001b[A\n",
      "Epoch 46:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.71it/s]\u001b[A\n",
      "Epoch 46:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 46:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 46:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:17,  5.80it/s]\u001b[A\n",
      "Epoch 46:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  21%|██        | 26/124 [00:05<00:13,  7.30it/s]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:11,  8.36it/s]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  24%|██▍       | 30/124 [00:06<00:10,  8.97it/s]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  26%|██▌       | 32/124 [00:06<00:09,  9.24it/s]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  27%|██▋       | 34/124 [00:07<00:14,  6.14it/s]\u001b[A\n",
      "Epoch 46:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  29%|██▉       | 36/124 [00:07<00:18,  4.87it/s]\u001b[A\n",
      "Epoch 46:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  31%|███       | 38/124 [00:07<00:17,  4.82it/s]\u001b[A\n",
      "Epoch 46:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  32%|███▏      | 40/124 [00:08<00:17,  4.78it/s]\u001b[A\n",
      "Epoch 46:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  34%|███▍      | 42/124 [00:08<00:19,  4.31it/s]\u001b[A\n",
      "Epoch 46:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  35%|███▌      | 44/124 [00:09<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 46:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  37%|███▋      | 46/124 [00:09<00:17,  4.47it/s]\u001b[A\n",
      "Epoch 46:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  39%|███▊      | 48/124 [00:10<00:17,  4.31it/s]\u001b[A\n",
      "Epoch 46:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  40%|████      | 50/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 46:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  42%|████▏     | 52/124 [00:11<00:15,  4.55it/s]\u001b[A\n",
      "Epoch 46:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  44%|████▎     | 54/124 [00:11<00:15,  4.66it/s]\u001b[A\n",
      "Epoch 46:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  45%|████▌     | 56/124 [00:11<00:15,  4.33it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  47%|████▋     | 58/124 [00:12<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  48%|████▊     | 60/124 [00:12<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  50%|█████     | 62/124 [00:13<00:14,  4.36it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  52%|█████▏    | 64/124 [00:13<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 46:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  53%|█████▎    | 66/124 [00:14<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 46:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  55%|█████▍    | 68/124 [00:14<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 46:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:11,  4.71it/s]\u001b[A\n",
      "Epoch 46:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  58%|█████▊    | 72/124 [00:15<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 46:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  60%|█████▉    | 74/124 [00:15<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 46:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  61%|██████▏   | 76/124 [00:16<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 46:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  63%|██████▎   | 78/124 [00:16<00:09,  4.67it/s]\u001b[A\n",
      "Epoch 46:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  65%|██████▍   | 80/124 [00:17<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 46:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  66%|██████▌   | 82/124 [00:17<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 46:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  68%|██████▊   | 84/124 [00:18<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 46:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  69%|██████▉   | 86/124 [00:18<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 46:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:08,  4.37it/s]\u001b[A\n",
      "Epoch 46:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  73%|███████▎  | 90/124 [00:19<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 46:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  74%|███████▍  | 92/124 [00:19<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 46:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  76%|███████▌  | 94/124 [00:20<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 46:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  77%|███████▋  | 96/124 [00:20<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 46:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  79%|███████▉  | 98/124 [00:21<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 46:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  81%|████████  | 100/124 [00:21<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 46:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  82%|████████▏ | 102/124 [00:22<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 46:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  84%|████████▍ | 104/124 [00:22<00:04,  4.39it/s]\u001b[A\n",
      "Epoch 46:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 46:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  87%|████████▋ | 108/124 [00:23<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 46:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  89%|████████▊ | 110/124 [00:23<00:03,  4.33it/s]\u001b[A\n",
      "Epoch 46:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  90%|█████████ | 112/124 [00:24<00:02,  4.70it/s]\u001b[A\n",
      "Epoch 46:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  92%|█████████▏| 114/124 [00:24<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 46:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  94%|█████████▎| 116/124 [00:25<00:01,  5.26it/s]\u001b[A\n",
      "Epoch 46:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  95%|█████████▌| 118/124 [00:25<00:01,  5.12it/s]\u001b[A\n",
      "Epoch 46:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  97%|█████████▋| 120/124 [00:25<00:00,  4.84it/s]\u001b[A\n",
      "Epoch 46: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Validating:  98%|█████████▊| 122/124 [00:26<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.370, train_loss_step=0.251, train_loss_epoch=0.217, val_loss_step=0.514]\n",
      "Epoch 46: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.409, train_loss_step=0.206, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Epoch 47:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  84%|████████▍ | 658/780 [06:06<01:07,  1.79it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]\u001b[A\n",
      "Epoch 47:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.19it/s]\u001b[A\n",
      "Epoch 47:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.87it/s]\u001b[A\n",
      "Epoch 47:  85%|████████▌ | 664/780 [06:07<01:04,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.07it/s]\u001b[A\n",
      "Epoch 47:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.45it/s]\u001b[A\n",
      "Epoch 47:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.38it/s]\u001b[A\n",
      "Epoch 47:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 47:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.62it/s]\u001b[A\n",
      "Epoch 47:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 47:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 47:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 47:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.33it/s]\u001b[A\n",
      "Epoch 47:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.65it/s]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.79it/s]\u001b[A\n",
      "Epoch 47:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.78it/s]\u001b[A\n",
      "Epoch 47:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 47:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.73it/s]\u001b[A\n",
      "Epoch 47:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 47:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 47:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.71it/s]\u001b[A\n",
      "Epoch 47:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 47:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 47:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.55it/s]\u001b[A\n",
      "Epoch 47:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 47:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.36it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.70it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.48it/s]\u001b[A\n",
      "Epoch 47:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.66it/s]\u001b[A\n",
      "Epoch 47:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.68it/s]\u001b[A\n",
      "Epoch 47:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.40it/s]\u001b[A\n",
      "Epoch 47:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.48it/s]\u001b[A\n",
      "Epoch 47:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 47:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.34it/s]\u001b[A\n",
      "Epoch 47:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 47:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 47:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.24it/s]\u001b[A\n",
      "Epoch 47:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 47:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 47:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.33it/s]\u001b[A\n",
      "Epoch 47:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 47:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 47:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 47:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.31it/s]\u001b[A\n",
      "Epoch 47:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 47:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 47:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.27it/s]\u001b[A\n",
      "Epoch 47:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.52it/s]\u001b[A\n",
      "Epoch 47:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 47:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.40it/s]\u001b[A\n",
      "Epoch 47:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 47:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 47:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.44it/s]\u001b[A\n",
      "Epoch 47:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 47:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.63it/s]\u001b[A\n",
      "Epoch 47:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.41it/s]\u001b[A\n",
      "Epoch 47: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.47it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.409, train_loss_step=0.452, train_loss_epoch=0.215, val_loss_step=0.298]\n",
      "Epoch 47: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.437, train_loss_step=0.224, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Epoch 48:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.88it/s]\u001b[A\n",
      "Epoch 48:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.26it/s]\u001b[A\n",
      "Epoch 48:  85%|████████▍ | 662/780 [06:04<01:05,  1.81it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.86it/s]\u001b[A\n",
      "Epoch 48:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 48:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.50it/s]\u001b[A\n",
      "Epoch 48:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.34it/s]\u001b[A\n",
      "Epoch 48:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 48:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.52it/s]\u001b[A\n",
      "Epoch 48:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 48:  87%|████████▋ | 676/780 [06:08<00:56,  1.84it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 48:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 48:  87%|████████▋ | 680/780 [06:08<00:54,  1.84it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 48:  87%|████████▋ | 682/780 [06:09<00:53,  1.85it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.76it/s]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 688/780 [06:10<00:49,  1.86it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.64it/s]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.41it/s]\u001b[A\n",
      "Epoch 48:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.75it/s]\u001b[A\n",
      "Epoch 48:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.47it/s]\u001b[A\n",
      "Epoch 48:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 48:  89%|████████▉ | 698/780 [06:12<00:43,  1.87it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 48:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 48:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 48:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 48:  91%|█████████ | 706/780 [06:14<00:39,  1.88it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 48:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.57it/s]\u001b[A\n",
      "Epoch 48:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.28it/s]\u001b[A\n",
      "Epoch 48:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:15,  4.22it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 48:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.32it/s]\u001b[A\n",
      "Epoch 48:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.37it/s]\u001b[A\n",
      "Epoch 48:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.44it/s]\u001b[A\n",
      "Epoch 48:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.43it/s]\u001b[A\n",
      "Epoch 48:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 48:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 48:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 48:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 48:  95%|█████████▍| 738/780 [06:21<00:21,  1.93it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 48:  95%|█████████▍| 740/780 [06:22<00:20,  1.94it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 48:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.66it/s]\u001b[A\n",
      "Epoch 48:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.72it/s]\u001b[A\n",
      "Epoch 48:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 48:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 48:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 48:  96%|█████████▋| 752/780 [06:24<00:14,  1.95it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.30it/s]\u001b[A\n",
      "Epoch 48:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 48:  97%|█████████▋| 756/780 [06:25<00:12,  1.96it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.47it/s]\u001b[A\n",
      "Epoch 48:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 48:  97%|█████████▋| 760/780 [06:26<00:10,  1.97it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 48:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 48:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 48:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.38it/s]\u001b[A\n",
      "Epoch 48:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.72it/s]\u001b[A\n",
      "Epoch 48:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.63it/s]\u001b[A\n",
      "Epoch 48:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 48:  99%|█████████▉| 774/780 [06:29<00:03,  1.99it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 48:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 48: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.27it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.191, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0927, train_loss_epoch=0.217, val_loss_step=0.211]\n",
      "Epoch 48: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.191, v_num=87, val_loss_epoch=0.345, train_loss_step=0.0983, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Epoch 49:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.86it/s]\u001b[A\n",
      "Epoch 49:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.15it/s]\u001b[A\n",
      "Epoch 49:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.62it/s]\u001b[A\n",
      "Epoch 49:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 49:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.39it/s]\u001b[A\n",
      "Epoch 49:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 49:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 49:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.37it/s]\u001b[A\n",
      "Epoch 49:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.57it/s]\u001b[A\n",
      "Epoch 49:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 49:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 49:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.68it/s]\u001b[A\n",
      "Epoch 49:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.32it/s]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.70it/s]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.67it/s]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.79it/s]\u001b[A\n",
      "Epoch 49:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 49:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.34it/s]\u001b[A\n",
      "Epoch 49:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.46it/s]\u001b[A\n",
      "Epoch 49:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:19,  4.31it/s]\u001b[A\n",
      "Epoch 49:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.37it/s]\u001b[A\n",
      "Epoch 49:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:18,  4.19it/s]\u001b[A\n",
      "Epoch 49:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.40it/s]\u001b[A\n",
      "Epoch 49:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.48it/s]\u001b[A\n",
      "Epoch 49:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.25it/s]\u001b[A\n",
      "Epoch 49:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.39it/s]\u001b[A\n",
      "Epoch 49:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.68it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.70it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.42it/s]\u001b[A\n",
      "Epoch 49:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.65it/s]\u001b[A\n",
      "Epoch 49:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.55it/s]\u001b[A\n",
      "Epoch 49:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.40it/s]\u001b[A\n",
      "Epoch 49:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 49:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 49:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 49:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 49:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 49:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.54it/s]\u001b[A\n",
      "Epoch 49:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.38it/s]\u001b[A\n",
      "Epoch 49:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 49:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.64it/s]\u001b[A\n",
      "Epoch 49:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.27it/s]\u001b[A\n",
      "Epoch 49:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 49:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.37it/s]\u001b[A\n",
      "Epoch 49:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 49:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 49:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 49:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 49:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 49:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 49:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.47it/s]\u001b[A\n",
      "Epoch 49:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 49:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 49:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.29it/s]\u001b[A\n",
      "Epoch 49:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 49:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 49:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.33it/s]\u001b[A\n",
      "Epoch 49: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.241, v_num=87, val_loss_epoch=0.345, train_loss_step=0.171, train_loss_epoch=0.211, val_loss_step=0.414]\n",
      "Epoch 49: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.241, v_num=87, val_loss_epoch=0.355, train_loss_step=0.214, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Epoch 50:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:58,  2.09it/s]\u001b[A\n",
      "Epoch 50:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.22it/s]\u001b[A\n",
      "Epoch 50:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.91it/s]\u001b[A\n",
      "Epoch 50:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.20it/s]\u001b[A\n",
      "Epoch 50:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 50:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.45it/s]\u001b[A\n",
      "Epoch 50:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.40it/s]\u001b[A\n",
      "Epoch 50:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 50:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.51it/s]\u001b[A\n",
      "Epoch 50:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 50:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 50:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.43it/s]\u001b[A\n",
      "Epoch 50:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.67it/s]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.52it/s]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.65it/s]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 50:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.69it/s]\u001b[A\n",
      "Epoch 50:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.77it/s]\u001b[A\n",
      "Epoch 50:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 50:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.69it/s]\u001b[A\n",
      "Epoch 50:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 50:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.36it/s]\u001b[A\n",
      "Epoch 50:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 50:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 50:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 50:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 50:  91%|█████████▏| 712/780 [06:16<00:36,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.35it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 50:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.32it/s]\u001b[A\n",
      "Epoch 50:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 50:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.59it/s]\u001b[A\n",
      "Epoch 50:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.30it/s]\u001b[A\n",
      "Epoch 50:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.45it/s]\u001b[A\n",
      "Epoch 50:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 50:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.31it/s]\u001b[A\n",
      "Epoch 50:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.71it/s]\u001b[A\n",
      "Epoch 50:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.88it/s]\u001b[A\n",
      "Epoch 50:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.80it/s]\u001b[A\n",
      "Epoch 50:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 50:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 50:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.64it/s]\u001b[A\n",
      "Epoch 50:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.32it/s]\u001b[A\n",
      "Epoch 50:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.54it/s]\u001b[A\n",
      "Epoch 50:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 50:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.30it/s]\u001b[A\n",
      "Epoch 50:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.51it/s]\u001b[A\n",
      "Epoch 50:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 50:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 50:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 50:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 50:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 50:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.54it/s]\u001b[A\n",
      "Epoch 50:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.56it/s]\u001b[A\n",
      "Epoch 50:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 50:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.23it/s]\u001b[A\n",
      "Epoch 50:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 50: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 50: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.187, v_num=87, val_loss_epoch=0.355, train_loss_step=0.116, train_loss_epoch=0.216, val_loss_step=0.428]\n",
      "Epoch 50: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.187, v_num=87, val_loss_epoch=0.374, train_loss_step=0.0773, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Epoch 51:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  84%|████████▍ | 658/780 [06:08<01:08,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 51:  85%|████████▍ | 660/780 [06:08<01:07,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.18it/s]\u001b[A\n",
      "Epoch 51:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.65it/s]\u001b[A\n",
      "Epoch 51:  85%|████████▌ | 664/780 [06:09<01:04,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.08it/s]\u001b[A\n",
      "Epoch 51:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 51:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.32it/s]\u001b[A\n",
      "Epoch 51:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 51:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 51:  86%|████████▋ | 674/780 [06:11<00:58,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 51:  87%|████████▋ | 676/780 [06:12<00:57,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.69it/s]\u001b[A\n",
      "Epoch 51:  87%|████████▋ | 678/780 [06:12<00:56,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 51:  87%|████████▋ | 680/780 [06:12<00:54,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 51:  87%|████████▋ | 682/780 [06:13<00:53,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.61it/s]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.73it/s]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 690/780 [06:15<00:48,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.89it/s]\u001b[A\n",
      "Epoch 51:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.76it/s]\u001b[A\n",
      "Epoch 51:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 51:  89%|████████▉ | 696/780 [06:16<00:45,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 51:  89%|████████▉ | 698/780 [06:16<00:44,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 51:  90%|████████▉ | 700/780 [06:17<00:43,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.27it/s]\u001b[A\n",
      "Epoch 51:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 51:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 51:  91%|█████████ | 706/780 [06:18<00:39,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.32it/s]\u001b[A\n",
      "Epoch 51:  91%|█████████ | 708/780 [06:19<00:38,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 51:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 51:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:15,  4.45it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 714/780 [06:20<00:35,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 716/780 [06:20<00:34,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.63it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 718/780 [06:21<00:32,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.50it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 51:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.52it/s]\u001b[A\n",
      "Epoch 51:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 51:  93%|█████████▎| 726/780 [06:23<00:28,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.40it/s]\u001b[A\n",
      "Epoch 51:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 51:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 51:  94%|█████████▍| 732/780 [06:24<00:25,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 51:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 51:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 51:  95%|█████████▍| 738/780 [06:25<00:21,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 51:  95%|█████████▍| 740/780 [06:26<00:20,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 51:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.56it/s]\u001b[A\n",
      "Epoch 51:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.44it/s]\u001b[A\n",
      "Epoch 51:  96%|█████████▌| 746/780 [06:27<00:17,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 51:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.28it/s]\u001b[A\n",
      "Epoch 51:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.46it/s]\u001b[A\n",
      "Epoch 51:  96%|█████████▋| 752/780 [06:28<00:14,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.40it/s]\u001b[A\n",
      "Epoch 51:  97%|█████████▋| 754/780 [06:29<00:13,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 51:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 51:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 51:  97%|█████████▋| 760/780 [06:30<00:10,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 51:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.36it/s]\u001b[A\n",
      "Epoch 51:  98%|█████████▊| 764/780 [06:31<00:08,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 51:  98%|█████████▊| 766/780 [06:31<00:07,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 51:  98%|█████████▊| 768/780 [06:32<00:06,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.32it/s]\u001b[A\n",
      "Epoch 51:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 51:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.67it/s]\u001b[A\n",
      "Epoch 51:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.31it/s]\u001b[A\n",
      "Epoch 51:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.51it/s]\u001b[A\n",
      "Epoch 51: 100%|█████████▉| 778/780 [06:34<00:01,  1.97it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 51: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.192, v_num=87, val_loss_epoch=0.374, train_loss_step=0.103, train_loss_epoch=0.210, val_loss_step=0.311]\n",
      "Epoch 51: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.192, v_num=87, val_loss_epoch=0.377, train_loss_step=0.0981, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Epoch 52:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.83it/s]\u001b[A\n",
      "Epoch 52:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.11it/s]\u001b[A\n",
      "Epoch 52:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:29,  3.95it/s]\u001b[A\n",
      "Epoch 52:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.26it/s]\u001b[A\n",
      "Epoch 52:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 52:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.64it/s]\u001b[A\n",
      "Epoch 52:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 52:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.31it/s]\u001b[A\n",
      "Epoch 52:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.52it/s]\u001b[A\n",
      "Epoch 52:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:20,  5.04it/s]\u001b[A\n",
      "Epoch 52:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.69it/s]\u001b[A\n",
      "Epoch 52:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.44it/s]\u001b[A\n",
      "Epoch 52:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 52:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 52:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.48it/s]\u001b[A\n",
      "Epoch 52:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 52:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 52:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 52:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 52:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 52:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 52:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 52:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.33it/s]\u001b[A\n",
      "Epoch 52:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.62it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 52:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.22it/s]\u001b[A\n",
      "Epoch 52:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 52:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.43it/s]\u001b[A\n",
      "Epoch 52:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 52:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.26it/s]\u001b[A\n",
      "Epoch 52:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 52:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.51it/s]\u001b[A\n",
      "Epoch 52:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.31it/s]\u001b[A\n",
      "Epoch 52:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 52:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 52:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.40it/s]\u001b[A\n",
      "Epoch 52:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 52:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 52:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 52:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 52:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 52:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.42it/s]\u001b[A\n",
      "Epoch 52:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 52:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 52:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.61it/s]\u001b[A\n",
      "Epoch 52:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 52:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 52:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 52:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.49it/s]\u001b[A\n",
      "Epoch 52:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.57it/s]\u001b[A\n",
      "Epoch 52:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.32it/s]\u001b[A\n",
      "Epoch 52:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.77it/s]\u001b[A\n",
      "Epoch 52:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.72it/s]\u001b[A\n",
      "Epoch 52: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.31it/s]\u001b[A\n",
      "Epoch 52: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.209, v_num=87, val_loss_epoch=0.377, train_loss_step=0.163, train_loss_epoch=0.210, val_loss_step=0.290]\n",
      "Epoch 52: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.209, v_num=87, val_loss_epoch=0.378, train_loss_step=0.142, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Epoch 53:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.96it/s]\u001b[A\n",
      "Epoch 53:  85%|████████▍ | 660/780 [06:03<01:06,  1.81it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.21it/s]\u001b[A\n",
      "Epoch 53:  85%|████████▍ | 662/780 [06:04<01:04,  1.82it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.64it/s]\u001b[A\n",
      "Epoch 53:  85%|████████▌ | 664/780 [06:04<01:03,  1.82it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.23it/s]\u001b[A\n",
      "Epoch 53:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.41it/s]\u001b[A\n",
      "Epoch 53:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.27it/s]\u001b[A\n",
      "Epoch 53:  86%|████████▌ | 670/780 [06:05<01:00,  1.83it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 53:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.53it/s]\u001b[A\n",
      "Epoch 53:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 53:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.27it/s]\u001b[A\n",
      "Epoch 53:  87%|████████▋ | 678/780 [06:07<00:55,  1.84it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 53:  87%|████████▋ | 680/780 [06:08<00:54,  1.85it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.42it/s]\u001b[A\n",
      "Epoch 53:  87%|████████▋ | 682/780 [06:08<00:52,  1.85it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.30it/s]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.62it/s]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 686/780 [06:09<00:50,  1.86it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.53it/s]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 688/780 [06:10<00:49,  1.86it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.35it/s]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.52it/s]\u001b[A\n",
      "Epoch 53:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 53:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 53:  89%|████████▉ | 696/780 [06:11<00:44,  1.87it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 53:  89%|████████▉ | 698/780 [06:12<00:43,  1.88it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.45it/s]\u001b[A\n",
      "Epoch 53:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.65it/s]\u001b[A\n",
      "Epoch 53:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 53:  90%|█████████ | 704/780 [06:13<00:40,  1.88it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 53:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 53:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 53:  91%|█████████ | 710/780 [06:14<00:36,  1.89it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 53:  91%|█████████▏| 712/780 [06:15<00:35,  1.90it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.44it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 718/780 [06:16<00:32,  1.91it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 53:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.53it/s]\u001b[A\n",
      "Epoch 53:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 53:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 53:  93%|█████████▎| 728/780 [06:18<00:27,  1.92it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 53:  94%|█████████▎| 730/780 [06:19<00:25,  1.92it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.28it/s]\u001b[A\n",
      "Epoch 53:  94%|█████████▍| 732/780 [06:19<00:24,  1.93it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 53:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.50it/s]\u001b[A\n",
      "Epoch 53:  94%|█████████▍| 736/780 [06:20<00:22,  1.93it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 53:  95%|█████████▍| 738/780 [06:21<00:21,  1.94it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.28it/s]\u001b[A\n",
      "Epoch 53:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 53:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 53:  95%|█████████▌| 744/780 [06:22<00:18,  1.95it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.31it/s]\u001b[A\n",
      "Epoch 53:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.82it/s]\u001b[A\n",
      "Epoch 53:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:05,  5.34it/s]\u001b[A\n",
      "Epoch 53:  96%|█████████▌| 750/780 [06:23<00:15,  1.96it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.94it/s]\u001b[A\n",
      "Epoch 53:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.46it/s]\u001b[A\n",
      "Epoch 53:  97%|█████████▋| 754/780 [06:24<00:13,  1.96it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 53:  97%|█████████▋| 756/780 [06:24<00:12,  1.96it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 53:  97%|█████████▋| 758/780 [06:25<00:11,  1.97it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.49it/s]\u001b[A\n",
      "Epoch 53:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.73it/s]\u001b[A\n",
      "Epoch 53:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 53:  98%|█████████▊| 764/780 [06:26<00:08,  1.98it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.42it/s]\u001b[A\n",
      "Epoch 53:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.67it/s]\u001b[A\n",
      "Epoch 53:  98%|█████████▊| 768/780 [06:27<00:06,  1.98it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.57it/s]\u001b[A\n",
      "Epoch 53:  99%|█████████▊| 770/780 [06:27<00:05,  1.98it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 53:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.33it/s]\u001b[A\n",
      "Epoch 53:  99%|█████████▉| 774/780 [06:28<00:03,  1.99it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 53:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.71it/s]\u001b[A\n",
      "Epoch 53: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 53: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.211, v_num=87, val_loss_epoch=0.378, train_loss_step=0.189, train_loss_epoch=0.209, val_loss_step=0.208]\n",
      "Epoch 53: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.211, v_num=87, val_loss_epoch=0.346, train_loss_step=0.065, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Epoch 54:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.06it/s]\u001b[A\n",
      "Epoch 54:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.15it/s]\u001b[A\n",
      "Epoch 54:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  3.99it/s]\u001b[A\n",
      "Epoch 54:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.28it/s]\u001b[A\n",
      "Epoch 54:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.23it/s]\u001b[A\n",
      "Epoch 54:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.61it/s]\u001b[A\n",
      "Epoch 54:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 54:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.44it/s]\u001b[A\n",
      "Epoch 54:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 54:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 54:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 54:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 54:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.50it/s]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.32it/s]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 54:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 54:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 54:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 54:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.41it/s]\u001b[A\n",
      "Epoch 54:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.53it/s]\u001b[A\n",
      "Epoch 54:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.42it/s]\u001b[A\n",
      "Epoch 54:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.66it/s]\u001b[A\n",
      "Epoch 54:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.79it/s]\u001b[A\n",
      "Epoch 54:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.35it/s]\u001b[A\n",
      "Epoch 54:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.74it/s]\u001b[A\n",
      "Epoch 54:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.64it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.67it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 54:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 54:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 54:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.59it/s]\u001b[A\n",
      "Epoch 54:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.27it/s]\u001b[A\n",
      "Epoch 54:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.73it/s]\u001b[A\n",
      "Epoch 54:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.67it/s]\u001b[A\n",
      "Epoch 54:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.37it/s]\u001b[A\n",
      "Epoch 54:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 54:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.65it/s]\u001b[A\n",
      "Epoch 54:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 54:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.43it/s]\u001b[A\n",
      "Epoch 54:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 54:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 54:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.34it/s]\u001b[A\n",
      "Epoch 54:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.37it/s]\u001b[A\n",
      "Epoch 54:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 54:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.26it/s]\u001b[A\n",
      "Epoch 54:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.42it/s]\u001b[A\n",
      "Epoch 54:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 54:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.39it/s]\u001b[A\n",
      "Epoch 54:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 54:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 54:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.39it/s]\u001b[A\n",
      "Epoch 54:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 54:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 54:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.43it/s]\u001b[A\n",
      "Epoch 54:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.46it/s]\u001b[A\n",
      "Epoch 54:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.46it/s]\u001b[A\n",
      "Epoch 54: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.53it/s]\u001b[A\n",
      "Epoch 54: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.346, train_loss_step=0.286, train_loss_epoch=0.210, val_loss_step=0.609]\n",
      "Epoch 54: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.391, train_loss_step=0.093, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Epoch 55:  84%|████████▍ | 656/780 [06:08<01:09,  1.78it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  84%|████████▍ | 658/780 [06:10<01:08,  1.78it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.01it/s]\u001b[A\n",
      "Epoch 55:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 55:  85%|████████▍ | 662/780 [06:10<01:06,  1.78it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.90it/s]\u001b[A\n",
      "Epoch 55:  85%|████████▌ | 664/780 [06:11<01:04,  1.79it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.20it/s]\u001b[A\n",
      "Epoch 55:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 55:  86%|████████▌ | 668/780 [06:12<01:02,  1.79it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 55:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 55:  86%|████████▌ | 672/780 [06:13<00:59,  1.80it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 55:  86%|████████▋ | 674/780 [06:13<00:58,  1.80it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 55:  87%|████████▋ | 676/780 [06:14<00:57,  1.81it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.61it/s]\u001b[A\n",
      "Epoch 55:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 55:  87%|████████▋ | 680/780 [06:14<00:55,  1.81it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 55:  87%|████████▋ | 682/780 [06:15<00:53,  1.82it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 686/780 [06:16<00:51,  1.82it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.39it/s]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 690/780 [06:17<00:49,  1.83it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.54it/s]\u001b[A\n",
      "Epoch 55:  89%|████████▊ | 692/780 [06:17<00:48,  1.83it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 55:  89%|████████▉ | 694/780 [06:18<00:46,  1.84it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 55:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.47it/s]\u001b[A\n",
      "Epoch 55:  89%|████████▉ | 698/780 [06:19<00:44,  1.84it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.60it/s]\u001b[A\n",
      "Epoch 55:  90%|████████▉ | 700/780 [06:19<00:43,  1.84it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.65it/s]\u001b[A\n",
      "Epoch 55:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.39it/s]\u001b[A\n",
      "Epoch 55:  90%|█████████ | 704/780 [06:20<00:41,  1.85it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 55:  91%|█████████ | 706/780 [06:20<00:39,  1.85it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 55:  91%|█████████ | 708/780 [06:21<00:38,  1.86it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.35it/s]\u001b[A\n",
      "Epoch 55:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 55:  91%|█████████▏| 712/780 [06:22<00:36,  1.86it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.33it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.52it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.48it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 720/780 [06:23<00:31,  1.88it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 55:  93%|█████████▎| 722/780 [06:24<00:30,  1.88it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.25it/s]\u001b[A\n",
      "Epoch 55:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 55:  93%|█████████▎| 726/780 [06:25<00:28,  1.88it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 55:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.28it/s]\u001b[A\n",
      "Epoch 55:  94%|█████████▎| 730/780 [06:26<00:26,  1.89it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 55:  94%|█████████▍| 732/780 [06:26<00:25,  1.89it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 55:  94%|█████████▍| 734/780 [06:27<00:24,  1.90it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 55:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 55:  95%|█████████▍| 738/780 [06:27<00:22,  1.90it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 55:  95%|█████████▍| 740/780 [06:28<00:20,  1.91it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.38it/s]\u001b[A\n",
      "Epoch 55:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.57it/s]\u001b[A\n",
      "Epoch 55:  95%|█████████▌| 744/780 [06:29<00:18,  1.91it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 55:  96%|█████████▌| 746/780 [06:29<00:17,  1.91it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 55:  96%|█████████▌| 748/780 [06:30<00:16,  1.92it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 55:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 55:  96%|█████████▋| 752/780 [06:31<00:14,  1.92it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 55:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.44it/s]\u001b[A\n",
      "Epoch 55:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 55:  97%|█████████▋| 758/780 [06:32<00:11,  1.93it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 55:  97%|█████████▋| 760/780 [06:32<00:10,  1.93it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 55:  98%|█████████▊| 762/780 [06:33<00:09,  1.94it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 55:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.47it/s]\u001b[A\n",
      "Epoch 55:  98%|█████████▊| 766/780 [06:34<00:07,  1.94it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.71it/s]\u001b[A\n",
      "Epoch 55:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 55:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.36it/s]\u001b[A\n",
      "Epoch 55:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.77it/s]\u001b[A\n",
      "Epoch 55:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.72it/s]\u001b[A\n",
      "Epoch 55:  99%|█████████▉| 776/780 [06:36<00:02,  1.96it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.35it/s]\u001b[A\n",
      "Epoch 55: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 55: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.206, v_num=87, val_loss_epoch=0.391, train_loss_step=0.122, train_loss_epoch=0.206, val_loss_step=0.313]\n",
      "Epoch 55: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.206, v_num=87, val_loss_epoch=0.451, train_loss_step=0.163, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Epoch 56:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 56:  85%|████████▍ | 660/780 [06:03<01:06,  1.81it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.20it/s]\u001b[A\n",
      "Epoch 56:  85%|████████▍ | 662/780 [06:04<01:04,  1.82it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.88it/s]\u001b[A\n",
      "Epoch 56:  85%|████████▌ | 664/780 [06:04<01:03,  1.82it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 56:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.13it/s]\u001b[A\n",
      "Epoch 56:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.63it/s]\u001b[A\n",
      "Epoch 56:  86%|████████▌ | 670/780 [06:05<01:00,  1.83it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 56:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 56:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 56:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.34it/s]\u001b[A\n",
      "Epoch 56:  87%|████████▋ | 678/780 [06:07<00:55,  1.84it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.50it/s]\u001b[A\n",
      "Epoch 56:  87%|████████▋ | 680/780 [06:08<00:54,  1.85it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.32it/s]\u001b[A\n",
      "Epoch 56:  87%|████████▋ | 682/780 [06:08<00:52,  1.85it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.61it/s]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 686/780 [06:09<00:50,  1.86it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.40it/s]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 688/780 [06:09<00:49,  1.86it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.70it/s]\u001b[A\n",
      "Epoch 56:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.33it/s]\u001b[A\n",
      "Epoch 56:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 56:  89%|████████▉ | 696/780 [06:11<00:44,  1.87it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.60it/s]\u001b[A\n",
      "Epoch 56:  89%|████████▉ | 698/780 [06:12<00:43,  1.88it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:19,  4.31it/s]\u001b[A\n",
      "Epoch 56:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 56:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.53it/s]\u001b[A\n",
      "Epoch 56:  90%|█████████ | 704/780 [06:13<00:40,  1.88it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 56:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.37it/s]\u001b[A\n",
      "Epoch 56:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 56:  91%|█████████ | 710/780 [06:14<00:36,  1.89it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 56:  91%|█████████▏| 712/780 [06:15<00:35,  1.90it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.28it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 718/780 [06:16<00:32,  1.91it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.69it/s]\u001b[A\n",
      "Epoch 56:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 56:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.43it/s]\u001b[A\n",
      "Epoch 56:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 56:  93%|█████████▎| 728/780 [06:18<00:27,  1.92it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.63it/s]\u001b[A\n",
      "Epoch 56:  94%|█████████▎| 730/780 [06:19<00:25,  1.92it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 56:  94%|█████████▍| 732/780 [06:19<00:24,  1.93it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.76it/s]\u001b[A\n",
      "Epoch 56:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 56:  94%|█████████▍| 736/780 [06:20<00:22,  1.93it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 56:  95%|█████████▍| 738/780 [06:20<00:21,  1.94it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 56:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 56:  95%|█████████▌| 742/780 [06:21<00:19,  1.94it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 56:  95%|█████████▌| 744/780 [06:22<00:18,  1.95it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.37it/s]\u001b[A\n",
      "Epoch 56:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 56:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 56:  96%|█████████▌| 750/780 [06:23<00:15,  1.95it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 56:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 56:  97%|█████████▋| 754/780 [06:24<00:13,  1.96it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 56:  97%|█████████▋| 756/780 [06:24<00:12,  1.96it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.44it/s]\u001b[A\n",
      "Epoch 56:  97%|█████████▋| 758/780 [06:25<00:11,  1.97it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.61it/s]\u001b[A\n",
      "Epoch 56:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 56:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 56:  98%|█████████▊| 764/780 [06:26<00:08,  1.98it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 56:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 56:  98%|█████████▊| 768/780 [06:27<00:06,  1.98it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 56:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.48it/s]\u001b[A\n",
      "Epoch 56:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.68it/s]\u001b[A\n",
      "Epoch 56:  99%|█████████▉| 774/780 [06:28<00:03,  1.99it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 56:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.38it/s]\u001b[A\n",
      "Epoch 56: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 56: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.184, v_num=87, val_loss_epoch=0.451, train_loss_step=0.120, train_loss_epoch=0.202, val_loss_step=0.701]\n",
      "Epoch 56: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.184, v_num=87, val_loss_epoch=0.415, train_loss_step=0.242, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Epoch 57:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 57:  85%|████████▍ | 660/780 [06:07<01:06,  1.79it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 57:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.87it/s]\u001b[A\n",
      "Epoch 57:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  4.00it/s]\u001b[A\n",
      "Epoch 57:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.51it/s]\u001b[A\n",
      "Epoch 57:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 57:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.26it/s]\u001b[A\n",
      "Epoch 57:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.48it/s]\u001b[A\n",
      "Epoch 57:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.57it/s]\u001b[A\n",
      "Epoch 57:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.38it/s]\u001b[A\n",
      "Epoch 57:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 57:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.67it/s]\u001b[A\n",
      "Epoch 57:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.74it/s]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.40it/s]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:19,  4.78it/s]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 688/780 [06:13<00:50,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.64it/s]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 57:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 57:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 57:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.32it/s]\u001b[A\n",
      "Epoch 57:  89%|████████▉ | 698/780 [06:16<00:44,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.48it/s]\u001b[A\n",
      "Epoch 57:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 57:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.35it/s]\u001b[A\n",
      "Epoch 57:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 57:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 57:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.40it/s]\u001b[A\n",
      "Epoch 57:  91%|█████████ | 710/780 [06:18<00:37,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.42it/s]\u001b[A\n",
      "Epoch 57:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 716/780 [06:20<00:33,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 57:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 57:  93%|█████████▎| 724/780 [06:22<00:29,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 57:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 57:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.43it/s]\u001b[A\n",
      "Epoch 57:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 57:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.21it/s]\u001b[A\n",
      "Epoch 57:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 57:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 57:  95%|█████████▍| 738/780 [06:25<00:21,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.35it/s]\u001b[A\n",
      "Epoch 57:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 57:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.67it/s]\u001b[A\n",
      "Epoch 57:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.66it/s]\u001b[A\n",
      "Epoch 57:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.39it/s]\u001b[A\n",
      "Epoch 57:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.82it/s]\u001b[A\n",
      "Epoch 57:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.70it/s]\u001b[A\n",
      "Epoch 57:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.31it/s]\u001b[A\n",
      "Epoch 57:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.51it/s]\u001b[A\n",
      "Epoch 57:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 57:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.30it/s]\u001b[A\n",
      "Epoch 57:  97%|█████████▋| 760/780 [06:30<00:10,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 57:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 57:  98%|█████████▊| 764/780 [06:30<00:08,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.34it/s]\u001b[A\n",
      "Epoch 57:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 57:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 57:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 57:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.68it/s]\u001b[A\n",
      "Epoch 57:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.55it/s]\u001b[A\n",
      "Epoch 57:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 57: 100%|█████████▉| 778/780 [06:33<00:01,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.37it/s]\u001b[A\n",
      "Epoch 57: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.202, v_num=87, val_loss_epoch=0.415, train_loss_step=0.304, train_loss_epoch=0.199, val_loss_step=0.312]\n",
      "Epoch 57: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.202, v_num=87, val_loss_epoch=0.376, train_loss_step=0.290, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Epoch 58:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.03it/s]\u001b[A\n",
      "Epoch 58:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.25it/s]\u001b[A\n",
      "Epoch 58:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.65it/s]\u001b[A\n",
      "Epoch 58:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.17it/s]\u001b[A\n",
      "Epoch 58:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 58:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.24it/s]\u001b[A\n",
      "Epoch 58:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 58:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.53it/s]\u001b[A\n",
      "Epoch 58:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.31it/s]\u001b[A\n",
      "Epoch 58:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 58:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 58:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 58:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.50it/s]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.28it/s]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 58:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.48it/s]\u001b[A\n",
      "Epoch 58:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 58:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.66it/s]\u001b[A\n",
      "Epoch 58:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 58:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.36it/s]\u001b[A\n",
      "Epoch 58:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.49it/s]\u001b[A\n",
      "Epoch 58:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 58:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.40it/s]\u001b[A\n",
      "Epoch 58:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 58:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 58:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.38it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.50it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.39it/s]\u001b[A\n",
      "Epoch 58:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 58:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.46it/s]\u001b[A\n",
      "Epoch 58:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 58:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  4.76it/s]\u001b[A\n",
      "Epoch 58:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 58:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.46it/s]\u001b[A\n",
      "Epoch 58:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.53it/s]\u001b[A\n",
      "Epoch 58:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.25it/s]\u001b[A\n",
      "Epoch 58:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 58:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 58:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.35it/s]\u001b[A\n",
      "Epoch 58:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 58:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 58:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 58:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 58:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 58:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 58:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 58:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.57it/s]\u001b[A\n",
      "Epoch 58:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 58:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.40it/s]\u001b[A\n",
      "Epoch 58:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.46it/s]\u001b[A\n",
      "Epoch 58:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.59it/s]\u001b[A\n",
      "Epoch 58:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.43it/s]\u001b[A\n",
      "Epoch 58:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 58:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 58:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 58:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.51it/s]\u001b[A\n",
      "Epoch 58: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 58: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.376, train_loss_step=0.205, train_loss_epoch=0.199, val_loss_step=0.244]\n",
      "Epoch 58: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.484, train_loss_step=0.191, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Epoch 59:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.82it/s]\u001b[A\n",
      "Epoch 59:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.10it/s]\u001b[A\n",
      "Epoch 59:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.85it/s]\u001b[A\n",
      "Epoch 59:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.01it/s]\u001b[A\n",
      "Epoch 59:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 59:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.58it/s]\u001b[A\n",
      "Epoch 59:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.32it/s]\u001b[A\n",
      "Epoch 59:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.47it/s]\u001b[A\n",
      "Epoch 59:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 59:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.38it/s]\u001b[A\n",
      "Epoch 59:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 59:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 59:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 59:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 59:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 59:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 59:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.43it/s]\u001b[A\n",
      "Epoch 59:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 59:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 59:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.32it/s]\u001b[A\n",
      "Epoch 59:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 59:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.44it/s]\u001b[A\n",
      "Epoch 59:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 59:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 59:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 59:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.39it/s]\u001b[A\n",
      "Epoch 59:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.51it/s]\u001b[A\n",
      "Epoch 59:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.30it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.54it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:14,  4.24it/s]\u001b[A\n",
      "Epoch 59:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 59:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 59:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.36it/s]\u001b[A\n",
      "Epoch 59:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 59:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 59:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 59:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.53it/s]\u001b[A\n",
      "Epoch 59:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 59:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.45it/s]\u001b[A\n",
      "Epoch 59:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.57it/s]\u001b[A\n",
      "Epoch 59:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 59:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.44it/s]\u001b[A\n",
      "Epoch 59:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 59:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.65it/s]\u001b[A\n",
      "Epoch 59:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 59:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 59:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 59:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 59:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 59:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.71it/s]\u001b[A\n",
      "Epoch 59:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.71it/s]\u001b[A\n",
      "Epoch 59:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.42it/s]\u001b[A\n",
      "Epoch 59:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 59:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.56it/s]\u001b[A\n",
      "Epoch 59:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 59:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 59:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.60it/s]\u001b[A\n",
      "Epoch 59:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.47it/s]\u001b[A\n",
      "Epoch 59: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 59: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.484, train_loss_step=0.193, train_loss_epoch=0.201, val_loss_step=0.432]\n",
      "Epoch 59: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.228, v_num=87, val_loss_epoch=0.430, train_loss_step=0.291, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Epoch 60:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  84%|████████▍ | 658/780 [06:06<01:08,  1.79it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  2.00it/s]\u001b[A\n",
      "Epoch 60:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.02it/s]\u001b[A\n",
      "Epoch 60:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.78it/s]\u001b[A\n",
      "Epoch 60:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 60:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 60:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 60:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.46it/s]\u001b[A\n",
      "Epoch 60:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 60:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 60:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 60:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 60:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 60:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 60:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 60:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.40it/s]\u001b[A\n",
      "Epoch 60:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.80it/s]\u001b[A\n",
      "Epoch 60:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 60:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 60:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 60:  89%|████████▉ | 696/780 [06:15<00:45,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 60:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.44it/s]\u001b[A\n",
      "Epoch 60:  90%|████████▉ | 700/780 [06:16<00:42,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 60:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 60:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 60:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.39it/s]\u001b[A\n",
      "Epoch 60:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 60:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 60:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.45it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.63it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.51it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 60:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.52it/s]\u001b[A\n",
      "Epoch 60:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 60:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:09,  5.60it/s]\u001b[A\n",
      "Epoch 60:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  5.11it/s]\u001b[A\n",
      "Epoch 60:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 60:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 60:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 60:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 60:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 60:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 60:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 60:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:08,  4.43it/s]\u001b[A\n",
      "Epoch 60:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.74it/s]\u001b[A\n",
      "Epoch 60:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.78it/s]\u001b[A\n",
      "Epoch 60:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 60:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.67it/s]\u001b[A\n",
      "Epoch 60:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 60:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.34it/s]\u001b[A\n",
      "Epoch 60:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.77it/s]\u001b[A\n",
      "Epoch 60:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.82it/s]\u001b[A\n",
      "Epoch 60:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 60:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.77it/s]\u001b[A\n",
      "Epoch 60:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 60:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.66it/s]\u001b[A\n",
      "Epoch 60:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 60:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 60:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 60:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  97%|█████████▋| 120/124 [00:26<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 60: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 60: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.430, train_loss_step=0.362, train_loss_epoch=0.203, val_loss_step=0.359]\n",
      "Epoch 60: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.448, train_loss_step=0.184, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Epoch 61:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 61:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.27it/s]\u001b[A\n",
      "Epoch 61:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 61:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.12it/s]\u001b[A\n",
      "Epoch 61:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 61:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.29it/s]\u001b[A\n",
      "Epoch 61:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 61:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 61:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 61:  87%|████████▋ | 676/780 [06:08<00:56,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 61:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 61:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 61:  87%|████████▋ | 682/780 [06:09<00:53,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.27it/s]\u001b[A\n",
      "Epoch 61:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.45it/s]\u001b[A\n",
      "Epoch 61:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.51it/s]\u001b[A\n",
      "Epoch 61:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.28it/s]\u001b[A\n",
      "Epoch 61:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 61:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 61:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 61:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.60it/s]\u001b[A\n",
      "Epoch 61:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.67it/s]\u001b[A\n",
      "Epoch 61:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 61:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 61:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.65it/s]\u001b[A\n",
      "Epoch 61:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.40it/s]\u001b[A\n",
      "Epoch 61:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 61:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 61:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.58it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.69it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.49it/s]\u001b[A\n",
      "Epoch 61:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 61:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 61:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.43it/s]\u001b[A\n",
      "Epoch 61:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 61:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 61:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 61:  94%|█████████▍| 734/780 [06:21<00:23,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.51it/s]\u001b[A\n",
      "Epoch 61:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.28it/s]\u001b[A\n",
      "Epoch 61:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 61:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 61:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 61:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 61:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 61:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.68it/s]\u001b[A\n",
      "Epoch 61:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.37it/s]\u001b[A\n",
      "Epoch 61:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.77it/s]\u001b[A\n",
      "Epoch 61:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 61:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.31it/s]\u001b[A\n",
      "Epoch 61:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 61:  97%|█████████▋| 760/780 [06:26<00:10,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 61:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.30it/s]\u001b[A\n",
      "Epoch 61:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 61:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.66it/s]\u001b[A\n",
      "Epoch 61:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 61:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.48it/s]\u001b[A\n",
      "Epoch 61:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.50it/s]\u001b[A\n",
      "Epoch 61:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 61:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.33it/s]\u001b[A\n",
      "Epoch 61: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 61: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.175, v_num=87, val_loss_epoch=0.448, train_loss_step=0.146, train_loss_epoch=0.198, val_loss_step=0.622]\n",
      "Epoch 61: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.175, v_num=87, val_loss_epoch=0.482, train_loss_step=0.131, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Epoch 62:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.84it/s]\u001b[A\n",
      "Epoch 62:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.16it/s]\u001b[A\n",
      "Epoch 62:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.84it/s]\u001b[A\n",
      "Epoch 62:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.02it/s]\u001b[A\n",
      "Epoch 62:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.45it/s]\u001b[A\n",
      "Epoch 62:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.52it/s]\u001b[A\n",
      "Epoch 62:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.40it/s]\u001b[A\n",
      "Epoch 62:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 62:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 62:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.39it/s]\u001b[A\n",
      "Epoch 62:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 62:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 62:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 62:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.53it/s]\u001b[A\n",
      "Epoch 62:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 62:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.68it/s]\u001b[A\n",
      "Epoch 62:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 62:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 62:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 62:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 62:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 62:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 62:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.43it/s]\u001b[A\n",
      "Epoch 62:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.53it/s]\u001b[A\n",
      "Epoch 62:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.30it/s]\u001b[A\n",
      "Epoch 62:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.70it/s]\u001b[A\n",
      "Epoch 62:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.73it/s]\u001b[A\n",
      "Epoch 62:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.40it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 716/780 [06:19<00:33,  1.88it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.52it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 62:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 62:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.71it/s]\u001b[A\n",
      "Epoch 62:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.49it/s]\u001b[A\n",
      "Epoch 62:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  4.73it/s]\u001b[A\n",
      "Epoch 62:  94%|█████████▎| 730/780 [06:23<00:26,  1.91it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.66it/s]\u001b[A\n",
      "Epoch 62:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 62:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.75it/s]\u001b[A\n",
      "Epoch 62:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.79it/s]\u001b[A\n",
      "Epoch 62:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 62:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.66it/s]\u001b[A\n",
      "Epoch 62:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.69it/s]\u001b[A\n",
      "Epoch 62:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 62:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.72it/s]\u001b[A\n",
      "Epoch 62:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 62:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 62:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 62:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 62:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 62:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 62:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 62:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 62:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.29it/s]\u001b[A\n",
      "Epoch 62:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 62:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 62:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.29it/s]\u001b[A\n",
      "Epoch 62:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.43it/s]\u001b[A\n",
      "Epoch 62:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 62:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.25it/s]\u001b[A\n",
      "Epoch 62: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.53it/s]\u001b[A\n",
      "Epoch 62: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.18, v_num=87, val_loss_epoch=0.482, train_loss_step=0.203, train_loss_epoch=0.194, val_loss_step=0.495]\n",
      "Epoch 62: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.18, v_num=87, val_loss_epoch=0.492, train_loss_step=0.0986, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Epoch 63:  84%|████████▍ | 656/780 [06:09<01:09,  1.78it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  84%|████████▍ | 658/780 [06:10<01:08,  1.78it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.93it/s]\u001b[A\n",
      "Epoch 63:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.11it/s]\u001b[A\n",
      "Epoch 63:  85%|████████▍ | 662/780 [06:11<01:06,  1.78it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 63:  85%|████████▌ | 664/780 [06:11<01:04,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.98it/s]\u001b[A\n",
      "Epoch 63:  85%|████████▌ | 666/780 [06:12<01:03,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.51it/s]\u001b[A\n",
      "Epoch 63:  86%|████████▌ | 668/780 [06:12<01:02,  1.79it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.55it/s]\u001b[A\n",
      "Epoch 63:  86%|████████▌ | 670/780 [06:13<01:01,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.31it/s]\u001b[A\n",
      "Epoch 63:  86%|████████▌ | 672/780 [06:13<01:00,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.67it/s]\u001b[A\n",
      "Epoch 63:  86%|████████▋ | 674/780 [06:13<00:58,  1.80it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.65it/s]\u001b[A\n",
      "Epoch 63:  87%|████████▋ | 676/780 [06:14<00:57,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 63:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.83it/s]\u001b[A\n",
      "Epoch 63:  87%|████████▋ | 680/780 [06:15<00:55,  1.81it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:20,  4.78it/s]\u001b[A\n",
      "Epoch 63:  87%|████████▋ | 682/780 [06:15<00:53,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.42it/s]\u001b[A\n",
      "Epoch 63:  88%|████████▊ | 684/780 [06:16<00:52,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 63:  88%|████████▊ | 686/780 [06:16<00:51,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.65it/s]\u001b[A\n",
      "Epoch 63:  88%|████████▊ | 688/780 [06:17<00:50,  1.82it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.35it/s]\u001b[A\n",
      "Epoch 63:  88%|████████▊ | 690/780 [06:17<00:49,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.55it/s]\u001b[A\n",
      "Epoch 63:  89%|████████▊ | 692/780 [06:17<00:48,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 63:  89%|████████▉ | 694/780 [06:18<00:46,  1.83it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 63:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.23it/s]\u001b[A\n",
      "Epoch 63:  89%|████████▉ | 698/780 [06:19<00:44,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.41it/s]\u001b[A\n",
      "Epoch 63:  90%|████████▉ | 700/780 [06:19<00:43,  1.84it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 63:  90%|█████████ | 702/780 [06:20<00:42,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:18,  4.31it/s]\u001b[A\n",
      "Epoch 63:  90%|█████████ | 704/780 [06:20<00:41,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.47it/s]\u001b[A\n",
      "Epoch 63:  91%|█████████ | 706/780 [06:21<00:39,  1.85it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.52it/s]\u001b[A\n",
      "Epoch 63:  91%|█████████ | 708/780 [06:21<00:38,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 63:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 63:  91%|█████████▏| 712/780 [06:22<00:36,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.58it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 714/780 [06:22<00:35,  1.86it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 716/780 [06:23<00:34,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 720/780 [06:24<00:32,  1.87it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 63:  93%|█████████▎| 722/780 [06:24<00:30,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 63:  93%|█████████▎| 724/780 [06:25<00:29,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 63:  93%|█████████▎| 726/780 [06:25<00:28,  1.88it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.60it/s]\u001b[A\n",
      "Epoch 63:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.41it/s]\u001b[A\n",
      "Epoch 63:  94%|█████████▎| 730/780 [06:26<00:26,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.68it/s]\u001b[A\n",
      "Epoch 63:  94%|█████████▍| 732/780 [06:26<00:25,  1.89it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 63:  94%|█████████▍| 734/780 [06:27<00:24,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.40it/s]\u001b[A\n",
      "Epoch 63:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 63:  95%|█████████▍| 738/780 [06:28<00:22,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 63:  95%|█████████▍| 740/780 [06:28<00:21,  1.90it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.42it/s]\u001b[A\n",
      "Epoch 63:  95%|█████████▌| 742/780 [06:29<00:19,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 63:  95%|█████████▌| 744/780 [06:29<00:18,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 63:  96%|█████████▌| 746/780 [06:29<00:17,  1.91it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.49it/s]\u001b[A\n",
      "Epoch 63:  96%|█████████▌| 748/780 [06:30<00:16,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 63:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 63:  96%|█████████▋| 752/780 [06:31<00:14,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 63:  97%|█████████▋| 754/780 [06:31<00:13,  1.92it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.41it/s]\u001b[A\n",
      "Epoch 63:  97%|█████████▋| 756/780 [06:32<00:12,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 63:  97%|█████████▋| 758/780 [06:32<00:11,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.40it/s]\u001b[A\n",
      "Epoch 63:  97%|█████████▋| 760/780 [06:33<00:10,  1.93it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.66it/s]\u001b[A\n",
      "Epoch 63:  98%|█████████▊| 762/780 [06:33<00:09,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 63:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.32it/s]\u001b[A\n",
      "Epoch 63:  98%|█████████▊| 766/780 [06:34<00:07,  1.94it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 63:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.59it/s]\u001b[A\n",
      "Epoch 63:  99%|█████████▊| 770/780 [06:35<00:05,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.26it/s]\u001b[A\n",
      "Epoch 63:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 63:  99%|█████████▉| 774/780 [06:36<00:03,  1.95it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 63:  99%|█████████▉| 776/780 [06:36<00:02,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.27it/s]\u001b[A\n",
      "Epoch 63: 100%|█████████▉| 778/780 [06:37<00:01,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 63: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.492, train_loss_step=0.170, train_loss_epoch=0.191, val_loss_step=0.505]\n",
      "Epoch 63: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.192, v_num=87, val_loss_epoch=0.415, train_loss_step=0.296, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Epoch 64:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  84%|████████▍ | 658/780 [06:06<01:07,  1.79it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 64:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.21it/s]\u001b[A\n",
      "Epoch 64:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.65it/s]\u001b[A\n",
      "Epoch 64:  85%|████████▌ | 664/780 [06:07<01:04,  1.80it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.12it/s]\u001b[A\n",
      "Epoch 64:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.26it/s]\u001b[A\n",
      "Epoch 64:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 64:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.44it/s]\u001b[A\n",
      "Epoch 64:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 64:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 64:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.35it/s]\u001b[A\n",
      "Epoch 64:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 64:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 64:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 64:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.51it/s]\u001b[A\n",
      "Epoch 64:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 64:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.31it/s]\u001b[A\n",
      "Epoch 64:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.49it/s]\u001b[A\n",
      "Epoch 64:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.54it/s]\u001b[A\n",
      "Epoch 64:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.32it/s]\u001b[A\n",
      "Epoch 64:  89%|████████▉ | 696/780 [06:15<00:45,  1.86it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.59it/s]\u001b[A\n",
      "Epoch 64:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 64:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 64:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.36it/s]\u001b[A\n",
      "Epoch 64:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 64:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 64:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.27it/s]\u001b[A\n",
      "Epoch 64:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 64:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.34it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 64:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 64:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.55it/s]\u001b[A\n",
      "Epoch 64:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.30it/s]\u001b[A\n",
      "Epoch 64:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.36it/s]\u001b[A\n",
      "Epoch 64:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 64:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 64:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 64:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 64:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 64:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.44it/s]\u001b[A\n",
      "Epoch 64:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 64:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 64:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.41it/s]\u001b[A\n",
      "Epoch 64:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 64:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.34it/s]\u001b[A\n",
      "Epoch 64:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:05,  4.74it/s]\u001b[A\n",
      "Epoch 64:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.79it/s]\u001b[A\n",
      "Epoch 64:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 64:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.83it/s]\u001b[A\n",
      "Epoch 64:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 64:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 64:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 64:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.41it/s]\u001b[A\n",
      "Epoch 64:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 64:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.37it/s]\u001b[A\n",
      "Epoch 64:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 64:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 64:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.42it/s]\u001b[A\n",
      "Epoch 64: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.73it/s]\u001b[A\n",
      "Epoch 64: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.208, v_num=87, val_loss_epoch=0.415, train_loss_step=0.0252, train_loss_epoch=0.192, val_loss_step=0.503]\n",
      "Epoch 64: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.208, v_num=87, val_loss_epoch=0.568, train_loss_step=0.333, train_loss_epoch=0.195, val_loss_step=0.453] \n",
      "Epoch 65:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 65:  85%|████████▍ | 660/780 [06:03<01:06,  1.81it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:40,  2.96it/s]\u001b[A\n",
      "Epoch 65:  85%|████████▍ | 662/780 [06:04<01:04,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.80it/s]\u001b[A\n",
      "Epoch 65:  85%|████████▌ | 664/780 [06:04<01:03,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.23it/s]\u001b[A\n",
      "Epoch 65:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 65:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 65:  86%|████████▌ | 670/780 [06:05<01:00,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 65:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.36it/s]\u001b[A\n",
      "Epoch 65:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.55it/s]\u001b[A\n",
      "Epoch 65:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 65:  87%|████████▋ | 678/780 [06:07<00:55,  1.84it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 65:  87%|████████▋ | 680/780 [06:08<00:54,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 65:  87%|████████▋ | 682/780 [06:08<00:52,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 65:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 65:  88%|████████▊ | 686/780 [06:09<00:50,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.38it/s]\u001b[A\n",
      "Epoch 65:  88%|████████▊ | 688/780 [06:09<00:49,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.51it/s]\u001b[A\n",
      "Epoch 65:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 65:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.37it/s]\u001b[A\n",
      "Epoch 65:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 65:  89%|████████▉ | 696/780 [06:11<00:44,  1.87it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 65:  89%|████████▉ | 698/780 [06:12<00:43,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 65:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 65:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 65:  90%|█████████ | 704/780 [06:13<00:40,  1.88it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 65:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.48it/s]\u001b[A\n",
      "Epoch 65:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.28it/s]\u001b[A\n",
      "Epoch 65:  91%|█████████ | 710/780 [06:14<00:36,  1.89it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 65:  91%|█████████▏| 712/780 [06:15<00:35,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.59it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 718/780 [06:16<00:32,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.67it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.66it/s]\u001b[A\n",
      "Epoch 65:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.35it/s]\u001b[A\n",
      "Epoch 65:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.52it/s]\u001b[A\n",
      "Epoch 65:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.64it/s]\u001b[A\n",
      "Epoch 65:  93%|█████████▎| 728/780 [06:18<00:27,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.40it/s]\u001b[A\n",
      "Epoch 65:  94%|█████████▎| 730/780 [06:19<00:25,  1.92it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.49it/s]\u001b[A\n",
      "Epoch 65:  94%|█████████▍| 732/780 [06:19<00:24,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 65:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.31it/s]\u001b[A\n",
      "Epoch 65:  94%|█████████▍| 736/780 [06:20<00:22,  1.93it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.46it/s]\u001b[A\n",
      "Epoch 65:  95%|█████████▍| 738/780 [06:21<00:21,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.47it/s]\u001b[A\n",
      "Epoch 65:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.36it/s]\u001b[A\n",
      "Epoch 65:  95%|█████████▌| 742/780 [06:21<00:19,  1.94it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 65:  95%|█████████▌| 744/780 [06:22<00:18,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 65:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 65:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.34it/s]\u001b[A\n",
      "Epoch 65:  96%|█████████▌| 750/780 [06:23<00:15,  1.95it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 65:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 65:  97%|█████████▋| 754/780 [06:24<00:13,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.48it/s]\u001b[A\n",
      "Epoch 65:  97%|█████████▋| 756/780 [06:25<00:12,  1.96it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.71it/s]\u001b[A\n",
      "Epoch 65:  97%|█████████▋| 758/780 [06:25<00:11,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 65:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 65:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 65:  98%|█████████▊| 764/780 [06:26<00:08,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 65:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 65:  98%|█████████▊| 768/780 [06:27<00:06,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 65:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.54it/s]\u001b[A\n",
      "Epoch 65:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 65:  99%|█████████▉| 774/780 [06:29<00:03,  1.99it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.46it/s]\u001b[A\n",
      "Epoch 65:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.67it/s]\u001b[A\n",
      "Epoch 65: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 65: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.196, v_num=87, val_loss_epoch=0.568, train_loss_step=0.165, train_loss_epoch=0.195, val_loss_step=0.453]\n",
      "Epoch 65: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.196, v_num=87, val_loss_epoch=0.474, train_loss_step=0.267, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Epoch 66:  84%|████████▍ | 656/780 [06:09<01:09,  1.78it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  84%|████████▍ | 658/780 [06:10<01:08,  1.78it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 66:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.19it/s]\u001b[A\n",
      "Epoch 66:  85%|████████▍ | 662/780 [06:11<01:06,  1.78it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.68it/s]\u001b[A\n",
      "Epoch 66:  85%|████████▌ | 664/780 [06:11<01:04,  1.79it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 66:  85%|████████▌ | 666/780 [06:12<01:03,  1.79it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.41it/s]\u001b[A\n",
      "Epoch 66:  86%|████████▌ | 668/780 [06:12<01:02,  1.79it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.32it/s]\u001b[A\n",
      "Epoch 66:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 66:  86%|████████▌ | 672/780 [06:13<01:00,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.60it/s]\u001b[A\n",
      "Epoch 66:  86%|████████▋ | 674/780 [06:13<00:58,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.38it/s]\u001b[A\n",
      "Epoch 66:  87%|████████▋ | 676/780 [06:14<00:57,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:21,  4.74it/s]\u001b[A\n",
      "Epoch 66:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 66:  87%|████████▋ | 680/780 [06:15<00:55,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.42it/s]\u001b[A\n",
      "Epoch 66:  87%|████████▋ | 682/780 [06:15<00:53,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.68it/s]\u001b[A\n",
      "Epoch 66:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.68it/s]\u001b[A\n",
      "Epoch 66:  88%|████████▊ | 686/780 [06:16<00:51,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.49it/s]\u001b[A\n",
      "Epoch 66:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 66:  88%|████████▊ | 690/780 [06:17<00:49,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 66:  89%|████████▊ | 692/780 [06:17<00:48,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.55it/s]\u001b[A\n",
      "Epoch 66:  89%|████████▉ | 694/780 [06:18<00:46,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:20,  4.28it/s]\u001b[A\n",
      "Epoch 66:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 66:  89%|████████▉ | 698/780 [06:19<00:44,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 66:  90%|████████▉ | 700/780 [06:19<00:43,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.37it/s]\u001b[A\n",
      "Epoch 66:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 66:  90%|█████████ | 704/780 [06:20<00:41,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 66:  91%|█████████ | 706/780 [06:20<00:39,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.42it/s]\u001b[A\n",
      "Epoch 66:  91%|█████████ | 708/780 [06:21<00:38,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 66:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.68it/s]\u001b[A\n",
      "Epoch 66:  91%|█████████▏| 712/780 [06:22<00:36,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.39it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 716/780 [06:23<00:34,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.57it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 720/780 [06:24<00:32,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 66:  93%|█████████▎| 722/780 [06:24<00:30,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.53it/s]\u001b[A\n",
      "Epoch 66:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 66:  93%|█████████▎| 726/780 [06:25<00:28,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.38it/s]\u001b[A\n",
      "Epoch 66:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 66:  94%|█████████▎| 730/780 [06:26<00:26,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.31it/s]\u001b[A\n",
      "Epoch 66:  94%|█████████▍| 732/780 [06:26<00:25,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.77it/s]\u001b[A\n",
      "Epoch 66:  94%|█████████▍| 734/780 [06:27<00:24,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.78it/s]\u001b[A\n",
      "Epoch 66:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 66:  95%|█████████▍| 738/780 [06:28<00:22,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.70it/s]\u001b[A\n",
      "Epoch 66:  95%|█████████▍| 740/780 [06:28<00:20,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.78it/s]\u001b[A\n",
      "Epoch 66:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 66:  95%|█████████▌| 744/780 [06:29<00:18,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 66:  96%|█████████▌| 746/780 [06:29<00:17,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 66:  96%|█████████▌| 748/780 [06:30<00:16,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 66:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 66:  96%|█████████▋| 752/780 [06:31<00:14,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 66:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 66:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 66:  97%|█████████▋| 758/780 [06:32<00:11,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 66:  97%|█████████▋| 760/780 [06:32<00:10,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 66:  98%|█████████▊| 762/780 [06:33<00:09,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.40it/s]\u001b[A\n",
      "Epoch 66:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.68it/s]\u001b[A\n",
      "Epoch 66:  98%|█████████▊| 766/780 [06:34<00:07,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.60it/s]\u001b[A\n",
      "Epoch 66:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 66:  99%|█████████▊| 770/780 [06:35<00:05,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.80it/s]\u001b[A\n",
      "Epoch 66:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 66:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 66:  99%|█████████▉| 776/780 [06:36<00:02,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.76it/s]\u001b[A\n",
      "Epoch 66: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.75it/s]\u001b[A\n",
      "Epoch 66: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.474, train_loss_step=0.169, train_loss_epoch=0.195, val_loss_step=0.588]\n",
      "Epoch 66: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.519, train_loss_step=0.265, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Epoch 67:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]\u001b[A\n",
      "Epoch 67:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:40,  2.97it/s]\u001b[A\n",
      "Epoch 67:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.81it/s]\u001b[A\n",
      "Epoch 67:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 67:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 67:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.28it/s]\u001b[A\n",
      "Epoch 67:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.55it/s]\u001b[A\n",
      "Epoch 67:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 67:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:25,  4.23it/s]\u001b[A\n",
      "Epoch 67:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 67:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 67:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.33it/s]\u001b[A\n",
      "Epoch 67:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 67:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 67:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 67:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 67:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.56it/s]\u001b[A\n",
      "Epoch 67:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 67:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.44it/s]\u001b[A\n",
      "Epoch 67:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.69it/s]\u001b[A\n",
      "Epoch 67:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:16,  5.00it/s]\u001b[A\n",
      "Epoch 67:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.78it/s]\u001b[A\n",
      "Epoch 67:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 67:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 67:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 67:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 67:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 67:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.66it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.53it/s]\u001b[A\n",
      "Epoch 67:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 67:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 67:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 67:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 67:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 67:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 67:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.76it/s]\u001b[A\n",
      "Epoch 67:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.78it/s]\u001b[A\n",
      "Epoch 67:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.30it/s]\u001b[A\n",
      "Epoch 67:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 67:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.56it/s]\u001b[A\n",
      "Epoch 67:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.24it/s]\u001b[A\n",
      "Epoch 67:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.42it/s]\u001b[A\n",
      "Epoch 67:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.42it/s]\u001b[A\n",
      "Epoch 67:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.32it/s]\u001b[A\n",
      "Epoch 67:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 67:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 67:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 67:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 67:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 67:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 67:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.37it/s]\u001b[A\n",
      "Epoch 67:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.69it/s]\u001b[A\n",
      "Epoch 67:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 67:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.39it/s]\u001b[A\n",
      "Epoch 67:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.54it/s]\u001b[A\n",
      "Epoch 67:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.60it/s]\u001b[A\n",
      "Epoch 67:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.40it/s]\u001b[A\n",
      "Epoch 67: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 67: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.519, train_loss_step=0.229, train_loss_epoch=0.187, val_loss_step=0.389]\n",
      "Epoch 67: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.457, train_loss_step=0.200, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Epoch 68:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:04,  1.88it/s]\u001b[A\n",
      "Epoch 68:  85%|████████▍ | 660/780 [06:07<01:06,  1.79it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.16it/s]\u001b[A\n",
      "Epoch 68:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.89it/s]\u001b[A\n",
      "Epoch 68:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.97it/s]\u001b[A\n",
      "Epoch 68:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.26it/s]\u001b[A\n",
      "Epoch 68:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.33it/s]\u001b[A\n",
      "Epoch 68:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 68:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.37it/s]\u001b[A\n",
      "Epoch 68:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 68:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 68:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.30it/s]\u001b[A\n",
      "Epoch 68:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.48it/s]\u001b[A\n",
      "Epoch 68:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 68:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.21it/s]\u001b[A\n",
      "Epoch 68:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.40it/s]\u001b[A\n",
      "Epoch 68:  88%|████████▊ | 688/780 [06:13<00:50,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.47it/s]\u001b[A\n",
      "Epoch 68:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.36it/s]\u001b[A\n",
      "Epoch 68:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 68:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 68:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 68:  89%|████████▉ | 698/780 [06:16<00:44,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 68:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 68:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 68:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.41it/s]\u001b[A\n",
      "Epoch 68:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 68:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.42it/s]\u001b[A\n",
      "Epoch 68:  91%|█████████ | 710/780 [06:18<00:37,  1.87it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 68:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.69it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.46it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 716/780 [06:20<00:33,  1.88it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.70it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.72it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.33it/s]\u001b[A\n",
      "Epoch 68:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.51it/s]\u001b[A\n",
      "Epoch 68:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 68:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 68:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 68:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 68:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.65it/s]\u001b[A\n",
      "Epoch 68:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.32it/s]\u001b[A\n",
      "Epoch 68:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 68:  95%|█████████▍| 738/780 [06:25<00:21,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 68:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.29it/s]\u001b[A\n",
      "Epoch 68:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 68:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 68:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.30it/s]\u001b[A\n",
      "Epoch 68:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 68:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 68:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.36it/s]\u001b[A\n",
      "Epoch 68:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.68it/s]\u001b[A\n",
      "Epoch 68:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.68it/s]\u001b[A\n",
      "Epoch 68:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 68:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 68:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.78it/s]\u001b[A\n",
      "Epoch 68:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.94it/s]\u001b[A\n",
      "Epoch 68:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.75it/s]\u001b[A\n",
      "Epoch 68:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 68:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 68:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 68:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 68:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 68: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.22it/s]\u001b[A\n",
      "Epoch 68: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.457, train_loss_step=0.157, train_loss_epoch=0.189, val_loss_step=0.677]\n",
      "Epoch 68: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.199, v_num=87, val_loss_epoch=0.437, train_loss_step=0.147, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Epoch 69:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.96it/s]\u001b[A\n",
      "Epoch 69:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.17it/s]\u001b[A\n",
      "Epoch 69:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 69:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.36it/s]\u001b[A\n",
      "Epoch 69:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.55it/s]\u001b[A\n",
      "Epoch 69:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.32it/s]\u001b[A\n",
      "Epoch 69:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.48it/s]\u001b[A\n",
      "Epoch 69:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.60it/s]\u001b[A\n",
      "Epoch 69:  86%|████████▋ | 674/780 [06:08<00:58,  1.83it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.31it/s]\u001b[A\n",
      "Epoch 69:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.46it/s]\u001b[A\n",
      "Epoch 69:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 69:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.23it/s]\u001b[A\n",
      "Epoch 69:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 69:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 69:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 69:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.25it/s]\u001b[A\n",
      "Epoch 69:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 69:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 69:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.37it/s]\u001b[A\n",
      "Epoch 69:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.67it/s]\u001b[A\n",
      "Epoch 69:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 69:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.43it/s]\u001b[A\n",
      "Epoch 69:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.74it/s]\u001b[A\n",
      "Epoch 69:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 69:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.39it/s]\u001b[A\n",
      "Epoch 69:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.51it/s]\u001b[A\n",
      "Epoch 69:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 69:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.64it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.54it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.39it/s]\u001b[A\n",
      "Epoch 69:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 69:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 69:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.45it/s]\u001b[A\n",
      "Epoch 69:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.61it/s]\u001b[A\n",
      "Epoch 69:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.40it/s]\u001b[A\n",
      "Epoch 69:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 69:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 69:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.33it/s]\u001b[A\n",
      "Epoch 69:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 69:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 69:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.33it/s]\u001b[A\n",
      "Epoch 69:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 69:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.64it/s]\u001b[A\n",
      "Epoch 69:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 69:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.37it/s]\u001b[A\n",
      "Epoch 69:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.84it/s]\u001b[A\n",
      "Epoch 69:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.71it/s]\u001b[A\n",
      "Epoch 69:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.34it/s]\u001b[A\n",
      "Epoch 69:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.53it/s]\u001b[A\n",
      "Epoch 69:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.56it/s]\u001b[A\n",
      "Epoch 69:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.32it/s]\u001b[A\n",
      "Epoch 69:  98%|█████████▊| 764/780 [06:28<00:08,  1.96it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 69:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.59it/s]\u001b[A\n",
      "Epoch 69:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.32it/s]\u001b[A\n",
      "Epoch 69:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.51it/s]\u001b[A\n",
      "Epoch 69:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 69:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 69:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 69: 100%|█████████▉| 778/780 [06:31<00:01,  1.98it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 69: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.195, v_num=87, val_loss_epoch=0.437, train_loss_step=0.0458, train_loss_epoch=0.192, val_loss_step=0.379]\n",
      "Epoch 69: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.195, v_num=87, val_loss_epoch=0.490, train_loss_step=0.104, train_loss_epoch=0.192, val_loss_step=0.385] \n",
      "Epoch 70:  84%|████████▍ | 656/780 [06:07<01:09,  1.79it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  84%|████████▍ | 658/780 [06:08<01:08,  1.78it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.95it/s]\u001b[A\n",
      "Epoch 70:  85%|████████▍ | 660/780 [06:09<01:07,  1.79it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.19it/s]\u001b[A\n",
      "Epoch 70:  85%|████████▍ | 662/780 [06:09<01:05,  1.79it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.62it/s]\u001b[A\n",
      "Epoch 70:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.12it/s]\u001b[A\n",
      "Epoch 70:  85%|████████▌ | 666/780 [06:10<01:03,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 70:  86%|████████▌ | 668/780 [06:10<01:02,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.20it/s]\u001b[A\n",
      "Epoch 70:  86%|████████▌ | 670/780 [06:11<01:00,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 70:  86%|████████▌ | 672/780 [06:11<00:59,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 70:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.38it/s]\u001b[A\n",
      "Epoch 70:  87%|████████▋ | 676/780 [06:12<00:57,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 70:  87%|████████▋ | 678/780 [06:13<00:56,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 70:  87%|████████▋ | 680/780 [06:13<00:54,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.43it/s]\u001b[A\n",
      "Epoch 70:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.53it/s]\u001b[A\n",
      "Epoch 70:  88%|████████▊ | 684/780 [06:14<00:52,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 70:  88%|████████▊ | 686/780 [06:14<00:51,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.38it/s]\u001b[A\n",
      "Epoch 70:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 70:  88%|████████▊ | 690/780 [06:15<00:49,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.68it/s]\u001b[A\n",
      "Epoch 70:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 70:  89%|████████▉ | 694/780 [06:16<00:46,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 70:  89%|████████▉ | 696/780 [06:17<00:45,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 70:  89%|████████▉ | 698/780 [06:17<00:44,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.66it/s]\u001b[A\n",
      "Epoch 70:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 70:  90%|█████████ | 702/780 [06:18<00:42,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 70:  90%|█████████ | 704/780 [06:18<00:40,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.66it/s]\u001b[A\n",
      "Epoch 70:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 70:  91%|█████████ | 708/780 [06:19<00:38,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 70:  91%|█████████ | 710/780 [06:20<00:37,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 70:  91%|█████████▏| 712/780 [06:20<00:36,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 716/780 [06:21<00:34,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.27it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 718/780 [06:22<00:32,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.49it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.47it/s]\u001b[A\n",
      "Epoch 70:  93%|█████████▎| 722/780 [06:22<00:30,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 70:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.45it/s]\u001b[A\n",
      "Epoch 70:  93%|█████████▎| 726/780 [06:23<00:28,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.64it/s]\u001b[A\n",
      "Epoch 70:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.73it/s]\u001b[A\n",
      "Epoch 70:  94%|█████████▎| 730/780 [06:24<00:26,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 70:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.70it/s]\u001b[A\n",
      "Epoch 70:  94%|█████████▍| 734/780 [06:25<00:24,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 70:  94%|█████████▍| 736/780 [06:25<00:23,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.40it/s]\u001b[A\n",
      "Epoch 70:  95%|█████████▍| 738/780 [06:26<00:21,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.75it/s]\u001b[A\n",
      "Epoch 70:  95%|█████████▍| 740/780 [06:26<00:20,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.74it/s]\u001b[A\n",
      "Epoch 70:  95%|█████████▌| 742/780 [06:27<00:19,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.40it/s]\u001b[A\n",
      "Epoch 70:  95%|█████████▌| 744/780 [06:27<00:18,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.78it/s]\u001b[A\n",
      "Epoch 70:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.73it/s]\u001b[A\n",
      "Epoch 70:  96%|█████████▌| 748/780 [06:28<00:16,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.39it/s]\u001b[A\n",
      "Epoch 70:  96%|█████████▌| 750/780 [06:28<00:15,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 70:  96%|█████████▋| 752/780 [06:29<00:14,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.44it/s]\u001b[A\n",
      "Epoch 70:  97%|█████████▋| 754/780 [06:29<00:13,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 70:  97%|█████████▋| 756/780 [06:30<00:12,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 70:  97%|█████████▋| 758/780 [06:30<00:11,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.69it/s]\u001b[A\n",
      "Epoch 70:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 70:  98%|█████████▊| 762/780 [06:31<00:09,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 70:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 70:  98%|█████████▊| 766/780 [06:32<00:07,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 70:  98%|█████████▊| 768/780 [06:32<00:06,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.28it/s]\u001b[A\n",
      "Epoch 70:  99%|█████████▊| 770/780 [06:33<00:05,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.44it/s]\u001b[A\n",
      "Epoch 70:  99%|█████████▉| 772/780 [06:33<00:04,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.57it/s]\u001b[A\n",
      "Epoch 70:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.33it/s]\u001b[A\n",
      "Epoch 70:  99%|█████████▉| 776/780 [06:34<00:02,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 70: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.51it/s]\u001b[A\n",
      "Epoch 70: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.490, train_loss_step=0.200, train_loss_epoch=0.192, val_loss_step=0.385]\n",
      "Epoch 70: 100%|██████████| 780/780 [06:35<00:00,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.528, train_loss_step=0.270, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Epoch 71:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  84%|████████▍ | 658/780 [06:06<01:08,  1.79it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.94it/s]\u001b[A\n",
      "Epoch 71:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.21it/s]\u001b[A\n",
      "Epoch 71:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.73it/s]\u001b[A\n",
      "Epoch 71:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.07it/s]\u001b[A\n",
      "Epoch 71:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.46it/s]\u001b[A\n",
      "Epoch 71:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 71:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 71:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.51it/s]\u001b[A\n",
      "Epoch 71:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 71:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.41it/s]\u001b[A\n",
      "Epoch 71:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 71:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 71:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 71:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 71:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.34it/s]\u001b[A\n",
      "Epoch 71:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 71:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.77it/s]\u001b[A\n",
      "Epoch 71:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 71:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 71:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 71:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 71:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 71:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 71:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 71:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.54it/s]\u001b[A\n",
      "Epoch 71:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.66it/s]\u001b[A\n",
      "Epoch 71:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 71:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:13,  4.74it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.69it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.80it/s]\u001b[A\n",
      "Epoch 71:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 71:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.35it/s]\u001b[A\n",
      "Epoch 71:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.47it/s]\u001b[A\n",
      "Epoch 71:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 71:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 71:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.46it/s]\u001b[A\n",
      "Epoch 71:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.69it/s]\u001b[A\n",
      "Epoch 71:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.72it/s]\u001b[A\n",
      "Epoch 71:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.39it/s]\u001b[A\n",
      "Epoch 71:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.72it/s]\u001b[A\n",
      "Epoch 71:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:07,  4.81it/s]\u001b[A\n",
      "Epoch 71:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 71:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.71it/s]\u001b[A\n",
      "Epoch 71:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 71:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.30it/s]\u001b[A\n",
      "Epoch 71:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.77it/s]\u001b[A\n",
      "Epoch 71:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.82it/s]\u001b[A\n",
      "Epoch 71:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.44it/s]\u001b[A\n",
      "Epoch 71:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.73it/s]\u001b[A\n",
      "Epoch 71:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.53it/s]\u001b[A\n",
      "Epoch 71:  98%|█████████▊| 762/780 [06:29<00:09,  1.95it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 71:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 71:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.45it/s]\u001b[A\n",
      "Epoch 71:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.63it/s]\u001b[A\n",
      "Epoch 71:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 71:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.38it/s]\u001b[A\n",
      "Epoch 71:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.53it/s]\u001b[A\n",
      "Epoch 71:  99%|█████████▉| 776/780 [06:32<00:02,  1.97it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.30it/s]\u001b[A\n",
      "Epoch 71: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.66it/s]\u001b[A\n",
      "Epoch 71: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.181, v_num=87, val_loss_epoch=0.528, train_loss_step=0.154, train_loss_epoch=0.187, val_loss_step=0.604]\n",
      "Epoch 71: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.181, v_num=87, val_loss_epoch=0.422, train_loss_step=0.155, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Epoch 72:  84%|████████▍ | 656/780 [06:01<01:08,  1.81it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  84%|████████▍ | 658/780 [06:02<01:07,  1.81it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.05it/s]\u001b[A\n",
      "Epoch 72:  85%|████████▍ | 660/780 [06:03<01:06,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 72:  85%|████████▍ | 662/780 [06:03<01:04,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:31,  3.78it/s]\u001b[A\n",
      "Epoch 72:  85%|████████▌ | 664/780 [06:03<01:03,  1.82it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.39it/s]\u001b[A\n",
      "Epoch 72:  85%|████████▌ | 666/780 [06:04<01:02,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.44it/s]\u001b[A\n",
      "Epoch 72:  86%|████████▌ | 668/780 [06:04<01:01,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.33it/s]\u001b[A\n",
      "Epoch 72:  86%|████████▌ | 670/780 [06:05<00:59,  1.83it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 72:  86%|████████▌ | 672/780 [06:05<00:58,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 72:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 72:  87%|████████▋ | 676/780 [06:06<00:56,  1.84it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.52it/s]\u001b[A\n",
      "Epoch 72:  87%|████████▋ | 678/780 [06:07<00:55,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 72:  87%|████████▋ | 680/780 [06:07<00:54,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 72:  87%|████████▋ | 682/780 [06:07<00:52,  1.85it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 72:  88%|████████▊ | 684/780 [06:08<00:51,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.71it/s]\u001b[A\n",
      "Epoch 72:  88%|████████▊ | 686/780 [06:08<00:50,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.65it/s]\u001b[A\n",
      "Epoch 72:  88%|████████▊ | 688/780 [06:09<00:49,  1.86it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.41it/s]\u001b[A\n",
      "Epoch 72:  88%|████████▊ | 690/780 [06:09<00:48,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.54it/s]\u001b[A\n",
      "Epoch 72:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 72:  89%|████████▉ | 694/780 [06:10<00:45,  1.87it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.34it/s]\u001b[A\n",
      "Epoch 72:  89%|████████▉ | 696/780 [06:11<00:44,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 72:  89%|████████▉ | 698/780 [06:11<00:43,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.46it/s]\u001b[A\n",
      "Epoch 72:  90%|████████▉ | 700/780 [06:11<00:42,  1.88it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.67it/s]\u001b[A\n",
      "Epoch 72:  90%|█████████ | 702/780 [06:12<00:41,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.65it/s]\u001b[A\n",
      "Epoch 72:  90%|█████████ | 704/780 [06:12<00:40,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 72:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 72:  91%|█████████ | 708/780 [06:13<00:38,  1.89it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.56it/s]\u001b[A\n",
      "Epoch 72:  91%|█████████ | 710/780 [06:14<00:36,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 72:  91%|█████████▏| 712/780 [06:14<00:35,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 716/780 [06:15<00:33,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 718/780 [06:15<00:32,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 720/780 [06:16<00:31,  1.91it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.69it/s]\u001b[A\n",
      "Epoch 72:  93%|█████████▎| 722/780 [06:16<00:30,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.75it/s]\u001b[A\n",
      "Epoch 72:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.49it/s]\u001b[A\n",
      "Epoch 72:  93%|█████████▎| 726/780 [06:17<00:28,  1.92it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.70it/s]\u001b[A\n",
      "Epoch 72:  93%|█████████▎| 728/780 [06:18<00:27,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 72:  94%|█████████▎| 730/780 [06:18<00:25,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 72:  94%|█████████▍| 732/780 [06:18<00:24,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.49it/s]\u001b[A\n",
      "Epoch 72:  94%|█████████▍| 734/780 [06:19<00:23,  1.93it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 72:  94%|█████████▍| 736/780 [06:19<00:22,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.34it/s]\u001b[A\n",
      "Epoch 72:  95%|█████████▍| 738/780 [06:20<00:21,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 72:  95%|█████████▍| 740/780 [06:20<00:20,  1.94it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 72:  95%|█████████▌| 742/780 [06:21<00:19,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.64it/s]\u001b[A\n",
      "Epoch 72:  95%|█████████▌| 744/780 [06:21<00:18,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.40it/s]\u001b[A\n",
      "Epoch 72:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.73it/s]\u001b[A\n",
      "Epoch 72:  96%|█████████▌| 748/780 [06:22<00:16,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.74it/s]\u001b[A\n",
      "Epoch 72:  96%|█████████▌| 750/780 [06:22<00:15,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 72:  96%|█████████▋| 752/780 [06:23<00:14,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.73it/s]\u001b[A\n",
      "Epoch 72:  97%|█████████▋| 754/780 [06:23<00:13,  1.96it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.73it/s]\u001b[A\n",
      "Epoch 72:  97%|█████████▋| 756/780 [06:24<00:12,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 72:  97%|█████████▋| 758/780 [06:24<00:11,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.76it/s]\u001b[A\n",
      "Epoch 72:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 72:  98%|█████████▊| 762/780 [06:25<00:09,  1.98it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 72:  98%|█████████▊| 764/780 [06:25<00:08,  1.98it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.77it/s]\u001b[A\n",
      "Epoch 72:  98%|█████████▊| 766/780 [06:26<00:07,  1.98it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.69it/s]\u001b[A\n",
      "Epoch 72:  98%|█████████▊| 768/780 [06:26<00:06,  1.99it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.30it/s]\u001b[A\n",
      "Epoch 72:  99%|█████████▊| 770/780 [06:27<00:05,  1.99it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.45it/s]\u001b[A\n",
      "Epoch 72:  99%|█████████▉| 772/780 [06:27<00:04,  1.99it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 72:  99%|█████████▉| 774/780 [06:28<00:03,  1.99it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.64it/s]\u001b[A\n",
      "Epoch 72:  99%|█████████▉| 776/780 [06:28<00:02,  2.00it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.38it/s]\u001b[A\n",
      "Epoch 72: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.75it/s]\u001b[A\n",
      "Epoch 72: 100%|██████████| 780/780 [06:29<00:00,  2.00it/s, loss=0.202, v_num=87, val_loss_epoch=0.422, train_loss_step=0.146, train_loss_epoch=0.184, val_loss_step=0.174]\n",
      "Epoch 72: 100%|██████████| 780/780 [06:29<00:00,  2.00it/s, loss=0.202, v_num=87, val_loss_epoch=0.510, train_loss_step=0.308, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Epoch 73:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]\u001b[A\n",
      "Epoch 73:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.20it/s]\u001b[A\n",
      "Epoch 73:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.92it/s]\u001b[A\n",
      "Epoch 73:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.01it/s]\u001b[A\n",
      "Epoch 73:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.33it/s]\u001b[A\n",
      "Epoch 73:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 73:  86%|████████▌ | 670/780 [06:07<01:00,  1.83it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 73:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 73:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.66it/s]\u001b[A\n",
      "Epoch 73:  87%|████████▋ | 676/780 [06:08<00:56,  1.84it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.35it/s]\u001b[A\n",
      "Epoch 73:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 73:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.63it/s]\u001b[A\n",
      "Epoch 73:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.43it/s]\u001b[A\n",
      "Epoch 73:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.70it/s]\u001b[A\n",
      "Epoch 73:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 73:  88%|████████▊ | 688/780 [06:10<00:49,  1.85it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 73:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 73:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 73:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 73:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.37it/s]\u001b[A\n",
      "Epoch 73:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 73:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.62it/s]\u001b[A\n",
      "Epoch 73:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.43it/s]\u001b[A\n",
      "Epoch 73:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 73:  91%|█████████ | 706/780 [06:14<00:39,  1.88it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 73:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 73:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.49it/s]\u001b[A\n",
      "Epoch 73:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.39it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 714/780 [06:16<00:34,  1.89it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 73:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.51it/s]\u001b[A\n",
      "Epoch 73:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 73:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.73it/s]\u001b[A\n",
      "Epoch 73:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.47it/s]\u001b[A\n",
      "Epoch 73:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 73:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.34it/s]\u001b[A\n",
      "Epoch 73:  94%|█████████▍| 734/780 [06:21<00:23,  1.93it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.33it/s]\u001b[A\n",
      "Epoch 73:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.45it/s]\u001b[A\n",
      "Epoch 73:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.30it/s]\u001b[A\n",
      "Epoch 73:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 73:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 73:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.29it/s]\u001b[A\n",
      "Epoch 73:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 73:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 73:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 73:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.22it/s]\u001b[A\n",
      "Epoch 73:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.47it/s]\u001b[A\n",
      "Epoch 73:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 73:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.30it/s]\u001b[A\n",
      "Epoch 73:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 73:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 73:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.37it/s]\u001b[A\n",
      "Epoch 73:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 73:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.56it/s]\u001b[A\n",
      "Epoch 73:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 73:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 73:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.60it/s]\u001b[A\n",
      "Epoch 73:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 73: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.42it/s]\u001b[A\n",
      "Epoch 73: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.177, v_num=87, val_loss_epoch=0.510, train_loss_step=0.0404, train_loss_epoch=0.185, val_loss_step=0.221]\n",
      "Epoch 73: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.177, v_num=87, val_loss_epoch=0.387, train_loss_step=0.222, train_loss_epoch=0.184, val_loss_step=0.566] \n",
      "Epoch 74:  84%|████████▍ | 656/780 [06:01<01:08,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  84%|████████▍ | 658/780 [06:02<01:07,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 74:  85%|████████▍ | 660/780 [06:02<01:05,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.08it/s]\u001b[A\n",
      "Epoch 74:  85%|████████▍ | 662/780 [06:03<01:04,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.89it/s]\u001b[A\n",
      "Epoch 74:  85%|████████▌ | 664/780 [06:03<01:03,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 74:  85%|████████▌ | 666/780 [06:04<01:02,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.25it/s]\u001b[A\n",
      "Epoch 74:  86%|████████▌ | 668/780 [06:04<01:01,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.58it/s]\u001b[A\n",
      "Epoch 74:  86%|████████▌ | 670/780 [06:05<00:59,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 74:  86%|████████▌ | 672/780 [06:05<00:58,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 74:  86%|████████▋ | 674/780 [06:05<00:57,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.29it/s]\u001b[A\n",
      "Epoch 74:  87%|████████▋ | 676/780 [06:06<00:56,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.51it/s]\u001b[A\n",
      "Epoch 74:  87%|████████▋ | 678/780 [06:06<00:55,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.66it/s]\u001b[A\n",
      "Epoch 74:  87%|████████▋ | 680/780 [06:07<00:54,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 74:  87%|████████▋ | 682/780 [06:07<00:52,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.84it/s]\u001b[A\n",
      "Epoch 74:  88%|████████▊ | 684/780 [06:07<00:51,  1.86it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:18,  5.09it/s]\u001b[A\n",
      "Epoch 74:  88%|████████▊ | 686/780 [06:08<00:50,  1.86it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:19,  4.89it/s]\u001b[A\n",
      "Epoch 74:  88%|████████▊ | 688/780 [06:08<00:49,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 74:  88%|████████▊ | 690/780 [06:09<00:48,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 74:  89%|████████▊ | 692/780 [06:09<00:47,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.50it/s]\u001b[A\n",
      "Epoch 74:  89%|████████▉ | 694/780 [06:10<00:45,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.56it/s]\u001b[A\n",
      "Epoch 74:  89%|████████▉ | 696/780 [06:10<00:44,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.56it/s]\u001b[A\n",
      "Epoch 74:  89%|████████▉ | 698/780 [06:11<00:43,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:19,  4.29it/s]\u001b[A\n",
      "Epoch 74:  90%|████████▉ | 700/780 [06:11<00:42,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.74it/s]\u001b[A\n",
      "Epoch 74:  90%|█████████ | 702/780 [06:11<00:41,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 74:  90%|█████████ | 704/780 [06:12<00:40,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 74:  91%|█████████ | 706/780 [06:12<00:39,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 74:  91%|█████████ | 708/780 [06:13<00:37,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 74:  91%|█████████ | 710/780 [06:13<00:36,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 74:  91%|█████████▏| 712/780 [06:14<00:35,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:15,  4.43it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 714/780 [06:14<00:34,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.69it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 716/780 [06:15<00:33,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 718/780 [06:15<00:32,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.35it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 720/780 [06:15<00:31,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.77it/s]\u001b[A\n",
      "Epoch 74:  93%|█████████▎| 722/780 [06:16<00:30,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.74it/s]\u001b[A\n",
      "Epoch 74:  93%|█████████▎| 724/780 [06:16<00:29,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 74:  93%|█████████▎| 726/780 [06:17<00:28,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 74:  93%|█████████▎| 728/780 [06:17<00:26,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 74:  94%|█████████▎| 730/780 [06:18<00:25,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.32it/s]\u001b[A\n",
      "Epoch 74:  94%|█████████▍| 732/780 [06:18<00:24,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 74:  94%|█████████▍| 734/780 [06:19<00:23,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 74:  94%|█████████▍| 736/780 [06:19<00:22,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 74:  95%|█████████▍| 738/780 [06:19<00:21,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.31it/s]\u001b[A\n",
      "Epoch 74:  95%|█████████▍| 740/780 [06:20<00:20,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.52it/s]\u001b[A\n",
      "Epoch 74:  95%|█████████▌| 742/780 [06:20<00:19,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 74:  95%|█████████▌| 744/780 [06:21<00:18,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.28it/s]\u001b[A\n",
      "Epoch 74:  96%|█████████▌| 746/780 [06:21<00:17,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 74:  96%|█████████▌| 748/780 [06:22<00:16,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 74:  96%|█████████▌| 750/780 [06:22<00:15,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.38it/s]\u001b[A\n",
      "Epoch 74:  96%|█████████▋| 752/780 [06:23<00:14,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 74:  97%|█████████▋| 754/780 [06:23<00:13,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 74:  97%|█████████▋| 756/780 [06:23<00:12,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 74:  97%|█████████▋| 758/780 [06:24<00:11,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.57it/s]\u001b[A\n",
      "Epoch 74:  97%|█████████▋| 760/780 [06:24<00:10,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 74:  98%|█████████▊| 762/780 [06:25<00:09,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 74:  98%|█████████▊| 764/780 [06:25<00:08,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.47it/s]\u001b[A\n",
      "Epoch 74:  98%|█████████▊| 766/780 [06:26<00:07,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 74:  98%|█████████▊| 768/780 [06:26<00:06,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 74:  99%|█████████▊| 770/780 [06:27<00:05,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.41it/s]\u001b[A\n",
      "Epoch 74:  99%|█████████▉| 772/780 [06:27<00:04,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 74:  99%|█████████▉| 774/780 [06:27<00:03,  2.00it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 74:  99%|█████████▉| 776/780 [06:28<00:02,  2.00it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 74: 100%|█████████▉| 778/780 [06:28<00:00,  2.00it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.63it/s]\u001b[A\n",
      "Epoch 74: 100%|██████████| 780/780 [06:29<00:00,  2.00it/s, loss=0.198, v_num=87, val_loss_epoch=0.387, train_loss_step=0.192, train_loss_epoch=0.184, val_loss_step=0.566]\n",
      "Epoch 74: 100%|██████████| 780/780 [06:29<00:00,  2.00it/s, loss=0.198, v_num=87, val_loss_epoch=0.549, train_loss_step=0.712, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Epoch 75:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.91it/s]\u001b[A\n",
      "Epoch 75:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.16it/s]\u001b[A\n",
      "Epoch 75:  85%|████████▍ | 662/780 [06:04<01:05,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.68it/s]\u001b[A\n",
      "Epoch 75:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.29it/s]\u001b[A\n",
      "Epoch 75:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.54it/s]\u001b[A\n",
      "Epoch 75:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.41it/s]\u001b[A\n",
      "Epoch 75:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 75:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.69it/s]\u001b[A\n",
      "Epoch 75:  86%|████████▋ | 674/780 [06:07<00:57,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.51it/s]\u001b[A\n",
      "Epoch 75:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.72it/s]\u001b[A\n",
      "Epoch 75:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 75:  87%|████████▋ | 680/780 [06:08<00:54,  1.84it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.63it/s]\u001b[A\n",
      "Epoch 75:  87%|████████▋ | 682/780 [06:09<00:53,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 75:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.41it/s]\u001b[A\n",
      "Epoch 75:  88%|████████▊ | 686/780 [06:09<00:50,  1.85it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 75:  88%|████████▊ | 688/780 [06:10<00:49,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 75:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.66it/s]\u001b[A\n",
      "Epoch 75:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 75:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.30it/s]\u001b[A\n",
      "Epoch 75:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 75:  89%|████████▉ | 698/780 [06:12<00:43,  1.87it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 75:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.38it/s]\u001b[A\n",
      "Epoch 75:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 75:  90%|█████████ | 704/780 [06:13<00:40,  1.88it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 75:  91%|█████████ | 706/780 [06:14<00:39,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.31it/s]\u001b[A\n",
      "Epoch 75:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 75:  91%|█████████ | 710/780 [06:15<00:36,  1.89it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.73it/s]\u001b[A\n",
      "Epoch 75:  91%|█████████▏| 712/780 [06:15<00:35,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.30it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.44it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:14,  4.26it/s]\u001b[A\n",
      "Epoch 75:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 75:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.51it/s]\u001b[A\n",
      "Epoch 75:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.30it/s]\u001b[A\n",
      "Epoch 75:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 75:  94%|█████████▎| 730/780 [06:19<00:26,  1.92it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 75:  94%|█████████▍| 732/780 [06:20<00:24,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 75:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 75:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 75:  95%|█████████▍| 738/780 [06:21<00:21,  1.93it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.38it/s]\u001b[A\n",
      "Epoch 75:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.41it/s]\u001b[A\n",
      "Epoch 75:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 75:  95%|█████████▌| 744/780 [06:22<00:18,  1.94it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 75:  96%|█████████▌| 746/780 [06:23<00:17,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.41it/s]\u001b[A\n",
      "Epoch 75:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 75:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.69it/s]\u001b[A\n",
      "Epoch 75:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 75:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:04,  5.43it/s]\u001b[A\n",
      "Epoch 75:  97%|█████████▋| 756/780 [06:25<00:12,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:04,  4.96it/s]\u001b[A\n",
      "Epoch 75:  97%|█████████▋| 758/780 [06:25<00:11,  1.96it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.52it/s]\u001b[A\n",
      "Epoch 75:  97%|█████████▋| 760/780 [06:26<00:10,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 75:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.60it/s]\u001b[A\n",
      "Epoch 75:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.26it/s]\u001b[A\n",
      "Epoch 75:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 75:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 75:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.38it/s]\u001b[A\n",
      "Epoch 75:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.63it/s]\u001b[A\n",
      "Epoch 75:  99%|█████████▉| 774/780 [06:29<00:03,  1.99it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.42it/s]\u001b[A\n",
      "Epoch 75:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 75: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.25it/s]\u001b[A\n",
      "Epoch 75: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.17, v_num=87, val_loss_epoch=0.549, train_loss_step=0.0128, train_loss_epoch=0.186, val_loss_step=0.378]\n",
      "Epoch 75: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.17, v_num=87, val_loss_epoch=0.515, train_loss_step=0.211, train_loss_epoch=0.186, val_loss_step=0.473] \n",
      "Epoch 76:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.94it/s]\u001b[A\n",
      "Epoch 76:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.10it/s]\u001b[A\n",
      "Epoch 76:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 76:  85%|████████▌ | 664/780 [06:05<01:03,  1.81it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.29it/s]\u001b[A\n",
      "Epoch 76:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.27it/s]\u001b[A\n",
      "Epoch 76:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 76:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 76:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 76:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.65it/s]\u001b[A\n",
      "Epoch 76:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.43it/s]\u001b[A\n",
      "Epoch 76:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.61it/s]\u001b[A\n",
      "Epoch 76:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.43it/s]\u001b[A\n",
      "Epoch 76:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 76:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.61it/s]\u001b[A\n",
      "Epoch 76:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.39it/s]\u001b[A\n",
      "Epoch 76:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 76:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 76:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 76:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 76:  89%|████████▉ | 696/780 [06:12<00:45,  1.87it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.32it/s]\u001b[A\n",
      "Epoch 76:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 76:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.71it/s]\u001b[A\n",
      "Epoch 76:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.38it/s]\u001b[A\n",
      "Epoch 76:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.52it/s]\u001b[A\n",
      "Epoch 76:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 76:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.30it/s]\u001b[A\n",
      "Epoch 76:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 76:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 714/780 [06:16<00:34,  1.89it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.68it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.38it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:12,  4.78it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.65it/s]\u001b[A\n",
      "Epoch 76:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.37it/s]\u001b[A\n",
      "Epoch 76:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 76:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 76:  93%|█████████▎| 728/780 [06:20<00:27,  1.92it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 76:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 76:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.66it/s]\u001b[A\n",
      "Epoch 76:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.25it/s]\u001b[A\n",
      "Epoch 76:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.47it/s]\u001b[A\n",
      "Epoch 76:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 76:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.39it/s]\u001b[A\n",
      "Epoch 76:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 76:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 76:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 76:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.32it/s]\u001b[A\n",
      "Epoch 76:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 76:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 76:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 76:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 76:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 76:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.40it/s]\u001b[A\n",
      "Epoch 76:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 76:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 76:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.39it/s]\u001b[A\n",
      "Epoch 76:  98%|█████████▊| 768/780 [06:28<00:06,  1.97it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 76:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.44it/s]\u001b[A\n",
      "Epoch 76:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 76:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 76:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.57it/s]\u001b[A\n",
      "Epoch 76: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.68it/s]\u001b[A\n",
      "Epoch 76: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.203, v_num=87, val_loss_epoch=0.515, train_loss_step=0.227, train_loss_epoch=0.186, val_loss_step=0.473]\n",
      "Epoch 76: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.203, v_num=87, val_loss_epoch=0.459, train_loss_step=0.235, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Epoch 77:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.88it/s]\u001b[A\n",
      "Epoch 77:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 77:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.58it/s]\u001b[A\n",
      "Epoch 77:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.31it/s]\u001b[A\n",
      "Epoch 77:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.55it/s]\u001b[A\n",
      "Epoch 77:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.29it/s]\u001b[A\n",
      "Epoch 77:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.73it/s]\u001b[A\n",
      "Epoch 77:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.65it/s]\u001b[A\n",
      "Epoch 77:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 77:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 77:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 77:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.30it/s]\u001b[A\n",
      "Epoch 77:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 77:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 77:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 77:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.31it/s]\u001b[A\n",
      "Epoch 77:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 77:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 77:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:20,  4.27it/s]\u001b[A\n",
      "Epoch 77:  89%|████████▉ | 696/780 [06:13<00:45,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 77:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.44it/s]\u001b[A\n",
      "Epoch 77:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.32it/s]\u001b[A\n",
      "Epoch 77:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 77:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.55it/s]\u001b[A\n",
      "Epoch 77:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 77:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 77:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.42it/s]\u001b[A\n",
      "Epoch 77:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.63it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.38it/s]\u001b[A\n",
      "Epoch 77:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 77:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.38it/s]\u001b[A\n",
      "Epoch 77:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 77:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.71it/s]\u001b[A\n",
      "Epoch 77:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.41it/s]\u001b[A\n",
      "Epoch 77:  94%|█████████▍| 732/780 [06:21<00:24,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 77:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 77:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.30it/s]\u001b[A\n",
      "Epoch 77:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 77:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.66it/s]\u001b[A\n",
      "Epoch 77:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.35it/s]\u001b[A\n",
      "Epoch 77:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 77:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 77:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 77:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.32it/s]\u001b[A\n",
      "Epoch 77:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 77:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 77:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.28it/s]\u001b[A\n",
      "Epoch 77:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 77:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 77:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.29it/s]\u001b[A\n",
      "Epoch 77:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.46it/s]\u001b[A\n",
      "Epoch 77:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 77:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 77:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.51it/s]\u001b[A\n",
      "Epoch 77:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.25it/s]\u001b[A\n",
      "Epoch 77:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 77:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 77: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 77: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.459, train_loss_step=0.251, train_loss_epoch=0.187, val_loss_step=0.467]\n",
      "Epoch 77: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.460, train_loss_step=0.0908, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Epoch 78:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:09,  1.75it/s]\u001b[A\n",
      "Epoch 78:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.02it/s]\u001b[A\n",
      "Epoch 78:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.78it/s]\u001b[A\n",
      "Epoch 78:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.94it/s]\u001b[A\n",
      "Epoch 78:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:   8%|▊         | 10/124 [00:03<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 78:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.41it/s]\u001b[A\n",
      "Epoch 78:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.34it/s]\u001b[A\n",
      "Epoch 78:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 78:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 78:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 78:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 78:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 78:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 78:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:21,  4.44it/s]\u001b[A\n",
      "Epoch 78:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.62it/s]\u001b[A\n",
      "Epoch 78:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 78:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.41it/s]\u001b[A\n",
      "Epoch 78:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 78:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 78:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 78:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.77it/s]\u001b[A\n",
      "Epoch 78:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.73it/s]\u001b[A\n",
      "Epoch 78:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.40it/s]\u001b[A\n",
      "Epoch 78:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 78:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 78:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 78:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.60it/s]\u001b[A\n",
      "Epoch 78:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.37it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.37it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.66it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 78:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.42it/s]\u001b[A\n",
      "Epoch 78:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 78:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.63it/s]\u001b[A\n",
      "Epoch 78:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.45it/s]\u001b[A\n",
      "Epoch 78:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.72it/s]\u001b[A\n",
      "Epoch 78:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 78:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 78:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 78:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 78:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.38it/s]\u001b[A\n",
      "Epoch 78:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 78:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 78:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.70it/s]\u001b[A\n",
      "Epoch 78:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 78:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 78:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 78:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.42it/s]\u001b[A\n",
      "Epoch 78:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 78:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 78:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.52it/s]\u001b[A\n",
      "Epoch 78:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 78:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.28it/s]\u001b[A\n",
      "Epoch 78:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.47it/s]\u001b[A\n",
      "Epoch 78:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.59it/s]\u001b[A\n",
      "Epoch 78:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.32it/s]\u001b[A\n",
      "Epoch 78:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 78:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.67it/s]\u001b[A\n",
      "Epoch 78:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.41it/s]\u001b[A\n",
      "Epoch 78: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  5.01it/s]\u001b[A\n",
      "Epoch 78: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.159, v_num=87, val_loss_epoch=0.460, train_loss_step=0.195, train_loss_epoch=0.175, val_loss_step=0.784]\n",
      "Epoch 78: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.159, v_num=87, val_loss_epoch=0.490, train_loss_step=0.0631, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Epoch 79:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.95it/s]\u001b[A\n",
      "Epoch 79:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.26it/s]\u001b[A\n",
      "Epoch 79:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.76it/s]\u001b[A\n",
      "Epoch 79:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.23it/s]\u001b[A\n",
      "Epoch 79:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.50it/s]\u001b[A\n",
      "Epoch 79:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.44it/s]\u001b[A\n",
      "Epoch 79:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.69it/s]\u001b[A\n",
      "Epoch 79:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 79:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 79:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 79:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.40it/s]\u001b[A\n",
      "Epoch 79:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 79:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 79:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.41it/s]\u001b[A\n",
      "Epoch 79:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 79:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.43it/s]\u001b[A\n",
      "Epoch 79:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.70it/s]\u001b[A\n",
      "Epoch 79:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.73it/s]\u001b[A\n",
      "Epoch 79:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.37it/s]\u001b[A\n",
      "Epoch 79:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 79:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 79:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.34it/s]\u001b[A\n",
      "Epoch 79:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.49it/s]\u001b[A\n",
      "Epoch 79:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 79:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.70it/s]\u001b[A\n",
      "Epoch 79:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 79:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.73it/s]\u001b[A\n",
      "Epoch 79:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.73it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.32it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.29it/s]\u001b[A\n",
      "Epoch 79:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.52it/s]\u001b[A\n",
      "Epoch 79:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 79:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.35it/s]\u001b[A\n",
      "Epoch 79:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 79:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 79:  94%|█████████▍| 732/780 [06:21<00:24,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.34it/s]\u001b[A\n",
      "Epoch 79:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 79:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 79:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 79:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.30it/s]\u001b[A\n",
      "Epoch 79:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 79:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 79:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 79:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 79:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 79:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 79:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 79:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 79:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 79:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 79:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 79:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.48it/s]\u001b[A\n",
      "Epoch 79:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.44it/s]\u001b[A\n",
      "Epoch 79:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.49it/s]\u001b[A\n",
      "Epoch 79:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 79:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.46it/s]\u001b[A\n",
      "Epoch 79:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.66it/s]\u001b[A\n",
      "Epoch 79:  99%|█████████▉| 776/780 [06:30<00:02,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.50it/s]\u001b[A\n",
      "Epoch 79: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.47it/s]\u001b[A\n",
      "Epoch 79: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.490, train_loss_step=0.196, train_loss_epoch=0.179, val_loss_step=0.314]\n",
      "Epoch 79: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.642, train_loss_step=0.174, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Epoch 80:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.86it/s]\u001b[A\n",
      "Epoch 80:  85%|████████▍ | 660/780 [06:07<01:06,  1.79it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 80:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.87it/s]\u001b[A\n",
      "Epoch 80:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.03it/s]\u001b[A\n",
      "Epoch 80:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 80:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 80:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 80:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 80:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.39it/s]\u001b[A\n",
      "Epoch 80:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.71it/s]\u001b[A\n",
      "Epoch 80:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 80:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 80:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.54it/s]\u001b[A\n",
      "Epoch 80:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.42it/s]\u001b[A\n",
      "Epoch 80:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 80:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 80:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.64it/s]\u001b[A\n",
      "Epoch 80:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.66it/s]\u001b[A\n",
      "Epoch 80:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.36it/s]\u001b[A\n",
      "Epoch 80:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 80:  89%|████████▉ | 698/780 [06:16<00:44,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.69it/s]\u001b[A\n",
      "Epoch 80:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.38it/s]\u001b[A\n",
      "Epoch 80:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.82it/s]\u001b[A\n",
      "Epoch 80:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.75it/s]\u001b[A\n",
      "Epoch 80:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 80:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.75it/s]\u001b[A\n",
      "Epoch 80:  91%|█████████ | 710/780 [06:18<00:37,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.56it/s]\u001b[A\n",
      "Epoch 80:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.52it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 716/780 [06:20<00:33,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.47it/s]\u001b[A\n",
      "Epoch 80:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.67it/s]\u001b[A\n",
      "Epoch 80:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.79it/s]\u001b[A\n",
      "Epoch 80:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 80:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 80:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 80:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 80:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.51it/s]\u001b[A\n",
      "Epoch 80:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 80:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.24it/s]\u001b[A\n",
      "Epoch 80:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 80:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 80:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.69it/s]\u001b[A\n",
      "Epoch 80:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.47it/s]\u001b[A\n",
      "Epoch 80:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.71it/s]\u001b[A\n",
      "Epoch 80:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 80:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.39it/s]\u001b[A\n",
      "Epoch 80:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 80:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 80:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.30it/s]\u001b[A\n",
      "Epoch 80:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 80:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 80:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.28it/s]\u001b[A\n",
      "Epoch 80:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 80:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.51it/s]\u001b[A\n",
      "Epoch 80:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.38it/s]\u001b[A\n",
      "Epoch 80:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.63it/s]\u001b[A\n",
      "Epoch 80:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 80:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 80: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.31it/s]\u001b[A\n",
      "Epoch 80: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.642, train_loss_step=0.158, train_loss_epoch=0.180, val_loss_step=0.418]\n",
      "Epoch 80: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.494, train_loss_step=0.161, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Epoch 81:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.92it/s]\u001b[A\n",
      "Epoch 81:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 81:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.81it/s]\u001b[A\n",
      "Epoch 81:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 81:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.23it/s]\u001b[A\n",
      "Epoch 81:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 81:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.40it/s]\u001b[A\n",
      "Epoch 81:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 81:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 81:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 81:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.79it/s]\u001b[A\n",
      "Epoch 81:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.71it/s]\u001b[A\n",
      "Epoch 81:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 81:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 81:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.48it/s]\u001b[A\n",
      "Epoch 81:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 81:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 81:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 81:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 81:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.28it/s]\u001b[A\n",
      "Epoch 81:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 81:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.72it/s]\u001b[A\n",
      "Epoch 81:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.36it/s]\u001b[A\n",
      "Epoch 81:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:15,  4.76it/s]\u001b[A\n",
      "Epoch 81:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 81:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.28it/s]\u001b[A\n",
      "Epoch 81:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.38it/s]\u001b[A\n",
      "Epoch 81:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.29it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.53it/s]\u001b[A\n",
      "Epoch 81:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.34it/s]\u001b[A\n",
      "Epoch 81:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.47it/s]\u001b[A\n",
      "Epoch 81:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.63it/s]\u001b[A\n",
      "Epoch 81:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 81:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 81:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 81:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.36it/s]\u001b[A\n",
      "Epoch 81:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 81:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 81:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 81:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.70it/s]\u001b[A\n",
      "Epoch 81:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 81:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 81:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 81:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 81:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 81:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.34it/s]\u001b[A\n",
      "Epoch 81:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.49it/s]\u001b[A\n",
      "Epoch 81:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 81:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 81:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.72it/s]\u001b[A\n",
      "Epoch 81:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.59it/s]\u001b[A\n",
      "Epoch 81:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.41it/s]\u001b[A\n",
      "Epoch 81:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 81:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 81:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.42it/s]\u001b[A\n",
      "Epoch 81:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.67it/s]\u001b[A\n",
      "Epoch 81:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 81: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.50it/s]\u001b[A\n",
      "Epoch 81: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.222, v_num=87, val_loss_epoch=0.494, train_loss_step=0.184, train_loss_epoch=0.179, val_loss_step=0.350]\n",
      "Epoch 81: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.222, v_num=87, val_loss_epoch=0.532, train_loss_step=0.240, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Epoch 82:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 82:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.30it/s]\u001b[A\n",
      "Epoch 82:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  3.97it/s]\u001b[A\n",
      "Epoch 82:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.02it/s]\u001b[A\n",
      "Epoch 82:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 82:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.53it/s]\u001b[A\n",
      "Epoch 82:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.27it/s]\u001b[A\n",
      "Epoch 82:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.46it/s]\u001b[A\n",
      "Epoch 82:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 82:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 82:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 82:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.52it/s]\u001b[A\n",
      "Epoch 82:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.40it/s]\u001b[A\n",
      "Epoch 82:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 82:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 82:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.43it/s]\u001b[A\n",
      "Epoch 82:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.49it/s]\u001b[A\n",
      "Epoch 82:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 82:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 82:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 82:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 82:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 82:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 82:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.68it/s]\u001b[A\n",
      "Epoch 82:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 82:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 82:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 82:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.49it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:11,  5.46it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:11,  5.20it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.76it/s]\u001b[A\n",
      "Epoch 82:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 82:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 82:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 82:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 82:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.41it/s]\u001b[A\n",
      "Epoch 82:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 82:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.45it/s]\u001b[A\n",
      "Epoch 82:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 82:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 82:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.31it/s]\u001b[A\n",
      "Epoch 82:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 82:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 82:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.35it/s]\u001b[A\n",
      "Epoch 82:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 82:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 82:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.25it/s]\u001b[A\n",
      "Epoch 82:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 82:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 82:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.71it/s]\u001b[A\n",
      "Epoch 82:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.37it/s]\u001b[A\n",
      "Epoch 82:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 82:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 82:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.31it/s]\u001b[A\n",
      "Epoch 82:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.47it/s]\u001b[A\n",
      "Epoch 82:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 82:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.32it/s]\u001b[A\n",
      "Epoch 82:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 82:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.55it/s]\u001b[A\n",
      "Epoch 82: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 82: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.189, v_num=87, val_loss_epoch=0.532, train_loss_step=0.124, train_loss_epoch=0.181, val_loss_step=0.450]\n",
      "Epoch 82: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.495, train_loss_step=0.0532, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Epoch 83:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.01it/s]\u001b[A\n",
      "Epoch 83:  85%|████████▍ | 660/780 [06:03<01:06,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 83:  85%|████████▍ | 662/780 [06:04<01:04,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.70it/s]\u001b[A\n",
      "Epoch 83:  85%|████████▌ | 664/780 [06:04<01:03,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.27it/s]\u001b[A\n",
      "Epoch 83:  85%|████████▌ | 666/780 [06:04<01:02,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 83:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.31it/s]\u001b[A\n",
      "Epoch 83:  86%|████████▌ | 670/780 [06:05<01:00,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 83:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 83:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.38it/s]\u001b[A\n",
      "Epoch 83:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 83:  87%|████████▋ | 678/780 [06:07<00:55,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 83:  87%|████████▋ | 680/780 [06:08<00:54,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.63it/s]\u001b[A\n",
      "Epoch 83:  87%|████████▋ | 682/780 [06:08<00:52,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.31it/s]\u001b[A\n",
      "Epoch 83:  88%|████████▊ | 684/780 [06:08<00:51,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.51it/s]\u001b[A\n",
      "Epoch 83:  88%|████████▊ | 686/780 [06:09<00:50,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 83:  88%|████████▊ | 688/780 [06:09<00:49,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.31it/s]\u001b[A\n",
      "Epoch 83:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.55it/s]\u001b[A\n",
      "Epoch 83:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 83:  89%|████████▉ | 694/780 [06:11<00:45,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 83:  89%|████████▉ | 696/780 [06:11<00:44,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 83:  89%|████████▉ | 698/780 [06:12<00:43,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 83:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.41it/s]\u001b[A\n",
      "Epoch 83:  90%|█████████ | 702/780 [06:12<00:41,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 83:  90%|█████████ | 704/780 [06:13<00:40,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 83:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 83:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 83:  91%|█████████ | 710/780 [06:14<00:36,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 83:  91%|█████████▏| 712/780 [06:15<00:35,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.39it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 718/780 [06:16<00:32,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 720/780 [06:16<00:31,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.42it/s]\u001b[A\n",
      "Epoch 83:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 83:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 83:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.46it/s]\u001b[A\n",
      "Epoch 83:  93%|█████████▎| 728/780 [06:18<00:27,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.60it/s]\u001b[A\n",
      "Epoch 83:  94%|█████████▎| 730/780 [06:19<00:25,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 83:  94%|█████████▍| 732/780 [06:19<00:24,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.43it/s]\u001b[A\n",
      "Epoch 83:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 83:  94%|█████████▍| 736/780 [06:20<00:22,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 83:  95%|█████████▍| 738/780 [06:20<00:21,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 83:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.52it/s]\u001b[A\n",
      "Epoch 83:  95%|█████████▌| 742/780 [06:21<00:19,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 83:  95%|█████████▌| 744/780 [06:22<00:18,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 83:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.33it/s]\u001b[A\n",
      "Epoch 83:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 83:  96%|█████████▌| 750/780 [06:23<00:15,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 83:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 83:  97%|█████████▋| 754/780 [06:24<00:13,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 83:  97%|█████████▋| 756/780 [06:24<00:12,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 83:  97%|█████████▋| 758/780 [06:25<00:11,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 83:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 83:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.30it/s]\u001b[A\n",
      "Epoch 83:  98%|█████████▊| 764/780 [06:26<00:08,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 83:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 83:  98%|█████████▊| 768/780 [06:27<00:06,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 83:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 83:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 83:  99%|█████████▉| 774/780 [06:28<00:03,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 83:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.29it/s]\u001b[A\n",
      "Epoch 83: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.47it/s]\u001b[A\n",
      "Epoch 83: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.163, v_num=87, val_loss_epoch=0.495, train_loss_step=0.160, train_loss_epoch=0.182, val_loss_step=0.600]\n",
      "Epoch 83: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.163, v_num=87, val_loss_epoch=0.548, train_loss_step=0.155, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Epoch 84:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:58,  2.07it/s]\u001b[A\n",
      "Epoch 84:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 84:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.69it/s]\u001b[A\n",
      "Epoch 84:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.20it/s]\u001b[A\n",
      "Epoch 84:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 84:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.28it/s]\u001b[A\n",
      "Epoch 84:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 84:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.37it/s]\u001b[A\n",
      "Epoch 84:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 84:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 84:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 84:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 84:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 84:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.27it/s]\u001b[A\n",
      "Epoch 84:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 84:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 84:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.68it/s]\u001b[A\n",
      "Epoch 84:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 84:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.47it/s]\u001b[A\n",
      "Epoch 84:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 84:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:19,  4.27it/s]\u001b[A\n",
      "Epoch 84:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 84:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.53it/s]\u001b[A\n",
      "Epoch 84:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.30it/s]\u001b[A\n",
      "Epoch 84:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 84:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 84:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.34it/s]\u001b[A\n",
      "Epoch 84:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.40it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 84:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 84:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 84:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.70it/s]\u001b[A\n",
      "Epoch 84:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.60it/s]\u001b[A\n",
      "Epoch 84:  94%|█████████▎| 730/780 [06:21<00:26,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.42it/s]\u001b[A\n",
      "Epoch 84:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.75it/s]\u001b[A\n",
      "Epoch 84:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.65it/s]\u001b[A\n",
      "Epoch 84:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 84:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 84:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 84:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 84:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 84:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 84:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 84:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.48it/s]\u001b[A\n",
      "Epoch 84:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 84:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 84:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 84:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.65it/s]\u001b[A\n",
      "Epoch 84:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 84:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 84:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 84:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.43it/s]\u001b[A\n",
      "Epoch 84:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 84:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.67it/s]\u001b[A\n",
      "Epoch 84:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 84:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.60it/s]\u001b[A\n",
      "Epoch 84:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.65it/s]\u001b[A\n",
      "Epoch 84: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.32it/s]\u001b[A\n",
      "Epoch 84: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.548, train_loss_step=0.237, train_loss_epoch=0.177, val_loss_step=0.358]\n",
      "Epoch 84: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.198, v_num=87, val_loss_epoch=0.483, train_loss_step=0.199, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Epoch 85:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.85it/s]\u001b[A\n",
      "Epoch 85:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.10it/s]\u001b[A\n",
      "Epoch 85:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.71it/s]\u001b[A\n",
      "Epoch 85:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.25it/s]\u001b[A\n",
      "Epoch 85:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.23it/s]\u001b[A\n",
      "Epoch 85:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 85:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.62it/s]\u001b[A\n",
      "Epoch 85:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 85:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.68it/s]\u001b[A\n",
      "Epoch 85:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 85:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.28it/s]\u001b[A\n",
      "Epoch 85:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.50it/s]\u001b[A\n",
      "Epoch 85:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.63it/s]\u001b[A\n",
      "Epoch 85:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 85:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.55it/s]\u001b[A\n",
      "Epoch 85:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.52it/s]\u001b[A\n",
      "Epoch 85:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.30it/s]\u001b[A\n",
      "Epoch 85:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 85:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 85:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 85:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 85:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 85:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 85:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 85:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 85:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.33it/s]\u001b[A\n",
      "Epoch 85:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 85:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.60it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.38it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.49it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.57it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.33it/s]\u001b[A\n",
      "Epoch 85:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 85:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.45it/s]\u001b[A\n",
      "Epoch 85:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 85:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.24it/s]\u001b[A\n",
      "Epoch 85:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 85:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 85:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.33it/s]\u001b[A\n",
      "Epoch 85:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 85:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 85:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 85:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 85:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 85:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.36it/s]\u001b[A\n",
      "Epoch 85:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 85:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 85:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 85:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.49it/s]\u001b[A\n",
      "Epoch 85:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 85:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.64it/s]\u001b[A\n",
      "Epoch 85:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 85:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 85:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.59it/s]\u001b[A\n",
      "Epoch 85:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.37it/s]\u001b[A\n",
      "Epoch 85:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.47it/s]\u001b[A\n",
      "Epoch 85:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.24it/s]\u001b[A\n",
      "Epoch 85:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.70it/s]\u001b[A\n",
      "Epoch 85:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.66it/s]\u001b[A\n",
      "Epoch 85:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.36it/s]\u001b[A\n",
      "Epoch 85: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.72it/s]\u001b[A\n",
      "Epoch 85: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.483, train_loss_step=0.300, train_loss_epoch=0.177, val_loss_step=0.441]\n",
      "Epoch 85: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.580, train_loss_step=0.0883, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Epoch 86:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 86:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.03it/s]\u001b[A\n",
      "Epoch 86:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.77it/s]\u001b[A\n",
      "Epoch 86:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.26it/s]\u001b[A\n",
      "Epoch 86:  85%|████████▌ | 666/780 [06:08<01:02,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.54it/s]\u001b[A\n",
      "Epoch 86:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 86:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 86:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 86:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.35it/s]\u001b[A\n",
      "Epoch 86:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.50it/s]\u001b[A\n",
      "Epoch 86:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 86:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.31it/s]\u001b[A\n",
      "Epoch 86:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.48it/s]\u001b[A\n",
      "Epoch 86:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 86:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 86:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.47it/s]\u001b[A\n",
      "Epoch 86:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 86:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.29it/s]\u001b[A\n",
      "Epoch 86:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.41it/s]\u001b[A\n",
      "Epoch 86:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.47it/s]\u001b[A\n",
      "Epoch 86:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 86:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.38it/s]\u001b[A\n",
      "Epoch 86:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 86:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 86:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 86:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 86:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.51it/s]\u001b[A\n",
      "Epoch 86:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.64it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.45it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.48it/s]\u001b[A\n",
      "Epoch 86:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.23it/s]\u001b[A\n",
      "Epoch 86:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.38it/s]\u001b[A\n",
      "Epoch 86:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.52it/s]\u001b[A\n",
      "Epoch 86:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 86:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.31it/s]\u001b[A\n",
      "Epoch 86:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.49it/s]\u001b[A\n",
      "Epoch 86:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 86:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.31it/s]\u001b[A\n",
      "Epoch 86:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 86:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 86:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.27it/s]\u001b[A\n",
      "Epoch 86:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 86:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 86:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.41it/s]\u001b[A\n",
      "Epoch 86:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 86:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 86:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.36it/s]\u001b[A\n",
      "Epoch 86:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 86:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.63it/s]\u001b[A\n",
      "Epoch 86:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 86:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.36it/s]\u001b[A\n",
      "Epoch 86:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 86:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 86:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.38it/s]\u001b[A\n",
      "Epoch 86:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 86:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 86:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.49it/s]\u001b[A\n",
      "Epoch 86:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 86: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.34it/s]\u001b[A\n",
      "Epoch 86: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.580, train_loss_step=0.428, train_loss_epoch=0.174, val_loss_step=0.614]\n",
      "Epoch 86: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.175, v_num=87, val_loss_epoch=0.550, train_loss_step=0.216, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Epoch 87:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.98it/s]\u001b[A\n",
      "Epoch 87:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.01it/s]\u001b[A\n",
      "Epoch 87:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 87:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.26it/s]\u001b[A\n",
      "Epoch 87:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.15it/s]\u001b[A\n",
      "Epoch 87:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.48it/s]\u001b[A\n",
      "Epoch 87:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.69it/s]\u001b[A\n",
      "Epoch 87:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 87:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.36it/s]\u001b[A\n",
      "Epoch 87:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 87:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 87:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.30it/s]\u001b[A\n",
      "Epoch 87:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 87:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.50it/s]\u001b[A\n",
      "Epoch 87:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:22,  4.24it/s]\u001b[A\n",
      "Epoch 87:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 87:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 87:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.43it/s]\u001b[A\n",
      "Epoch 87:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 87:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.62it/s]\u001b[A\n",
      "Epoch 87:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 87:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 87:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 87:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.54it/s]\u001b[A\n",
      "Epoch 87:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.32it/s]\u001b[A\n",
      "Epoch 87:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.68it/s]\u001b[A\n",
      "Epoch 87:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 87:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.64it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.38it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 87:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.59it/s]\u001b[A\n",
      "Epoch 87:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.46it/s]\u001b[A\n",
      "Epoch 87:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.64it/s]\u001b[A\n",
      "Epoch 87:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.38it/s]\u001b[A\n",
      "Epoch 87:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.45it/s]\u001b[A\n",
      "Epoch 87:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 87:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 87:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 87:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 87:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.73it/s]\u001b[A\n",
      "Epoch 87:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.37it/s]\u001b[A\n",
      "Epoch 87:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.75it/s]\u001b[A\n",
      "Epoch 87:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.71it/s]\u001b[A\n",
      "Epoch 87:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.31it/s]\u001b[A\n",
      "Epoch 87:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 87:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 87:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.24it/s]\u001b[A\n",
      "Epoch 87:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 87:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 87:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.32it/s]\u001b[A\n",
      "Epoch 87:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.72it/s]\u001b[A\n",
      "Epoch 87:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 87:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 87:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.36it/s]\u001b[A\n",
      "Epoch 87:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 87:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 87:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.30it/s]\u001b[A\n",
      "Epoch 87:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.49it/s]\u001b[A\n",
      "Epoch 87: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 87: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.550, train_loss_step=0.209, train_loss_epoch=0.175, val_loss_step=0.353]\n",
      "Epoch 87: 100%|██████████| 780/780 [06:32<00:00,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.696, train_loss_step=0.487, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Epoch 88:  84%|████████▍ | 656/780 [06:08<01:09,  1.78it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 88:  85%|████████▍ | 660/780 [06:09<01:07,  1.78it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 88:  85%|████████▍ | 662/780 [06:10<01:05,  1.79it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.79it/s]\u001b[A\n",
      "Epoch 88:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 88:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 88:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.59it/s]\u001b[A\n",
      "Epoch 88:  86%|████████▌ | 670/780 [06:11<01:01,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 88:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.36it/s]\u001b[A\n",
      "Epoch 88:  86%|████████▋ | 674/780 [06:12<00:58,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.67it/s]\u001b[A\n",
      "Epoch 88:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 88:  87%|████████▋ | 678/780 [06:13<00:56,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 88:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.69it/s]\u001b[A\n",
      "Epoch 88:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 88:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 88:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 88:  88%|████████▊ | 688/780 [06:15<00:50,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.54it/s]\u001b[A\n",
      "Epoch 88:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 88:  89%|████████▊ | 692/780 [06:16<00:47,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.36it/s]\u001b[A\n",
      "Epoch 88:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 88:  89%|████████▉ | 696/780 [06:17<00:45,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 88:  89%|████████▉ | 698/780 [06:18<00:44,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 88:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 88:  90%|█████████ | 702/780 [06:18<00:42,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 88:  90%|█████████ | 704/780 [06:19<00:40,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 88:  91%|█████████ | 706/780 [06:19<00:39,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.72it/s]\u001b[A\n",
      "Epoch 88:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.66it/s]\u001b[A\n",
      "Epoch 88:  91%|█████████ | 710/780 [06:20<00:37,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 88:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 714/780 [06:21<00:35,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.66it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 718/780 [06:22<00:33,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 720/780 [06:22<00:31,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 88:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.54it/s]\u001b[A\n",
      "Epoch 88:  93%|█████████▎| 724/780 [06:23<00:29,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.37it/s]\u001b[A\n",
      "Epoch 88:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 88:  93%|█████████▎| 728/780 [06:24<00:27,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.64it/s]\u001b[A\n",
      "Epoch 88:  94%|█████████▎| 730/780 [06:25<00:26,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.47it/s]\u001b[A\n",
      "Epoch 88:  94%|█████████▍| 732/780 [06:25<00:25,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.65it/s]\u001b[A\n",
      "Epoch 88:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 88:  94%|█████████▍| 736/780 [06:26<00:23,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 88:  95%|█████████▍| 738/780 [06:26<00:22,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 88:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.50it/s]\u001b[A\n",
      "Epoch 88:  95%|█████████▌| 742/780 [06:27<00:19,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 88:  95%|█████████▌| 744/780 [06:28<00:18,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 88:  96%|█████████▌| 746/780 [06:28<00:17,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 88:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 88:  96%|█████████▌| 750/780 [06:29<00:15,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.38it/s]\u001b[A\n",
      "Epoch 88:  96%|█████████▋| 752/780 [06:30<00:14,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 88:  97%|█████████▋| 754/780 [06:30<00:13,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.42it/s]\u001b[A\n",
      "Epoch 88:  97%|█████████▋| 756/780 [06:30<00:12,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 88:  97%|█████████▋| 758/780 [06:31<00:11,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.67it/s]\u001b[A\n",
      "Epoch 88:  97%|█████████▋| 760/780 [06:31<00:10,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.50it/s]\u001b[A\n",
      "Epoch 88:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.67it/s]\u001b[A\n",
      "Epoch 88:  98%|█████████▊| 764/780 [06:32<00:08,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.72it/s]\u001b[A\n",
      "Epoch 88:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.34it/s]\u001b[A\n",
      "Epoch 88:  98%|█████████▊| 768/780 [06:33<00:06,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.45it/s]\u001b[A\n",
      "Epoch 88:  99%|█████████▊| 770/780 [06:33<00:05,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 88:  99%|█████████▉| 772/780 [06:34<00:04,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.35it/s]\u001b[A\n",
      "Epoch 88:  99%|█████████▉| 774/780 [06:34<00:03,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.49it/s]\u001b[A\n",
      "Epoch 88:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.55it/s]\u001b[A\n",
      "Epoch 88: 100%|█████████▉| 778/780 [06:35<00:01,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 88: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.696, train_loss_step=0.222, train_loss_epoch=0.175, val_loss_step=0.733]\n",
      "Epoch 88: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.517, train_loss_step=0.119, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Epoch 89:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:58,  2.09it/s]\u001b[A\n",
      "Epoch 89:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.28it/s]\u001b[A\n",
      "Epoch 89:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.81it/s]\u001b[A\n",
      "Epoch 89:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 89:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.39it/s]\u001b[A\n",
      "Epoch 89:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.34it/s]\u001b[A\n",
      "Epoch 89:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 89:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.46it/s]\u001b[A\n",
      "Epoch 89:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.65it/s]\u001b[A\n",
      "Epoch 89:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 89:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.34it/s]\u001b[A\n",
      "Epoch 89:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.49it/s]\u001b[A\n",
      "Epoch 89:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 89:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.32it/s]\u001b[A\n",
      "Epoch 89:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 89:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.72it/s]\u001b[A\n",
      "Epoch 89:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:15,  5.73it/s]\u001b[A\n",
      "Epoch 89:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:16,  5.20it/s]\u001b[A\n",
      "Epoch 89:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 89:  89%|████████▉ | 696/780 [06:13<00:45,  1.87it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.77it/s]\u001b[A\n",
      "Epoch 89:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.74it/s]\u001b[A\n",
      "Epoch 89:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 89:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 89:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 89:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.26it/s]\u001b[A\n",
      "Epoch 89:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  42%|████▏     | 52/124 [00:11<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 89:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 89:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:15,  4.28it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.33it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.69it/s]\u001b[A\n",
      "Epoch 89:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 89:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 89:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:12,  4.27it/s]\u001b[A\n",
      "Epoch 89:  93%|█████████▎| 728/780 [06:20<00:27,  1.92it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 89:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 89:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.27it/s]\u001b[A\n",
      "Epoch 89:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 89:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 89:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.39it/s]\u001b[A\n",
      "Epoch 89:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 89:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 89:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:08,  4.38it/s]\u001b[A\n",
      "Epoch 89:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 89:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 89:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 89:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 89:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 89:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 89:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.40it/s]\u001b[A\n",
      "Epoch 89:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.56it/s]\u001b[A\n",
      "Epoch 89:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 89:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 89:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.60it/s]\u001b[A\n",
      "Epoch 89:  98%|█████████▊| 768/780 [06:28<00:06,  1.97it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.31it/s]\u001b[A\n",
      "Epoch 89:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.47it/s]\u001b[A\n",
      "Epoch 89:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.55it/s]\u001b[A\n",
      "Epoch 89:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.35it/s]\u001b[A\n",
      "Epoch 89:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 89: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 89: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.14, v_num=87, val_loss_epoch=0.517, train_loss_step=0.211, train_loss_epoch=0.172, val_loss_step=0.402]\n",
      "Epoch 89: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.14, v_num=87, val_loss_epoch=0.568, train_loss_step=0.0791, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Epoch 90:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:04,  1.90it/s]\u001b[A\n",
      "Epoch 90:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.01it/s]\u001b[A\n",
      "Epoch 90:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.71it/s]\u001b[A\n",
      "Epoch 90:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.16it/s]\u001b[A\n",
      "Epoch 90:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.37it/s]\u001b[A\n",
      "Epoch 90:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.33it/s]\u001b[A\n",
      "Epoch 90:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.55it/s]\u001b[A\n",
      "Epoch 90:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 90:  86%|████████▋ | 674/780 [06:08<00:58,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 90:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 90:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 90:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.44it/s]\u001b[A\n",
      "Epoch 90:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.51it/s]\u001b[A\n",
      "Epoch 90:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:22,  4.25it/s]\u001b[A\n",
      "Epoch 90:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.39it/s]\u001b[A\n",
      "Epoch 90:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 90:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.31it/s]\u001b[A\n",
      "Epoch 90:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 90:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 90:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.59it/s]\u001b[A\n",
      "Epoch 90:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.32it/s]\u001b[A\n",
      "Epoch 90:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.52it/s]\u001b[A\n",
      "Epoch 90:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.69it/s]\u001b[A\n",
      "Epoch 90:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 90:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.50it/s]\u001b[A\n",
      "Epoch 90:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.48it/s]\u001b[A\n",
      "Epoch 90:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.32it/s]\u001b[A\n",
      "Epoch 90:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.46it/s]\u001b[A\n",
      "Epoch 90:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 90:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.45it/s]\u001b[A\n",
      "Epoch 90:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 90:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.59it/s]\u001b[A\n",
      "Epoch 90:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.30it/s]\u001b[A\n",
      "Epoch 90:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 90:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.45it/s]\u001b[A\n",
      "Epoch 90:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 90:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 90:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 90:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.65it/s]\u001b[A\n",
      "Epoch 90:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 90:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.34it/s]\u001b[A\n",
      "Epoch 90:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.45it/s]\u001b[A\n",
      "Epoch 90:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 90:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 90:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 90:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 90:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  5.48it/s]\u001b[A\n",
      "Epoch 90:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:03,  5.07it/s]\u001b[A\n",
      "Epoch 90:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 90:  98%|█████████▊| 764/780 [06:28<00:08,  1.96it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.67it/s]\u001b[A\n",
      "Epoch 90:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 90:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.31it/s]\u001b[A\n",
      "Epoch 90:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.41it/s]\u001b[A\n",
      "Epoch 90:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 90:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.31it/s]\u001b[A\n",
      "Epoch 90:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 90: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.34it/s]\u001b[A\n",
      "Epoch 90: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.187, v_num=87, val_loss_epoch=0.568, train_loss_step=0.225, train_loss_epoch=0.172, val_loss_step=0.484]\n",
      "Epoch 90: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.187, v_num=87, val_loss_epoch=0.548, train_loss_step=0.160, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Epoch 91:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  2.00it/s]\u001b[A\n",
      "Epoch 91:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.20it/s]\u001b[A\n",
      "Epoch 91:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.69it/s]\u001b[A\n",
      "Epoch 91:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.25it/s]\u001b[A\n",
      "Epoch 91:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 91:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 91:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.26it/s]\u001b[A\n",
      "Epoch 91:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.42it/s]\u001b[A\n",
      "Epoch 91:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.50it/s]\u001b[A\n",
      "Epoch 91:  87%|████████▋ | 676/780 [06:08<00:56,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.34it/s]\u001b[A\n",
      "Epoch 91:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 91:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 91:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 91:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 91:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.49it/s]\u001b[A\n",
      "Epoch 91:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 91:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 91:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 91:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 91:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 91:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 91:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.62it/s]\u001b[A\n",
      "Epoch 91:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 91:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 91:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 91:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.40it/s]\u001b[A\n",
      "Epoch 91:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 91:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.34it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 714/780 [06:16<00:34,  1.89it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.68it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.36it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 91:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 91:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:13,  4.30it/s]\u001b[A\n",
      "Epoch 91:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 91:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 91:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 91:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.49it/s]\u001b[A\n",
      "Epoch 91:  94%|█████████▍| 734/780 [06:21<00:23,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 91:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 91:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.38it/s]\u001b[A\n",
      "Epoch 91:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 91:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.56it/s]\u001b[A\n",
      "Epoch 91:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.31it/s]\u001b[A\n",
      "Epoch 91:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 91:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 91:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 91:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.48it/s]\u001b[A\n",
      "Epoch 91:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 91:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 91:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 91:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 91:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 91:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.36it/s]\u001b[A\n",
      "Epoch 91:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 91:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.66it/s]\u001b[A\n",
      "Epoch 91:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.40it/s]\u001b[A\n",
      "Epoch 91:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.53it/s]\u001b[A\n",
      "Epoch 91:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 91:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.46it/s]\u001b[A\n",
      "Epoch 91: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 91: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.15, v_num=87, val_loss_epoch=0.548, train_loss_step=0.0753, train_loss_epoch=0.174, val_loss_step=0.757]\n",
      "Epoch 91: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.15, v_num=87, val_loss_epoch=0.499, train_loss_step=0.232, train_loss_epoch=0.169, val_loss_step=0.707] \n",
      "Epoch 92:  84%|████████▍ | 656/780 [06:01<01:08,  1.81it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  84%|████████▍ | 658/780 [06:02<01:07,  1.81it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.05it/s]\u001b[A\n",
      "Epoch 92:  85%|████████▍ | 660/780 [06:03<01:06,  1.82it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.22it/s]\u001b[A\n",
      "Epoch 92:  85%|████████▍ | 662/780 [06:03<01:04,  1.82it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.78it/s]\u001b[A\n",
      "Epoch 92:  85%|████████▌ | 664/780 [06:04<01:03,  1.82it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 92:  85%|████████▌ | 666/780 [06:04<01:02,  1.83it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.24it/s]\u001b[A\n",
      "Epoch 92:  86%|████████▌ | 668/780 [06:05<01:01,  1.83it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.66it/s]\u001b[A\n",
      "Epoch 92:  86%|████████▌ | 670/780 [06:05<01:00,  1.83it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 92:  86%|████████▌ | 672/780 [06:06<00:58,  1.84it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 92:  86%|████████▋ | 674/780 [06:06<00:57,  1.84it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.73it/s]\u001b[A\n",
      "Epoch 92:  87%|████████▋ | 676/780 [06:06<00:56,  1.84it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 92:  87%|████████▋ | 678/780 [06:07<00:55,  1.85it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.35it/s]\u001b[A\n",
      "Epoch 92:  87%|████████▋ | 680/780 [06:07<00:54,  1.85it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.49it/s]\u001b[A\n",
      "Epoch 92:  87%|████████▋ | 682/780 [06:08<00:52,  1.85it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 92:  88%|████████▊ | 684/780 [06:08<00:51,  1.86it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 92:  88%|████████▊ | 686/780 [06:09<00:50,  1.86it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 92:  88%|████████▊ | 688/780 [06:09<00:49,  1.86it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.66it/s]\u001b[A\n",
      "Epoch 92:  88%|████████▊ | 690/780 [06:09<00:48,  1.86it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 92:  89%|████████▊ | 692/780 [06:10<00:47,  1.87it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 92:  89%|████████▉ | 694/780 [06:10<00:45,  1.87it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.73it/s]\u001b[A\n",
      "Epoch 92:  89%|████████▉ | 696/780 [06:11<00:44,  1.87it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.64it/s]\u001b[A\n",
      "Epoch 92:  89%|████████▉ | 698/780 [06:11<00:43,  1.88it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.34it/s]\u001b[A\n",
      "Epoch 92:  90%|████████▉ | 700/780 [06:12<00:42,  1.88it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.51it/s]\u001b[A\n",
      "Epoch 92:  90%|█████████ | 702/780 [06:12<00:41,  1.88it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 92:  90%|█████████ | 704/780 [06:13<00:40,  1.89it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.28it/s]\u001b[A\n",
      "Epoch 92:  91%|█████████ | 706/780 [06:13<00:39,  1.89it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 92:  91%|█████████ | 708/780 [06:13<00:38,  1.89it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.57it/s]\u001b[A\n",
      "Epoch 92:  91%|█████████ | 710/780 [06:14<00:36,  1.90it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.29it/s]\u001b[A\n",
      "Epoch 92:  91%|█████████▏| 712/780 [06:14<00:35,  1.90it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 714/780 [06:15<00:34,  1.90it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 716/780 [06:15<00:33,  1.91it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 718/780 [06:16<00:32,  1.91it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.30it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 720/780 [06:16<00:31,  1.91it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 92:  93%|█████████▎| 722/780 [06:17<00:30,  1.91it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.54it/s]\u001b[A\n",
      "Epoch 92:  93%|█████████▎| 724/780 [06:17<00:29,  1.92it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 92:  93%|█████████▎| 726/780 [06:17<00:28,  1.92it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 92:  93%|█████████▎| 728/780 [06:18<00:27,  1.92it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 92:  94%|█████████▎| 730/780 [06:18<00:25,  1.93it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 92:  94%|█████████▍| 732/780 [06:19<00:24,  1.93it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.51it/s]\u001b[A\n",
      "Epoch 92:  94%|█████████▍| 734/780 [06:19<00:23,  1.93it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 92:  94%|█████████▍| 736/780 [06:20<00:22,  1.94it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 92:  95%|█████████▍| 738/780 [06:20<00:21,  1.94it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.61it/s]\u001b[A\n",
      "Epoch 92:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.57it/s]\u001b[A\n",
      "Epoch 92:  95%|█████████▌| 742/780 [06:21<00:19,  1.94it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 92:  95%|█████████▌| 744/780 [06:22<00:18,  1.95it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 92:  96%|█████████▌| 746/780 [06:22<00:17,  1.95it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 92:  96%|█████████▌| 748/780 [06:22<00:16,  1.95it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 92:  96%|█████████▌| 750/780 [06:23<00:15,  1.96it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 92:  96%|█████████▋| 752/780 [06:23<00:14,  1.96it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 92:  97%|█████████▋| 754/780 [06:24<00:13,  1.96it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 92:  97%|█████████▋| 756/780 [06:24<00:12,  1.97it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.41it/s]\u001b[A\n",
      "Epoch 92:  97%|█████████▋| 758/780 [06:25<00:11,  1.97it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.64it/s]\u001b[A\n",
      "Epoch 92:  97%|█████████▋| 760/780 [06:25<00:10,  1.97it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.57it/s]\u001b[A\n",
      "Epoch 92:  98%|█████████▊| 762/780 [06:25<00:09,  1.97it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 92:  98%|█████████▊| 764/780 [06:26<00:08,  1.98it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 92:  98%|█████████▊| 766/780 [06:26<00:07,  1.98it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.42it/s]\u001b[A\n",
      "Epoch 92:  98%|█████████▊| 768/780 [06:27<00:06,  1.98it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.74it/s]\u001b[A\n",
      "Epoch 92:  99%|█████████▊| 770/780 [06:27<00:05,  1.99it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.69it/s]\u001b[A\n",
      "Epoch 92:  99%|█████████▉| 772/780 [06:28<00:04,  1.99it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.36it/s]\u001b[A\n",
      "Epoch 92:  99%|█████████▉| 774/780 [06:28<00:03,  1.99it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.79it/s]\u001b[A\n",
      "Epoch 92:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 92: 100%|█████████▉| 778/780 [06:29<00:01,  2.00it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 92: 100%|██████████| 780/780 [06:29<00:00,  2.00it/s, loss=0.161, v_num=87, val_loss_epoch=0.499, train_loss_step=0.512, train_loss_epoch=0.169, val_loss_step=0.707]\n",
      "Epoch 92: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.161, v_num=87, val_loss_epoch=0.540, train_loss_step=0.140, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Epoch 93:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 93:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.04it/s]\u001b[A\n",
      "Epoch 93:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.76it/s]\u001b[A\n",
      "Epoch 93:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 93:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.15it/s]\u001b[A\n",
      "Epoch 93:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 93:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.58it/s]\u001b[A\n",
      "Epoch 93:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.24it/s]\u001b[A\n",
      "Epoch 93:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.47it/s]\u001b[A\n",
      "Epoch 93:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.50it/s]\u001b[A\n",
      "Epoch 93:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 93:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 93:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 93:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.43it/s]\u001b[A\n",
      "Epoch 93:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.51it/s]\u001b[A\n",
      "Epoch 93:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 93:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.53it/s]\u001b[A\n",
      "Epoch 93:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 93:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.69it/s]\u001b[A\n",
      "Epoch 93:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.67it/s]\u001b[A\n",
      "Epoch 93:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.43it/s]\u001b[A\n",
      "Epoch 93:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 93:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 93:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 93:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 93:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 93:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.42it/s]\u001b[A\n",
      "Epoch 93:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.60it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.53it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 93:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 93:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.40it/s]\u001b[A\n",
      "Epoch 93:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 93:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.46it/s]\u001b[A\n",
      "Epoch 93:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 93:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.67it/s]\u001b[A\n",
      "Epoch 93:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.34it/s]\u001b[A\n",
      "Epoch 93:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 93:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 93:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.33it/s]\u001b[A\n",
      "Epoch 93:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 93:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 93:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.27it/s]\u001b[A\n",
      "Epoch 93:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 93:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 93:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 93:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 93:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.54it/s]\u001b[A\n",
      "Epoch 93:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 93:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.30it/s]\u001b[A\n",
      "Epoch 93:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 93:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 93:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.42it/s]\u001b[A\n",
      "Epoch 93:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 93:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 93:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.48it/s]\u001b[A\n",
      "Epoch 93:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.60it/s]\u001b[A\n",
      "Epoch 93:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.61it/s]\u001b[A\n",
      "Epoch 93: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 93: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.189, v_num=87, val_loss_epoch=0.540, train_loss_step=0.231, train_loss_epoch=0.172, val_loss_step=0.941]\n",
      "Epoch 93: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.189, v_num=87, val_loss_epoch=0.601, train_loss_step=0.240, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Epoch 94:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 94:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:40,  2.97it/s]\u001b[A\n",
      "Epoch 94:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.83it/s]\u001b[A\n",
      "Epoch 94:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.15it/s]\u001b[A\n",
      "Epoch 94:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 94:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.28it/s]\u001b[A\n",
      "Epoch 94:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.54it/s]\u001b[A\n",
      "Epoch 94:  86%|████████▌ | 672/780 [06:10<00:59,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.57it/s]\u001b[A\n",
      "Epoch 94:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 94:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.47it/s]\u001b[A\n",
      "Epoch 94:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 94:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.29it/s]\u001b[A\n",
      "Epoch 94:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 94:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 94:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.30it/s]\u001b[A\n",
      "Epoch 94:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 94:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.52it/s]\u001b[A\n",
      "Epoch 94:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 94:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 94:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.69it/s]\u001b[A\n",
      "Epoch 94:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 94:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.42it/s]\u001b[A\n",
      "Epoch 94:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.68it/s]\u001b[A\n",
      "Epoch 94:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 94:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 94:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 94:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 94:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 716/780 [06:19<00:33,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 94:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 94:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 94:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.47it/s]\u001b[A\n",
      "Epoch 94:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 94:  94%|█████████▎| 730/780 [06:23<00:26,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 94:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.30it/s]\u001b[A\n",
      "Epoch 94:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 94:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 94:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 94:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.73it/s]\u001b[A\n",
      "Epoch 94:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 94:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 94:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.68it/s]\u001b[A\n",
      "Epoch 94:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.39it/s]\u001b[A\n",
      "Epoch 94:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.54it/s]\u001b[A\n",
      "Epoch 94:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 94:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.26it/s]\u001b[A\n",
      "Epoch 94:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.41it/s]\u001b[A\n",
      "Epoch 94:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.33it/s]\u001b[A\n",
      "Epoch 94:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 94:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.30it/s]\u001b[A\n",
      "Epoch 94:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 94:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 94:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.35it/s]\u001b[A\n",
      "Epoch 94:  99%|█████████▊| 770/780 [06:31<00:05,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.60it/s]\u001b[A\n",
      "Epoch 94:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 94:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.41it/s]\u001b[A\n",
      "Epoch 94:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.61it/s]\u001b[A\n",
      "Epoch 94: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.66it/s]\u001b[A\n",
      "Epoch 94: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.173, v_num=87, val_loss_epoch=0.601, train_loss_step=0.111, train_loss_epoch=0.173, val_loss_step=0.419]\n",
      "Epoch 94: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.173, v_num=87, val_loss_epoch=0.685, train_loss_step=0.343, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Epoch 95:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:07,  1.81it/s]\u001b[A\n",
      "Epoch 95:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.08it/s]\u001b[A\n",
      "Epoch 95:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.84it/s]\u001b[A\n",
      "Epoch 95:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.94it/s]\u001b[A\n",
      "Epoch 95:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:   8%|▊         | 10/124 [00:03<00:26,  4.28it/s]\u001b[A\n",
      "Epoch 95:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.38it/s]\u001b[A\n",
      "Epoch 95:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.58it/s]\u001b[A\n",
      "Epoch 95:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.21it/s]\u001b[A\n",
      "Epoch 95:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 95:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.40it/s]\u001b[A\n",
      "Epoch 95:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.32it/s]\u001b[A\n",
      "Epoch 95:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 95:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 95:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:21,  4.42it/s]\u001b[A\n",
      "Epoch 95:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 95:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 95:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 95:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 95:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 95:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.33it/s]\u001b[A\n",
      "Epoch 95:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.37it/s]\u001b[A\n",
      "Epoch 95:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 95:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 95:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.41it/s]\u001b[A\n",
      "Epoch 95:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 95:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 95:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.42it/s]\u001b[A\n",
      "Epoch 95:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.31it/s]\u001b[A\n",
      "Epoch 95:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.50it/s]\u001b[A\n",
      "Epoch 95:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 95:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.31it/s]\u001b[A\n",
      "Epoch 95:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.49it/s]\u001b[A\n",
      "Epoch 95:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.70it/s]\u001b[A\n",
      "Epoch 95:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 95:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.35it/s]\u001b[A\n",
      "Epoch 95:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 95:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 95:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 95:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 95:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 95:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.28it/s]\u001b[A\n",
      "Epoch 95:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 95:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 95:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.39it/s]\u001b[A\n",
      "Epoch 95:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 95:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 95:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 95:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.43it/s]\u001b[A\n",
      "Epoch 95:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.47it/s]\u001b[A\n",
      "Epoch 95:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 95:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.35it/s]\u001b[A\n",
      "Epoch 95:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 95:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.44it/s]\u001b[A\n",
      "Epoch 95:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 95:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 95:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.34it/s]\u001b[A\n",
      "Epoch 95: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.51it/s]\u001b[A\n",
      "Epoch 95: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.171, v_num=87, val_loss_epoch=0.685, train_loss_step=0.165, train_loss_epoch=0.169, val_loss_step=0.580]\n",
      "Epoch 95: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.171, v_num=87, val_loss_epoch=0.436, train_loss_step=0.0555, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Epoch 96:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:20,  1.52it/s]\u001b[A\n",
      "Epoch 96:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:42,  2.80it/s]\u001b[A\n",
      "Epoch 96:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:34,  3.42it/s]\u001b[A\n",
      "Epoch 96:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:34,  3.35it/s]\u001b[A\n",
      "Epoch 96:  85%|████████▌ | 666/780 [06:08<01:03,  1.80it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:   8%|▊         | 10/124 [00:03<00:29,  3.89it/s]\u001b[A\n",
      "Epoch 96:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.26it/s]\u001b[A\n",
      "Epoch 96:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  11%|█▏        | 14/124 [00:04<00:26,  4.19it/s]\u001b[A\n",
      "Epoch 96:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 96:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  15%|█▍        | 18/124 [00:05<00:23,  4.51it/s]\u001b[A\n",
      "Epoch 96:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.39it/s]\u001b[A\n",
      "Epoch 96:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  18%|█▊        | 22/124 [00:06<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 96:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 96:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 96:  88%|████████▊ | 684/780 [06:12<00:52,  1.83it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 96:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.44it/s]\u001b[A\n",
      "Epoch 96:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  26%|██▌       | 32/124 [00:08<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 96:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 96:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  29%|██▉       | 36/124 [00:09<00:20,  4.38it/s]\u001b[A\n",
      "Epoch 96:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.77it/s]\u001b[A\n",
      "Epoch 96:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  32%|███▏      | 40/124 [00:10<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 96:  89%|████████▉ | 698/780 [06:16<00:44,  1.86it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.65it/s]\u001b[A\n",
      "Epoch 96:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 96:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.40it/s]\u001b[A\n",
      "Epoch 96:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 96:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  40%|████      | 50/124 [00:12<00:16,  4.48it/s]\u001b[A\n",
      "Epoch 96:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 96:  91%|█████████ | 710/780 [06:18<00:37,  1.87it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  44%|████▎     | 54/124 [00:13<00:14,  4.71it/s]\u001b[A\n",
      "Epoch 96:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  47%|████▋     | 58/124 [00:14<00:14,  4.70it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 716/780 [06:20<00:33,  1.88it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.67it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.51it/s]\u001b[A\n",
      "Epoch 96:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 96:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  55%|█████▍    | 68/124 [00:16<00:12,  4.38it/s]\u001b[A\n",
      "Epoch 96:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 96:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  58%|█████▊    | 72/124 [00:17<00:11,  4.57it/s]\u001b[A\n",
      "Epoch 96:  94%|█████████▎| 730/780 [06:23<00:26,  1.91it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 96:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  61%|██████▏   | 76/124 [00:18<00:11,  4.31it/s]\u001b[A\n",
      "Epoch 96:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.43it/s]\u001b[A\n",
      "Epoch 96:  94%|█████████▍| 736/780 [06:24<00:22,  1.91it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 96:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.29it/s]\u001b[A\n",
      "Epoch 96:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 96:  95%|█████████▌| 742/780 [06:25<00:19,  1.92it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  69%|██████▉   | 86/124 [00:20<00:08,  4.57it/s]\u001b[A\n",
      "Epoch 96:  95%|█████████▌| 744/780 [06:26<00:18,  1.93it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.30it/s]\u001b[A\n",
      "Epoch 96:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  73%|███████▎  | 90/124 [00:21<00:07,  4.52it/s]\u001b[A\n",
      "Epoch 96:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.61it/s]\u001b[A\n",
      "Epoch 96:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  76%|███████▌  | 94/124 [00:22<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 96:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 96:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 96:  97%|█████████▋| 756/780 [06:28<00:12,  1.94it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.44it/s]\u001b[A\n",
      "Epoch 96:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.74it/s]\u001b[A\n",
      "Epoch 96:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  84%|████████▍ | 104/124 [00:24<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 96:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 96:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  87%|████████▋ | 108/124 [00:25<00:03,  4.27it/s]\u001b[A\n",
      "Epoch 96:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 96:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 96:  99%|█████████▊| 770/780 [06:31<00:05,  1.96it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 96:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.63it/s]\u001b[A\n",
      "Epoch 96:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 96:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.35it/s]\u001b[A\n",
      "Epoch 96: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Validating:  98%|█████████▊| 122/124 [00:28<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 96: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.19, v_num=87, val_loss_epoch=0.436, train_loss_step=0.224, train_loss_epoch=0.170, val_loss_step=1.220]\n",
      "Epoch 96: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.19, v_num=87, val_loss_epoch=0.663, train_loss_step=0.194, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Epoch 97:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.94it/s]\u001b[A\n",
      "Epoch 97:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 97:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.89it/s]\u001b[A\n",
      "Epoch 97:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.03it/s]\u001b[A\n",
      "Epoch 97:  85%|████████▌ | 666/780 [06:06<01:02,  1.81it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:24,  4.58it/s]\u001b[A\n",
      "Epoch 97:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.63it/s]\u001b[A\n",
      "Epoch 97:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 97:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 97:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.69it/s]\u001b[A\n",
      "Epoch 97:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.37it/s]\u001b[A\n",
      "Epoch 97:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.72it/s]\u001b[A\n",
      "Epoch 97:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.54it/s]\u001b[A\n",
      "Epoch 97:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 97:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 97:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 97:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.65it/s]\u001b[A\n",
      "Epoch 97:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 97:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.52it/s]\u001b[A\n",
      "Epoch 97:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.70it/s]\u001b[A\n",
      "Epoch 97:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.45it/s]\u001b[A\n",
      "Epoch 97:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 97:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 97:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:18,  4.28it/s]\u001b[A\n",
      "Epoch 97:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.45it/s]\u001b[A\n",
      "Epoch 97:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 97:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 97:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.56it/s]\u001b[A\n",
      "Epoch 97:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.32it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.47it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.65it/s]\u001b[A\n",
      "Epoch 97:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.40it/s]\u001b[A\n",
      "Epoch 97:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.81it/s]\u001b[A\n",
      "Epoch 97:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:10,  5.27it/s]\u001b[A\n",
      "Epoch 97:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  4.92it/s]\u001b[A\n",
      "Epoch 97:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 97:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.72it/s]\u001b[A\n",
      "Epoch 97:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 97:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.44it/s]\u001b[A\n",
      "Epoch 97:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.68it/s]\u001b[A\n",
      "Epoch 97:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 97:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.41it/s]\u001b[A\n",
      "Epoch 97:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 97:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.45it/s]\u001b[A\n",
      "Epoch 97:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 97:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:07,  4.25it/s]\u001b[A\n",
      "Epoch 97:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 97:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 97:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 97:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.61it/s]\u001b[A\n",
      "Epoch 97:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 97:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 97:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 97:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.38it/s]\u001b[A\n",
      "Epoch 97:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 97:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.74it/s]\u001b[A\n",
      "Epoch 97:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.54it/s]\u001b[A\n",
      "Epoch 97:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 97:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 97: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.71it/s]\u001b[A\n",
      "Epoch 97: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.159, v_num=87, val_loss_epoch=0.663, train_loss_step=0.0237, train_loss_epoch=0.173, val_loss_step=0.655]\n",
      "Epoch 97: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.159, v_num=87, val_loss_epoch=0.548, train_loss_step=0.184, train_loss_epoch=0.170, val_loss_step=0.392] \n",
      "Epoch 98:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 98:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.17it/s]\u001b[A\n",
      "Epoch 98:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.87it/s]\u001b[A\n",
      "Epoch 98:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.04it/s]\u001b[A\n",
      "Epoch 98:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 98:  86%|████████▌ | 668/780 [06:08<01:01,  1.82it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.51it/s]\u001b[A\n",
      "Epoch 98:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.45it/s]\u001b[A\n",
      "Epoch 98:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 98:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.60it/s]\u001b[A\n",
      "Epoch 98:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.39it/s]\u001b[A\n",
      "Epoch 98:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 98:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.39it/s]\u001b[A\n",
      "Epoch 98:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.59it/s]\u001b[A\n",
      "Epoch 98:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 98:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.32it/s]\u001b[A\n",
      "Epoch 98:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.50it/s]\u001b[A\n",
      "Epoch 98:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 98:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 98:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 98:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.70it/s]\u001b[A\n",
      "Epoch 98:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.63it/s]\u001b[A\n",
      "Epoch 98:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.26it/s]\u001b[A\n",
      "Epoch 98:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.48it/s]\u001b[A\n",
      "Epoch 98:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 98:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 98:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 98:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 98:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.34it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.58it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.35it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 98:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.81it/s]\u001b[A\n",
      "Epoch 98:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 98:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.39it/s]\u001b[A\n",
      "Epoch 98:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.49it/s]\u001b[A\n",
      "Epoch 98:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 98:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.31it/s]\u001b[A\n",
      "Epoch 98:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.47it/s]\u001b[A\n",
      "Epoch 98:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.61it/s]\u001b[A\n",
      "Epoch 98:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.36it/s]\u001b[A\n",
      "Epoch 98:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 98:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 98:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 98:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 98:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 98:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 98:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 98:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 98:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 98:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 98:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 98:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.59it/s]\u001b[A\n",
      "Epoch 98:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.46it/s]\u001b[A\n",
      "Epoch 98:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 98:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.57it/s]\u001b[A\n",
      "Epoch 98:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.37it/s]\u001b[A\n",
      "Epoch 98:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 98:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 98:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 98: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 98: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.172, v_num=87, val_loss_epoch=0.548, train_loss_step=0.327, train_loss_epoch=0.170, val_loss_step=0.392]\n",
      "Epoch 98: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.172, v_num=87, val_loss_epoch=0.652, train_loss_step=0.275, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Epoch 99:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.93it/s]\u001b[A\n",
      "Epoch 99:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.19it/s]\u001b[A\n",
      "Epoch 99:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.88it/s]\u001b[A\n",
      "Epoch 99:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.99it/s]\u001b[A\n",
      "Epoch 99:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 99:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.37it/s]\u001b[A\n",
      "Epoch 99:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.47it/s]\u001b[A\n",
      "Epoch 99:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.20it/s]\u001b[A\n",
      "Epoch 99:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.37it/s]\u001b[A\n",
      "Epoch 99:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 99:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 99:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 99:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.61it/s]\u001b[A\n",
      "Epoch 99:  88%|████████▊ | 684/780 [06:10<00:52,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.43it/s]\u001b[A\n",
      "Epoch 99:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 99:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 99:  88%|████████▊ | 690/780 [06:11<00:48,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 99:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 99:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.46it/s]\u001b[A\n",
      "Epoch 99:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.66it/s]\u001b[A\n",
      "Epoch 99:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 99:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:16,  4.74it/s]\u001b[A\n",
      "Epoch 99:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.63it/s]\u001b[A\n",
      "Epoch 99:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.48it/s]\u001b[A\n",
      "Epoch 99:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.68it/s]\u001b[A\n",
      "Epoch 99:  91%|█████████ | 708/780 [06:15<00:38,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.64it/s]\u001b[A\n",
      "Epoch 99:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.48it/s]\u001b[A\n",
      "Epoch 99:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.66it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.49it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.62it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.51it/s]\u001b[A\n",
      "Epoch 99:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.46it/s]\u001b[A\n",
      "Epoch 99:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 99:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 99:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 99:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 99:  94%|█████████▍| 732/780 [06:21<00:24,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 99:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.67it/s]\u001b[A\n",
      "Epoch 99:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.50it/s]\u001b[A\n",
      "Epoch 99:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.62it/s]\u001b[A\n",
      "Epoch 99:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 99:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.41it/s]\u001b[A\n",
      "Epoch 99:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 99:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.47it/s]\u001b[A\n",
      "Epoch 99:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.70it/s]\u001b[A\n",
      "Epoch 99:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.72it/s]\u001b[A\n",
      "Epoch 99:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 99:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.70it/s]\u001b[A\n",
      "Epoch 99:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.65it/s]\u001b[A\n",
      "Epoch 99:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.34it/s]\u001b[A\n",
      "Epoch 99:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 99:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.43it/s]\u001b[A\n",
      "Epoch 99:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 99:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.48it/s]\u001b[A\n",
      "Epoch 99:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.69it/s]\u001b[A\n",
      "Epoch 99:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.66it/s]\u001b[A\n",
      "Epoch 99:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.39it/s]\u001b[A\n",
      "Epoch 99:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.81it/s]\u001b[A\n",
      "Epoch 99:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.73it/s]\u001b[A\n",
      "Epoch 99: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.652, train_loss_step=0.109, train_loss_epoch=0.170, val_loss_step=0.673]\n",
      "Epoch 99: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.555, train_loss_step=0.0722, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Epoch 100:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 100:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 100:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.80it/s]\u001b[A\n",
      "Epoch 100:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 100:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 100:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 100:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 100:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.36it/s]\u001b[A\n",
      "Epoch 100:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.53it/s]\u001b[A\n",
      "Epoch 100:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.50it/s]\u001b[A\n",
      "Epoch 100:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.63it/s]\u001b[A\n",
      "Epoch 100:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.59it/s]\u001b[A\n",
      "Epoch 100:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.39it/s]\u001b[A\n",
      "Epoch 100:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.60it/s]\u001b[A\n",
      "Epoch 100:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 100:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 100:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 100:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.23it/s]\u001b[A\n",
      "Epoch 100:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 100:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 100:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:19,  4.29it/s]\u001b[A\n",
      "Epoch 100:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.49it/s]\u001b[A\n",
      "Epoch 100:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 100:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.39it/s]\u001b[A\n",
      "Epoch 100:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.51it/s]\u001b[A\n",
      "Epoch 100:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 100:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 100:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.36it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.66it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.33it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.49it/s]\u001b[A\n",
      "Epoch 100:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 100:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 100:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 100:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.61it/s]\u001b[A\n",
      "Epoch 100:  94%|█████████▎| 730/780 [06:21<00:26,  1.92it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.38it/s]\u001b[A\n",
      "Epoch 100:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.65it/s]\u001b[A\n",
      "Epoch 100:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 100:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.42it/s]\u001b[A\n",
      "Epoch 100:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.45it/s]\u001b[A\n",
      "Epoch 100:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.52it/s]\u001b[A\n",
      "Epoch 100:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 100:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 100:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 100:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 100:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.42it/s]\u001b[A\n",
      "Epoch 100:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 100:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.40it/s]\u001b[A\n",
      "Epoch 100:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.51it/s]\u001b[A\n",
      "Epoch 100:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.67it/s]\u001b[A\n",
      "Epoch 100:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 100:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 100:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.67it/s]\u001b[A\n",
      "Epoch 100:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.27it/s]\u001b[A\n",
      "Epoch 100:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.47it/s]\u001b[A\n",
      "Epoch 100:  99%|█████████▊| 770/780 [06:29<00:05,  1.97it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.45it/s]\u001b[A\n",
      "Epoch 100:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 100:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.33it/s]\u001b[A\n",
      "Epoch 100:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.70it/s]\u001b[A\n",
      "Epoch 100: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.62it/s]\u001b[A\n",
      "Epoch 100: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.207, v_num=87, val_loss_epoch=0.555, train_loss_step=0.181, train_loss_epoch=0.171, val_loss_step=0.345]\n",
      "Epoch 100: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.207, v_num=87, val_loss_epoch=0.624, train_loss_step=0.137, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Epoch 101:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 101:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 101:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.26it/s]\u001b[A\n",
      "Epoch 101:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.68it/s]\u001b[A\n",
      "Epoch 101:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.13it/s]\u001b[A\n",
      "Epoch 101:  85%|████████▌ | 666/780 [06:06<01:02,  1.81it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.36it/s]\u001b[A\n",
      "Epoch 101:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.30it/s]\u001b[A\n",
      "Epoch 101:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.53it/s]\u001b[A\n",
      "Epoch 101:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 101:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 101:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.44it/s]\u001b[A\n",
      "Epoch 101:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.56it/s]\u001b[A\n",
      "Epoch 101:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 101:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.71it/s]\u001b[A\n",
      "Epoch 101:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.67it/s]\u001b[A\n",
      "Epoch 101:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.39it/s]\u001b[A\n",
      "Epoch 101:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.68it/s]\u001b[A\n",
      "Epoch 101:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.82it/s]\u001b[A\n",
      "Epoch 101:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.71it/s]\u001b[A\n",
      "Epoch 101:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 101:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.56it/s]\u001b[A\n",
      "Epoch 101:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.62it/s]\u001b[A\n",
      "Epoch 101:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.35it/s]\u001b[A\n",
      "Epoch 101:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 101:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.54it/s]\u001b[A\n",
      "Epoch 101:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 101:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 101:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 101:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.45it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.59it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 716/780 [06:17<00:33,  1.89it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.31it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.36it/s]\u001b[A\n",
      "Epoch 101:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 101:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.59it/s]\u001b[A\n",
      "Epoch 101:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.36it/s]\u001b[A\n",
      "Epoch 101:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.61it/s]\u001b[A\n",
      "Epoch 101:  94%|█████████▎| 730/780 [06:21<00:26,  1.92it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.62it/s]\u001b[A\n",
      "Epoch 101:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 101:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 101:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 101:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.41it/s]\u001b[A\n",
      "Epoch 101:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 101:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 101:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 101:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 101:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 101:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 101:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 101:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.78it/s]\u001b[A\n",
      "Epoch 101:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.64it/s]\u001b[A\n",
      "Epoch 101:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.43it/s]\u001b[A\n",
      "Epoch 101:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.65it/s]\u001b[A\n",
      "Epoch 101:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 101:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 101:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.60it/s]\u001b[A\n",
      "Epoch 101:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 101:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.41it/s]\u001b[A\n",
      "Epoch 101:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 101:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.52it/s]\u001b[A\n",
      "Epoch 101:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 101: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.71it/s]\u001b[A\n",
      "Epoch 101: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.154, v_num=87, val_loss_epoch=0.624, train_loss_step=0.0292, train_loss_epoch=0.167, val_loss_step=0.935]\n",
      "Epoch 101: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.154, v_num=87, val_loss_epoch=0.622, train_loss_step=0.286, train_loss_epoch=0.165, val_loss_step=0.700] \n",
      "Epoch 102:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 102:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.93it/s]\u001b[A\n",
      "Epoch 102:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.15it/s]\u001b[A\n",
      "Epoch 102:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.92it/s]\u001b[A\n",
      "Epoch 102:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.95it/s]\u001b[A\n",
      "Epoch 102:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.29it/s]\u001b[A\n",
      "Epoch 102:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.34it/s]\u001b[A\n",
      "Epoch 102:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.53it/s]\u001b[A\n",
      "Epoch 102:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.29it/s]\u001b[A\n",
      "Epoch 102:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.48it/s]\u001b[A\n",
      "Epoch 102:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 102:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.34it/s]\u001b[A\n",
      "Epoch 102:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 102:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.64it/s]\u001b[A\n",
      "Epoch 102:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.42it/s]\u001b[A\n",
      "Epoch 102:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.61it/s]\u001b[A\n",
      "Epoch 102:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.54it/s]\u001b[A\n",
      "Epoch 102:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.43it/s]\u001b[A\n",
      "Epoch 102:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 102:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.61it/s]\u001b[A\n",
      "Epoch 102:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.48it/s]\u001b[A\n",
      "Epoch 102:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.47it/s]\u001b[A\n",
      "Epoch 102:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 102:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 102:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.41it/s]\u001b[A\n",
      "Epoch 102:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.53it/s]\u001b[A\n",
      "Epoch 102:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 102:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 102:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.64it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.72it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.51it/s]\u001b[A\n",
      "Epoch 102:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.76it/s]\u001b[A\n",
      "Epoch 102:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.76it/s]\u001b[A\n",
      "Epoch 102:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 102:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:10,  4.75it/s]\u001b[A\n",
      "Epoch 102:  94%|█████████▎| 730/780 [06:21<00:26,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 102:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 102:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 102:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.34it/s]\u001b[A\n",
      "Epoch 102:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.56it/s]\u001b[A\n",
      "Epoch 102:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 102:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.67it/s]\u001b[A\n",
      "Epoch 102:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 102:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.37it/s]\u001b[A\n",
      "Epoch 102:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 102:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 102:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.29it/s]\u001b[A\n",
      "Epoch 102:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 102:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 102:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.30it/s]\u001b[A\n",
      "Epoch 102:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 102:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.41it/s]\u001b[A\n",
      "Epoch 102:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 102:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.33it/s]\u001b[A\n",
      "Epoch 102:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.54it/s]\u001b[A\n",
      "Epoch 102:  99%|█████████▊| 770/780 [06:29<00:05,  1.97it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.63it/s]\u001b[A\n",
      "Epoch 102:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.34it/s]\u001b[A\n",
      "Epoch 102:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 102:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.50it/s]\u001b[A\n",
      "Epoch 102: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.35it/s]\u001b[A\n",
      "Epoch 102: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.622, train_loss_step=0.269, train_loss_epoch=0.165, val_loss_step=0.700]\n",
      "Epoch 102: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.157, v_num=87, val_loss_epoch=0.578, train_loss_step=0.0795, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Epoch 103:  84%|████████▍ | 656/780 [06:08<01:09,  1.78it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 103:  84%|████████▍ | 658/780 [06:10<01:08,  1.78it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.87it/s]\u001b[A\n",
      "Epoch 103:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:40,  2.93it/s]\u001b[A\n",
      "Epoch 103:  85%|████████▍ | 662/780 [06:11<01:06,  1.78it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.70it/s]\u001b[A\n",
      "Epoch 103:  85%|████████▌ | 664/780 [06:11<01:04,  1.79it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.08it/s]\u001b[A\n",
      "Epoch 103:  85%|████████▌ | 666/780 [06:12<01:03,  1.79it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:   8%|▊         | 10/124 [00:03<00:27,  4.13it/s]\u001b[A\n",
      "Epoch 103:  86%|████████▌ | 668/780 [06:12<01:02,  1.79it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 103:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 103:  86%|████████▌ | 672/780 [06:13<01:00,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 103:  86%|████████▋ | 674/780 [06:13<00:58,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 103:  87%|████████▋ | 676/780 [06:14<00:57,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.44it/s]\u001b[A\n",
      "Epoch 103:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 103:  87%|████████▋ | 680/780 [06:15<00:55,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.37it/s]\u001b[A\n",
      "Epoch 103:  87%|████████▋ | 682/780 [06:15<00:53,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:20,  4.67it/s]\u001b[A\n",
      "Epoch 103:  88%|████████▊ | 684/780 [06:16<00:52,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 103:  88%|████████▊ | 686/780 [06:16<00:51,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.35it/s]\u001b[A\n",
      "Epoch 103:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.52it/s]\u001b[A\n",
      "Epoch 103:  88%|████████▊ | 690/780 [06:17<00:49,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.50it/s]\u001b[A\n",
      "Epoch 103:  89%|████████▊ | 692/780 [06:17<00:48,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.35it/s]\u001b[A\n",
      "Epoch 103:  89%|████████▉ | 694/780 [06:18<00:46,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.47it/s]\u001b[A\n",
      "Epoch 103:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.28it/s]\u001b[A\n",
      "Epoch 103:  89%|████████▉ | 698/780 [06:19<00:44,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 103:  90%|████████▉ | 700/780 [06:19<00:43,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.39it/s]\u001b[A\n",
      "Epoch 103:  90%|█████████ | 702/780 [06:20<00:42,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.53it/s]\u001b[A\n",
      "Epoch 103:  90%|█████████ | 704/780 [06:20<00:41,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.33it/s]\u001b[A\n",
      "Epoch 103:  91%|█████████ | 706/780 [06:21<00:39,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.71it/s]\u001b[A\n",
      "Epoch 103:  91%|█████████ | 708/780 [06:21<00:38,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.69it/s]\u001b[A\n",
      "Epoch 103:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 103:  91%|█████████▏| 712/780 [06:22<00:36,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.73it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:13,  4.74it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 716/780 [06:23<00:34,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.34it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.49it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 720/780 [06:24<00:32,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 103:  93%|█████████▎| 722/780 [06:24<00:30,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.34it/s]\u001b[A\n",
      "Epoch 103:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 103:  93%|█████████▎| 726/780 [06:25<00:28,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 103:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.38it/s]\u001b[A\n",
      "Epoch 103:  94%|█████████▎| 730/780 [06:26<00:26,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 103:  94%|█████████▍| 732/780 [06:26<00:25,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.53it/s]\u001b[A\n",
      "Epoch 103:  94%|█████████▍| 734/780 [06:27<00:24,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 103:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.29it/s]\u001b[A\n",
      "Epoch 103:  95%|█████████▍| 738/780 [06:28<00:22,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.48it/s]\u001b[A\n",
      "Epoch 103:  95%|█████████▍| 740/780 [06:28<00:21,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 103:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.37it/s]\u001b[A\n",
      "Epoch 103:  95%|█████████▌| 744/780 [06:29<00:18,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 103:  96%|█████████▌| 746/780 [06:29<00:17,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 103:  96%|█████████▌| 748/780 [06:30<00:16,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.40it/s]\u001b[A\n",
      "Epoch 103:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.55it/s]\u001b[A\n",
      "Epoch 103:  96%|█████████▋| 752/780 [06:31<00:14,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 103:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 103:  97%|█████████▋| 756/780 [06:32<00:12,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 103:  97%|█████████▋| 758/780 [06:32<00:11,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.32it/s]\u001b[A\n",
      "Epoch 103:  97%|█████████▋| 760/780 [06:33<00:10,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.75it/s]\u001b[A\n",
      "Epoch 103:  98%|█████████▊| 762/780 [06:33<00:09,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 103:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 103:  98%|█████████▊| 766/780 [06:34<00:07,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 103:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.39it/s]\u001b[A\n",
      "Epoch 103:  99%|█████████▊| 770/780 [06:35<00:05,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 103:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.28it/s]\u001b[A\n",
      "Epoch 103:  99%|█████████▉| 774/780 [06:36<00:03,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.71it/s]\u001b[A\n",
      "Epoch 103:  99%|█████████▉| 776/780 [06:36<00:02,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.70it/s]\u001b[A\n",
      "Epoch 103: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 103: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.578, train_loss_step=0.367, train_loss_epoch=0.168, val_loss_step=0.727]\n",
      "Epoch 103: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.592, train_loss_step=0.119, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Epoch 104:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 104:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:04,  1.90it/s]\u001b[A\n",
      "Epoch 104:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.13it/s]\u001b[A\n",
      "Epoch 104:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.92it/s]\u001b[A\n",
      "Epoch 104:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:29,  3.99it/s]\u001b[A\n",
      "Epoch 104:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.47it/s]\u001b[A\n",
      "Epoch 104:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 104:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 104:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.65it/s]\u001b[A\n",
      "Epoch 104:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 104:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 104:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.48it/s]\u001b[A\n",
      "Epoch 104:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 104:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 104:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 104:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.45it/s]\u001b[A\n",
      "Epoch 104:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.54it/s]\u001b[A\n",
      "Epoch 104:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:21,  4.26it/s]\u001b[A\n",
      "Epoch 104:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.66it/s]\u001b[A\n",
      "Epoch 104:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.71it/s]\u001b[A\n",
      "Epoch 104:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 104:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 104:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 104:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.57it/s]\u001b[A\n",
      "Epoch 104:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.66it/s]\u001b[A\n",
      "Epoch 104:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 104:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 104:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.41it/s]\u001b[A\n",
      "Epoch 104:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.62it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.48it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.32it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.54it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 104:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.36it/s]\u001b[A\n",
      "Epoch 104:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 104:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 104:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 104:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.36it/s]\u001b[A\n",
      "Epoch 104:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.43it/s]\u001b[A\n",
      "Epoch 104:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 104:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.41it/s]\u001b[A\n",
      "Epoch 104:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 104:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 104:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.39it/s]\u001b[A\n",
      "Epoch 104:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 104:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 104:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.42it/s]\u001b[A\n",
      "Epoch 104:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.65it/s]\u001b[A\n",
      "Epoch 104:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 104:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 104:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.67it/s]\u001b[A\n",
      "Epoch 104:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.49it/s]\u001b[A\n",
      "Epoch 104:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.71it/s]\u001b[A\n",
      "Epoch 104:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.53it/s]\u001b[A\n",
      "Epoch 104:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 104:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.34it/s]\u001b[A\n",
      "Epoch 104:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.31it/s]\u001b[A\n",
      "Epoch 104:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.48it/s]\u001b[A\n",
      "Epoch 104:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.26it/s]\u001b[A\n",
      "Epoch 104:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.66it/s]\u001b[A\n",
      "Epoch 104:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.68it/s]\u001b[A\n",
      "Epoch 104: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.41it/s]\u001b[A\n",
      "Epoch 104: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.592, train_loss_step=0.227, train_loss_epoch=0.166, val_loss_step=0.188]\n",
      "Epoch 104: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.497, train_loss_step=0.124, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Epoch 105:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 105:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 105:  85%|████████▍ | 660/780 [06:08<01:06,  1.79it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.11it/s]\u001b[A\n",
      "Epoch 105:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  4.05it/s]\u001b[A\n",
      "Epoch 105:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 105:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.27it/s]\u001b[A\n",
      "Epoch 105:  86%|████████▌ | 668/780 [06:09<01:02,  1.81it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:23,  4.69it/s]\u001b[A\n",
      "Epoch 105:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.56it/s]\u001b[A\n",
      "Epoch 105:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 105:  86%|████████▋ | 674/780 [06:11<00:58,  1.82it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 105:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.36it/s]\u001b[A\n",
      "Epoch 105:  87%|████████▋ | 678/780 [06:12<00:55,  1.82it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 105:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 105:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 105:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 105:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 105:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.73it/s]\u001b[A\n",
      "Epoch 105:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.76it/s]\u001b[A\n",
      "Epoch 105:  89%|████████▊ | 692/780 [06:15<00:47,  1.84it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 105:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  31%|███       | 38/124 [00:08<00:18,  4.72it/s]\u001b[A\n",
      "Epoch 105:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.69it/s]\u001b[A\n",
      "Epoch 105:  89%|████████▉ | 698/780 [06:16<00:44,  1.85it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.34it/s]\u001b[A\n",
      "Epoch 105:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.52it/s]\u001b[A\n",
      "Epoch 105:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 105:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.64it/s]\u001b[A\n",
      "Epoch 105:  91%|█████████ | 706/780 [06:18<00:39,  1.87it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.32it/s]\u001b[A\n",
      "Epoch 105:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.67it/s]\u001b[A\n",
      "Epoch 105:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:14,  4.76it/s]\u001b[A\n",
      "Epoch 105:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:13,  4.74it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 716/780 [06:20<00:33,  1.88it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.67it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.75it/s]\u001b[A\n",
      "Epoch 105:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.78it/s]\u001b[A\n",
      "Epoch 105:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.54it/s]\u001b[A\n",
      "Epoch 105:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 105:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.67it/s]\u001b[A\n",
      "Epoch 105:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:11,  4.32it/s]\u001b[A\n",
      "Epoch 105:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 105:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 105:  94%|█████████▍| 736/780 [06:24<00:23,  1.91it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 105:  95%|█████████▍| 738/780 [06:25<00:21,  1.92it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.45it/s]\u001b[A\n",
      "Epoch 105:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.65it/s]\u001b[A\n",
      "Epoch 105:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.63it/s]\u001b[A\n",
      "Epoch 105:  95%|█████████▌| 744/780 [06:26<00:18,  1.92it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:08,  4.33it/s]\u001b[A\n",
      "Epoch 105:  96%|█████████▌| 746/780 [06:27<00:17,  1.93it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.49it/s]\u001b[A\n",
      "Epoch 105:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 105:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.32it/s]\u001b[A\n",
      "Epoch 105:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 105:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 105:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 105:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Epoch 105:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:03,  5.41it/s]\u001b[A\n",
      "Epoch 105:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  5.04it/s]\u001b[A\n",
      "Epoch 105:  98%|█████████▊| 764/780 [06:30<00:08,  1.95it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 105:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 105:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 105:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 105:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.30it/s]\u001b[A\n",
      "Epoch 105:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.53it/s]\u001b[A\n",
      "Epoch 105:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  97%|█████████▋| 120/124 [00:26<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 105: 100%|█████████▉| 778/780 [06:33<00:01,  1.97it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 105: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.162, v_num=87, val_loss_epoch=0.497, train_loss_step=0.215, train_loss_epoch=0.166, val_loss_step=0.550]\n",
      "Epoch 105: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.162, v_num=87, val_loss_epoch=0.545, train_loss_step=0.176, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Epoch 106:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 106:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.98it/s]\u001b[A\n",
      "Epoch 106:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.22it/s]\u001b[A\n",
      "Epoch 106:  85%|████████▍ | 662/780 [06:04<01:05,  1.81it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.79it/s]\u001b[A\n",
      "Epoch 106:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.27it/s]\u001b[A\n",
      "Epoch 106:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 106:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.38it/s]\u001b[A\n",
      "Epoch 106:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:22,  4.85it/s]\u001b[A\n",
      "Epoch 106:  86%|████████▌ | 672/780 [06:06<00:58,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:22,  4.77it/s]\u001b[A\n",
      "Epoch 106:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.54it/s]\u001b[A\n",
      "Epoch 106:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 106:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 106:  87%|████████▋ | 680/780 [06:08<00:54,  1.84it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 106:  87%|████████▋ | 682/780 [06:09<00:53,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 106:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 106:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.68it/s]\u001b[A\n",
      "Epoch 106:  88%|████████▊ | 688/780 [06:10<00:49,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.53it/s]\u001b[A\n",
      "Epoch 106:  88%|████████▊ | 690/780 [06:10<00:48,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.64it/s]\u001b[A\n",
      "Epoch 106:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 106:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.43it/s]\u001b[A\n",
      "Epoch 106:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 106:  89%|████████▉ | 698/780 [06:12<00:43,  1.87it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:19,  4.30it/s]\u001b[A\n",
      "Epoch 106:  90%|████████▉ | 700/780 [06:13<00:42,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.48it/s]\u001b[A\n",
      "Epoch 106:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 106:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:18,  4.17it/s]\u001b[A\n",
      "Epoch 106:  91%|█████████ | 706/780 [06:14<00:39,  1.88it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 106:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 106:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.37it/s]\u001b[A\n",
      "Epoch 106:  91%|█████████▏| 712/780 [06:15<00:35,  1.89it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.68it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.55it/s]\u001b[A\n",
      "Epoch 106:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 106:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:13,  4.25it/s]\u001b[A\n",
      "Epoch 106:  93%|█████████▎| 726/780 [06:19<00:28,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 106:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 106:  94%|█████████▎| 730/780 [06:19<00:26,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.36it/s]\u001b[A\n",
      "Epoch 106:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 106:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:09,  4.61it/s]\u001b[A\n",
      "Epoch 106:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.36it/s]\u001b[A\n",
      "Epoch 106:  95%|█████████▍| 738/780 [06:21<00:21,  1.93it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.63it/s]\u001b[A\n",
      "Epoch 106:  95%|█████████▍| 740/780 [06:22<00:20,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 106:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 106:  95%|█████████▌| 744/780 [06:22<00:18,  1.94it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.58it/s]\u001b[A\n",
      "Epoch 106:  96%|█████████▌| 746/780 [06:23<00:17,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.62it/s]\u001b[A\n",
      "Epoch 106:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 106:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 106:  96%|█████████▋| 752/780 [06:24<00:14,  1.95it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 106:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 106:  97%|█████████▋| 756/780 [06:25<00:12,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 106:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 106:  97%|█████████▋| 760/780 [06:26<00:10,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 106:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 106:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 106:  98%|█████████▊| 766/780 [06:27<00:07,  1.97it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.42it/s]\u001b[A\n",
      "Epoch 106:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 106:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.68it/s]\u001b[A\n",
      "Epoch 106:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 106:  99%|█████████▉| 774/780 [06:29<00:03,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 106:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.67it/s]\u001b[A\n",
      "Epoch 106: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.37it/s]\u001b[A\n",
      "Epoch 106: 100%|██████████| 780/780 [06:30<00:00,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.545, train_loss_step=0.057, train_loss_epoch=0.162, val_loss_step=0.765]\n",
      "Epoch 106: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.158, v_num=87, val_loss_epoch=0.642, train_loss_step=0.160, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Epoch 107:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 107:  84%|████████▍ | 658/780 [06:06<01:08,  1.79it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:06,  1.83it/s]\u001b[A\n",
      "Epoch 107:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.18it/s]\u001b[A\n",
      "Epoch 107:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 107:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.09it/s]\u001b[A\n",
      "Epoch 107:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.30it/s]\u001b[A\n",
      "Epoch 107:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 107:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 107:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.37it/s]\u001b[A\n",
      "Epoch 107:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.64it/s]\u001b[A\n",
      "Epoch 107:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 107:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.38it/s]\u001b[A\n",
      "Epoch 107:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.62it/s]\u001b[A\n",
      "Epoch 107:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 107:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.44it/s]\u001b[A\n",
      "Epoch 107:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 107:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 107:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.39it/s]\u001b[A\n",
      "Epoch 107:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.54it/s]\u001b[A\n",
      "Epoch 107:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 107:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 107:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 107:  90%|████████▉ | 700/780 [06:16<00:42,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 107:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 107:  90%|█████████ | 704/780 [06:17<00:40,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.50it/s]\u001b[A\n",
      "Epoch 107:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 107:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.65it/s]\u001b[A\n",
      "Epoch 107:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.46it/s]\u001b[A\n",
      "Epoch 107:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.58it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.43it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.62it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.67it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.37it/s]\u001b[A\n",
      "Epoch 107:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.46it/s]\u001b[A\n",
      "Epoch 107:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 107:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.27it/s]\u001b[A\n",
      "Epoch 107:  93%|█████████▎| 728/780 [06:22<00:27,  1.90it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.46it/s]\u001b[A\n",
      "Epoch 107:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.67it/s]\u001b[A\n",
      "Epoch 107:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 107:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 107:  94%|█████████▍| 736/780 [06:24<00:22,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.74it/s]\u001b[A\n",
      "Epoch 107:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:08,  4.73it/s]\u001b[A\n",
      "Epoch 107:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.37it/s]\u001b[A\n",
      "Epoch 107:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.47it/s]\u001b[A\n",
      "Epoch 107:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 107:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.28it/s]\u001b[A\n",
      "Epoch 107:  96%|█████████▌| 748/780 [06:26<00:16,  1.93it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 107:  96%|█████████▌| 750/780 [06:27<00:15,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 107:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.28it/s]\u001b[A\n",
      "Epoch 107:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.60it/s]\u001b[A\n",
      "Epoch 107:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.56it/s]\u001b[A\n",
      "Epoch 107:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 107:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.67it/s]\u001b[A\n",
      "Epoch 107:  98%|█████████▊| 762/780 [06:29<00:09,  1.95it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 107:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 107:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.26it/s]\u001b[A\n",
      "Epoch 107:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 107:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 107:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 107:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.56it/s]\u001b[A\n",
      "Epoch 107:  99%|█████████▉| 776/780 [06:32<00:02,  1.97it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.54it/s]\u001b[A\n",
      "Epoch 107: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.33it/s]\u001b[A\n",
      "Epoch 107: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.642, train_loss_step=0.491, train_loss_epoch=0.169, val_loss_step=0.515]\n",
      "Epoch 107: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.155, v_num=87, val_loss_epoch=0.583, train_loss_step=0.0321, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Epoch 108:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 108:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.93it/s]\u001b[A\n",
      "Epoch 108:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.06it/s]\u001b[A\n",
      "Epoch 108:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.86it/s]\u001b[A\n",
      "Epoch 108:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 108:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.27it/s]\u001b[A\n",
      "Epoch 108:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 108:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 108:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.39it/s]\u001b[A\n",
      "Epoch 108:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.46it/s]\u001b[A\n",
      "Epoch 108:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 108:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 108:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 108:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 108:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.56it/s]\u001b[A\n",
      "Epoch 108:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.38it/s]\u001b[A\n",
      "Epoch 108:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 108:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.47it/s]\u001b[A\n",
      "Epoch 108:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 108:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.65it/s]\u001b[A\n",
      "Epoch 108:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.33it/s]\u001b[A\n",
      "Epoch 108:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 108:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 108:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.37it/s]\u001b[A\n",
      "Epoch 108:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.52it/s]\u001b[A\n",
      "Epoch 108:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.56it/s]\u001b[A\n",
      "Epoch 108:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 108:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:16,  4.29it/s]\u001b[A\n",
      "Epoch 108:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.43it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.37it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 108:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.31it/s]\u001b[A\n",
      "Epoch 108:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.52it/s]\u001b[A\n",
      "Epoch 108:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 108:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.37it/s]\u001b[A\n",
      "Epoch 108:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 108:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 108:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.19it/s]\u001b[A\n",
      "Epoch 108:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.37it/s]\u001b[A\n",
      "Epoch 108:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 108:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.58it/s]\u001b[A\n",
      "Epoch 108:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.42it/s]\u001b[A\n",
      "Epoch 108:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 108:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 108:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.42it/s]\u001b[A\n",
      "Epoch 108:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.59it/s]\u001b[A\n",
      "Epoch 108:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 108:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.46it/s]\u001b[A\n",
      "Epoch 108:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 108:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.30it/s]\u001b[A\n",
      "Epoch 108:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 108:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 108:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.39it/s]\u001b[A\n",
      "Epoch 108:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 108:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 108:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 108:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 108:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 108:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 108: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 108: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.139, v_num=87, val_loss_epoch=0.583, train_loss_step=0.147, train_loss_epoch=0.163, val_loss_step=0.246]\n",
      "Epoch 108: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.139, v_num=87, val_loss_epoch=0.565, train_loss_step=0.162, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Epoch 109:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 109:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.99it/s]\u001b[A\n",
      "Epoch 109:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.23it/s]\u001b[A\n",
      "Epoch 109:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 109:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.12it/s]\u001b[A\n",
      "Epoch 109:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.45it/s]\u001b[A\n",
      "Epoch 109:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.23it/s]\u001b[A\n",
      "Epoch 109:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.47it/s]\u001b[A\n",
      "Epoch 109:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 109:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.30it/s]\u001b[A\n",
      "Epoch 109:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 109:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.49it/s]\u001b[A\n",
      "Epoch 109:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 109:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 109:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.50it/s]\u001b[A\n",
      "Epoch 109:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.65it/s]\u001b[A\n",
      "Epoch 109:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 109:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.57it/s]\u001b[A\n",
      "Epoch 109:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 109:  89%|████████▉ | 694/780 [06:14<00:46,  1.86it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.44it/s]\u001b[A\n",
      "Epoch 109:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.72it/s]\u001b[A\n",
      "Epoch 109:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 109:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 109:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 109:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 109:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 109:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 109:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 109:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.42it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.60it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 109:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 109:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 109:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.65it/s]\u001b[A\n",
      "Epoch 109:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 109:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.24it/s]\u001b[A\n",
      "Epoch 109:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 109:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 109:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.34it/s]\u001b[A\n",
      "Epoch 109:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 109:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.57it/s]\u001b[A\n",
      "Epoch 109:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 109:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.57it/s]\u001b[A\n",
      "Epoch 109:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 109:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 109:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.32it/s]\u001b[A\n",
      "Epoch 109:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 109:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.64it/s]\u001b[A\n",
      "Epoch 109:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.35it/s]\u001b[A\n",
      "Epoch 109:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.46it/s]\u001b[A\n",
      "Epoch 109:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 109:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.42it/s]\u001b[A\n",
      "Epoch 109:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.71it/s]\u001b[A\n",
      "Epoch 109:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 109:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 109:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.66it/s]\u001b[A\n",
      "Epoch 109:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.64it/s]\u001b[A\n",
      "Epoch 109:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.48it/s]\u001b[A\n",
      "Epoch 109:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 109: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.50it/s]\u001b[A\n",
      "Epoch 109: 100%|██████████| 780/780 [06:32<00:00,  1.98it/s, loss=0.185, v_num=87, val_loss_epoch=0.565, train_loss_step=0.164, train_loss_epoch=0.165, val_loss_step=0.512]\n",
      "Epoch 109: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.185, v_num=87, val_loss_epoch=0.562, train_loss_step=0.165, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Epoch 110:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 110:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.04it/s]\u001b[A\n",
      "Epoch 110:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.27it/s]\u001b[A\n",
      "Epoch 110:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.91it/s]\u001b[A\n",
      "Epoch 110:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.07it/s]\u001b[A\n",
      "Epoch 110:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 110:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.52it/s]\u001b[A\n",
      "Epoch 110:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.26it/s]\u001b[A\n",
      "Epoch 110:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.43it/s]\u001b[A\n",
      "Epoch 110:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.55it/s]\u001b[A\n",
      "Epoch 110:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.30it/s]\u001b[A\n",
      "Epoch 110:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.60it/s]\u001b[A\n",
      "Epoch 110:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.58it/s]\u001b[A\n",
      "Epoch 110:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 110:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.62it/s]\u001b[A\n",
      "Epoch 110:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.56it/s]\u001b[A\n",
      "Epoch 110:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 110:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.47it/s]\u001b[A\n",
      "Epoch 110:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 110:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.61it/s]\u001b[A\n",
      "Epoch 110:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 110:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 110:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 110:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.42it/s]\u001b[A\n",
      "Epoch 110:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.72it/s]\u001b[A\n",
      "Epoch 110:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:15,  4.68it/s]\u001b[A\n",
      "Epoch 110:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.42it/s]\u001b[A\n",
      "Epoch 110:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 110:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  45%|████▌     | 56/124 [00:12<00:14,  4.65it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.46it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.58it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.64it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.41it/s]\u001b[A\n",
      "Epoch 110:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.42it/s]\u001b[A\n",
      "Epoch 110:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 110:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.59it/s]\u001b[A\n",
      "Epoch 110:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.46it/s]\u001b[A\n",
      "Epoch 110:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.70it/s]\u001b[A\n",
      "Epoch 110:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 110:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.44it/s]\u001b[A\n",
      "Epoch 110:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.74it/s]\u001b[A\n",
      "Epoch 110:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.60it/s]\u001b[A\n",
      "Epoch 110:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.42it/s]\u001b[A\n",
      "Epoch 110:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 110:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 110:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.46it/s]\u001b[A\n",
      "Epoch 110:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 110:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 110:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 110:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 110:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 110:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 110:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.43it/s]\u001b[A\n",
      "Epoch 110:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 110:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.64it/s]\u001b[A\n",
      "Epoch 110:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.39it/s]\u001b[A\n",
      "Epoch 110:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.67it/s]\u001b[A\n",
      "Epoch 110:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.54it/s]\u001b[A\n",
      "Epoch 110:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.38it/s]\u001b[A\n",
      "Epoch 110:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 110:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.67it/s]\u001b[A\n",
      "Epoch 110: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.41it/s]\u001b[A\n",
      "Epoch 110: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.142, v_num=87, val_loss_epoch=0.562, train_loss_step=0.0529, train_loss_epoch=0.165, val_loss_step=0.441]\n",
      "Epoch 110: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.142, v_num=87, val_loss_epoch=0.524, train_loss_step=0.180, train_loss_epoch=0.161, val_loss_step=0.289] \n",
      "Epoch 111:  84%|████████▍ | 656/780 [06:03<01:08,  1.81it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 111:  84%|████████▍ | 658/780 [06:04<01:07,  1.81it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:04,  1.89it/s]\u001b[A\n",
      "Epoch 111:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.15it/s]\u001b[A\n",
      "Epoch 111:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.88it/s]\u001b[A\n",
      "Epoch 111:  85%|████████▌ | 664/780 [06:05<01:03,  1.81it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.02it/s]\u001b[A\n",
      "Epoch 111:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 111:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.42it/s]\u001b[A\n",
      "Epoch 111:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.27it/s]\u001b[A\n",
      "Epoch 111:  86%|████████▌ | 672/780 [06:07<00:59,  1.83it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.60it/s]\u001b[A\n",
      "Epoch 111:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 111:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:19,  5.23it/s]\u001b[A\n",
      "Epoch 111:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:20,  4.96it/s]\u001b[A\n",
      "Epoch 111:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:22,  4.42it/s]\u001b[A\n",
      "Epoch 111:  87%|████████▋ | 682/780 [06:09<00:53,  1.84it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.59it/s]\u001b[A\n",
      "Epoch 111:  88%|████████▊ | 684/780 [06:10<00:51,  1.85it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 111:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.35it/s]\u001b[A\n",
      "Epoch 111:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.52it/s]\u001b[A\n",
      "Epoch 111:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 111:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.43it/s]\u001b[A\n",
      "Epoch 111:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 111:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.58it/s]\u001b[A\n",
      "Epoch 111:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.49it/s]\u001b[A\n",
      "Epoch 111:  90%|████████▉ | 700/780 [06:13<00:42,  1.87it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.55it/s]\u001b[A\n",
      "Epoch 111:  90%|█████████ | 702/780 [06:14<00:41,  1.88it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.35it/s]\u001b[A\n",
      "Epoch 111:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.69it/s]\u001b[A\n",
      "Epoch 111:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 111:  91%|█████████ | 708/780 [06:15<00:38,  1.89it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.59it/s]\u001b[A\n",
      "Epoch 111:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.62it/s]\u001b[A\n",
      "Epoch 111:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.38it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 714/780 [06:16<00:34,  1.89it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.56it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.66it/s]\u001b[A\n",
      "Epoch 111:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.35it/s]\u001b[A\n",
      "Epoch 111:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.45it/s]\u001b[A\n",
      "Epoch 111:  93%|█████████▎| 726/780 [06:19<00:28,  1.91it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 111:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:12,  4.28it/s]\u001b[A\n",
      "Epoch 111:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 111:  94%|█████████▍| 732/780 [06:20<00:24,  1.92it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 111:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.34it/s]\u001b[A\n",
      "Epoch 111:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.67it/s]\u001b[A\n",
      "Epoch 111:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 111:  95%|█████████▍| 740/780 [06:22<00:20,  1.93it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 111:  95%|█████████▌| 742/780 [06:23<00:19,  1.94it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.29it/s]\u001b[A\n",
      "Epoch 111:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 111:  96%|█████████▌| 746/780 [06:23<00:17,  1.94it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 111:  96%|█████████▌| 748/780 [06:24<00:16,  1.95it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.37it/s]\u001b[A\n",
      "Epoch 111:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 111:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.64it/s]\u001b[A\n",
      "Epoch 111:  97%|█████████▋| 754/780 [06:25<00:13,  1.95it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 111:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 111:  97%|█████████▋| 758/780 [06:26<00:11,  1.96it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 111:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.44it/s]\u001b[A\n",
      "Epoch 111:  98%|█████████▊| 762/780 [06:27<00:09,  1.97it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.75it/s]\u001b[A\n",
      "Epoch 111:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 111:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 111:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.73it/s]\u001b[A\n",
      "Epoch 111:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 111:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.57it/s]\u001b[A\n",
      "Epoch 111:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.30it/s]\u001b[A\n",
      "Epoch 111:  99%|█████████▉| 776/780 [06:30<00:02,  1.99it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.51it/s]\u001b[A\n",
      "Epoch 111: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 111: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.149, v_num=87, val_loss_epoch=0.524, train_loss_step=0.085, train_loss_epoch=0.161, val_loss_step=0.289]\n",
      "Epoch 111: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.149, v_num=87, val_loss_epoch=0.583, train_loss_step=0.254, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Epoch 112:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 112:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  2.00it/s]\u001b[A\n",
      "Epoch 112:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 112:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  3.98it/s]\u001b[A\n",
      "Epoch 112:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.43it/s]\u001b[A\n",
      "Epoch 112:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.36it/s]\u001b[A\n",
      "Epoch 112:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.57it/s]\u001b[A\n",
      "Epoch 112:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 112:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.47it/s]\u001b[A\n",
      "Epoch 112:  86%|████████▋ | 674/780 [06:08<00:58,  1.83it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.72it/s]\u001b[A\n",
      "Epoch 112:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.71it/s]\u001b[A\n",
      "Epoch 112:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.33it/s]\u001b[A\n",
      "Epoch 112:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.75it/s]\u001b[A\n",
      "Epoch 112:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 112:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.59it/s]\u001b[A\n",
      "Epoch 112:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 112:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 112:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 112:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.28it/s]\u001b[A\n",
      "Epoch 112:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.48it/s]\u001b[A\n",
      "Epoch 112:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 112:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:19,  4.27it/s]\u001b[A\n",
      "Epoch 112:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 112:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.56it/s]\u001b[A\n",
      "Epoch 112:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.34it/s]\u001b[A\n",
      "Epoch 112:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 112:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 112:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.45it/s]\u001b[A\n",
      "Epoch 112:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.51it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.50it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.46it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.37it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.71it/s]\u001b[A\n",
      "Epoch 112:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 112:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 112:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 112:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.56it/s]\u001b[A\n",
      "Epoch 112:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.46it/s]\u001b[A\n",
      "Epoch 112:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.55it/s]\u001b[A\n",
      "Epoch 112:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.56it/s]\u001b[A\n",
      "Epoch 112:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.40it/s]\u001b[A\n",
      "Epoch 112:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.55it/s]\u001b[A\n",
      "Epoch 112:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.52it/s]\u001b[A\n",
      "Epoch 112:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.53it/s]\u001b[A\n",
      "Epoch 112:  95%|█████████▌| 744/780 [06:24<00:18,  1.94it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 112:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:06,  5.10it/s]\u001b[A\n",
      "Epoch 112:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  5.22it/s]\u001b[A\n",
      "Epoch 112:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.83it/s]\u001b[A\n",
      "Epoch 112:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 112:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 112:  97%|█████████▋| 756/780 [06:26<00:12,  1.95it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.41it/s]\u001b[A\n",
      "Epoch 112:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 112:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.57it/s]\u001b[A\n",
      "Epoch 112:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 112:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 112:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Epoch 112:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.29it/s]\u001b[A\n",
      "Epoch 112:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.49it/s]\u001b[A\n",
      "Epoch 112:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.57it/s]\u001b[A\n",
      "Epoch 112:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.32it/s]\u001b[A\n",
      "Epoch 112:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.55it/s]\u001b[A\n",
      "Epoch 112: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.49it/s]\u001b[A\n",
      "Epoch 112: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.147, v_num=87, val_loss_epoch=0.583, train_loss_step=0.138, train_loss_epoch=0.161, val_loss_step=0.185]\n",
      "Epoch 112: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.147, v_num=87, val_loss_epoch=0.669, train_loss_step=0.240, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Epoch 113:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 113:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:08,  1.77it/s]\u001b[A\n",
      "Epoch 113:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.03it/s]\u001b[A\n",
      "Epoch 113:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 113:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.11it/s]\u001b[A\n",
      "Epoch 113:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:   8%|▊         | 10/124 [00:03<00:26,  4.35it/s]\u001b[A\n",
      "Epoch 113:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.31it/s]\u001b[A\n",
      "Epoch 113:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 113:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:25,  4.27it/s]\u001b[A\n",
      "Epoch 113:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 113:  87%|████████▋ | 676/780 [06:10<00:56,  1.82it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.55it/s]\u001b[A\n",
      "Epoch 113:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.29it/s]\u001b[A\n",
      "Epoch 113:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.41it/s]\u001b[A\n",
      "Epoch 113:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 113:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:22,  4.33it/s]\u001b[A\n",
      "Epoch 113:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.48it/s]\u001b[A\n",
      "Epoch 113:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  26%|██▌       | 32/124 [00:08<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 113:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.56it/s]\u001b[A\n",
      "Epoch 113:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.23it/s]\u001b[A\n",
      "Epoch 113:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.45it/s]\u001b[A\n",
      "Epoch 113:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.48it/s]\u001b[A\n",
      "Epoch 113:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 113:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.53it/s]\u001b[A\n",
      "Epoch 113:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 113:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.43it/s]\u001b[A\n",
      "Epoch 113:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  40%|████      | 50/124 [00:12<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 113:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.47it/s]\u001b[A\n",
      "Epoch 113:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.45it/s]\u001b[A\n",
      "Epoch 113:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.62it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.40it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:13,  4.50it/s]\u001b[A\n",
      "Epoch 113:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.40it/s]\u001b[A\n",
      "Epoch 113:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  55%|█████▍    | 68/124 [00:16<00:11,  4.68it/s]\u001b[A\n",
      "Epoch 113:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.72it/s]\u001b[A\n",
      "Epoch 113:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.47it/s]\u001b[A\n",
      "Epoch 113:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.67it/s]\u001b[A\n",
      "Epoch 113:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.65it/s]\u001b[A\n",
      "Epoch 113:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.36it/s]\u001b[A\n",
      "Epoch 113:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 113:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.64it/s]\u001b[A\n",
      "Epoch 113:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.28it/s]\u001b[A\n",
      "Epoch 113:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  69%|██████▉   | 86/124 [00:20<00:08,  4.45it/s]\u001b[A\n",
      "Epoch 113:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 113:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.27it/s]\u001b[A\n",
      "Epoch 113:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 113:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.50it/s]\u001b[A\n",
      "Epoch 113:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 113:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:06,  4.26it/s]\u001b[A\n",
      "Epoch 113:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 113:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 113:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  84%|████████▍ | 104/124 [00:24<00:04,  4.38it/s]\u001b[A\n",
      "Epoch 113:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.62it/s]\u001b[A\n",
      "Epoch 113:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 113:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.35it/s]\u001b[A\n",
      "Epoch 113:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 113:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.55it/s]\u001b[A\n",
      "Epoch 113:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.41it/s]\u001b[A\n",
      "Epoch 113:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.63it/s]\u001b[A\n",
      "Epoch 113:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.38it/s]\u001b[A\n",
      "Epoch 113: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Validating:  98%|█████████▊| 122/124 [00:28<00:00,  4.59it/s]\u001b[A\n",
      "Epoch 113: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.167, v_num=87, val_loss_epoch=0.669, train_loss_step=0.113, train_loss_epoch=0.158, val_loss_step=0.682]\n",
      "Epoch 113: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.167, v_num=87, val_loss_epoch=0.656, train_loss_step=0.102, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Epoch 114:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 114:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:07,  1.81it/s]\u001b[A\n",
      "Epoch 114:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 114:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.64it/s]\u001b[A\n",
      "Epoch 114:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.16it/s]\u001b[A\n",
      "Epoch 114:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.36it/s]\u001b[A\n",
      "Epoch 114:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.28it/s]\u001b[A\n",
      "Epoch 114:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.62it/s]\u001b[A\n",
      "Epoch 114:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.66it/s]\u001b[A\n",
      "Epoch 114:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.45it/s]\u001b[A\n",
      "Epoch 114:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.67it/s]\u001b[A\n",
      "Epoch 114:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 114:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 114:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 114:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 114:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.42it/s]\u001b[A\n",
      "Epoch 114:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.47it/s]\u001b[A\n",
      "Epoch 114:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.63it/s]\u001b[A\n",
      "Epoch 114:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 114:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.44it/s]\u001b[A\n",
      "Epoch 114:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 114:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.61it/s]\u001b[A\n",
      "Epoch 114:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.39it/s]\u001b[A\n",
      "Epoch 114:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 114:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 114:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.43it/s]\u001b[A\n",
      "Epoch 114:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 114:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.40it/s]\u001b[A\n",
      "Epoch 114:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.64it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.68it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.38it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.76it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.50it/s]\u001b[A\n",
      "Epoch 114:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 114:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 114:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 114:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.68it/s]\u001b[A\n",
      "Epoch 114:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 114:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.50it/s]\u001b[A\n",
      "Epoch 114:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.50it/s]\u001b[A\n",
      "Epoch 114:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.29it/s]\u001b[A\n",
      "Epoch 114:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 114:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 114:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.30it/s]\u001b[A\n",
      "Epoch 114:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.48it/s]\u001b[A\n",
      "Epoch 114:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.59it/s]\u001b[A\n",
      "Epoch 114:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.37it/s]\u001b[A\n",
      "Epoch 114:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.54it/s]\u001b[A\n",
      "Epoch 114:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 114:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.43it/s]\u001b[A\n",
      "Epoch 114:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:06,  3.52it/s]\u001b[A\n",
      "Epoch 114:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.00it/s]\u001b[A\n",
      "Epoch 114:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  84%|████████▍ | 104/124 [00:24<00:04,  4.08it/s]\u001b[A\n",
      "Epoch 114:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.38it/s]\u001b[A\n",
      "Epoch 114:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.46it/s]\u001b[A\n",
      "Epoch 114:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.34it/s]\u001b[A\n",
      "Epoch 114:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.52it/s]\u001b[A\n",
      "Epoch 114:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 114:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.44it/s]\u001b[A\n",
      "Epoch 114:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 114:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 114: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Validating:  98%|█████████▊| 122/124 [00:28<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 114: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.129, v_num=87, val_loss_epoch=0.656, train_loss_step=0.0435, train_loss_epoch=0.160, val_loss_step=0.763]\n",
      "Epoch 114: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.129, v_num=87, val_loss_epoch=0.581, train_loss_step=0.020, train_loss_epoch=0.165, val_loss_step=0.544] \n",
      "Epoch 115:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 115:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.87it/s]\u001b[A\n",
      "Epoch 115:  85%|████████▍ | 660/780 [06:05<01:06,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.17it/s]\u001b[A\n",
      "Epoch 115:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.89it/s]\u001b[A\n",
      "Epoch 115:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.02it/s]\u001b[A\n",
      "Epoch 115:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.40it/s]\u001b[A\n",
      "Epoch 115:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 115:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.48it/s]\u001b[A\n",
      "Epoch 115:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.48it/s]\u001b[A\n",
      "Epoch 115:  86%|████████▋ | 674/780 [06:08<00:58,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.53it/s]\u001b[A\n",
      "Epoch 115:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.56it/s]\u001b[A\n",
      "Epoch 115:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 115:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 115:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.46it/s]\u001b[A\n",
      "Epoch 115:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 115:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:19,  4.70it/s]\u001b[A\n",
      "Epoch 115:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.46it/s]\u001b[A\n",
      "Epoch 115:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.67it/s]\u001b[A\n",
      "Epoch 115:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.68it/s]\u001b[A\n",
      "Epoch 115:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 115:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 115:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:17,  4.60it/s]\u001b[A\n",
      "Epoch 115:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.29it/s]\u001b[A\n",
      "Epoch 115:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.48it/s]\u001b[A\n",
      "Epoch 115:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.68it/s]\u001b[A\n",
      "Epoch 115:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 115:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.37it/s]\u001b[A\n",
      "Epoch 115:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.47it/s]\u001b[A\n",
      "Epoch 115:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.61it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.28it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.32it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.38it/s]\u001b[A\n",
      "Epoch 115:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 115:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.62it/s]\u001b[A\n",
      "Epoch 115:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.42it/s]\u001b[A\n",
      "Epoch 115:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 115:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.54it/s]\u001b[A\n",
      "Epoch 115:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.43it/s]\u001b[A\n",
      "Epoch 115:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 115:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 115:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 115:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 115:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 115:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 115:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 115:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.54it/s]\u001b[A\n",
      "Epoch 115:  96%|█████████▌| 750/780 [06:25<00:15,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.30it/s]\u001b[A\n",
      "Epoch 115:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:05,  4.72it/s]\u001b[A\n",
      "Epoch 115:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 115:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.37it/s]\u001b[A\n",
      "Epoch 115:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.55it/s]\u001b[A\n",
      "Epoch 115:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 115:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.31it/s]\u001b[A\n",
      "Epoch 115:  98%|█████████▊| 764/780 [06:28<00:08,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 115:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:02,  4.70it/s]\u001b[A\n",
      "Epoch 115:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.75it/s]\u001b[A\n",
      "Epoch 115:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 115:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.72it/s]\u001b[A\n",
      "Epoch 115:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.71it/s]\u001b[A\n",
      "Epoch 115:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 115: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.74it/s]\u001b[A\n",
      "Epoch 115: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.174, v_num=87, val_loss_epoch=0.581, train_loss_step=0.271, train_loss_epoch=0.165, val_loss_step=0.544]\n",
      "Epoch 115: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.174, v_num=87, val_loss_epoch=0.550, train_loss_step=0.0691, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Epoch 116:  84%|████████▍ | 656/780 [06:06<01:09,  1.79it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 116:  84%|████████▍ | 658/780 [06:07<01:08,  1.79it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 116:  85%|████████▍ | 660/780 [06:07<01:06,  1.79it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.23it/s]\u001b[A\n",
      "Epoch 116:  85%|████████▍ | 662/780 [06:08<01:05,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.66it/s]\u001b[A\n",
      "Epoch 116:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 116:  85%|████████▌ | 666/780 [06:09<01:03,  1.80it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.44it/s]\u001b[A\n",
      "Epoch 116:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.26it/s]\u001b[A\n",
      "Epoch 116:  86%|████████▌ | 670/780 [06:10<01:00,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.43it/s]\u001b[A\n",
      "Epoch 116:  86%|████████▌ | 672/780 [06:10<00:59,  1.81it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.63it/s]\u001b[A\n",
      "Epoch 116:  86%|████████▋ | 674/780 [06:11<00:58,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.29it/s]\u001b[A\n",
      "Epoch 116:  87%|████████▋ | 676/780 [06:11<00:57,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 116:  87%|████████▋ | 678/780 [06:11<00:55,  1.82it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.50it/s]\u001b[A\n",
      "Epoch 116:  87%|████████▋ | 680/780 [06:12<00:54,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 116:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.30it/s]\u001b[A\n",
      "Epoch 116:  88%|████████▊ | 684/780 [06:13<00:52,  1.83it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 116:  88%|████████▊ | 686/780 [06:13<00:51,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 116:  88%|████████▊ | 688/780 [06:14<00:50,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.31it/s]\u001b[A\n",
      "Epoch 116:  88%|████████▊ | 690/780 [06:14<00:48,  1.84it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 116:  89%|████████▊ | 692/780 [06:15<00:47,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.52it/s]\u001b[A\n",
      "Epoch 116:  89%|████████▉ | 694/780 [06:15<00:46,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.36it/s]\u001b[A\n",
      "Epoch 116:  89%|████████▉ | 696/780 [06:15<00:45,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 116:  89%|████████▉ | 698/780 [06:16<00:44,  1.85it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.64it/s]\u001b[A\n",
      "Epoch 116:  90%|████████▉ | 700/780 [06:16<00:43,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.48it/s]\u001b[A\n",
      "Epoch 116:  90%|█████████ | 702/780 [06:17<00:41,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 116:  90%|█████████ | 704/780 [06:17<00:40,  1.86it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.57it/s]\u001b[A\n",
      "Epoch 116:  91%|█████████ | 706/780 [06:18<00:39,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.36it/s]\u001b[A\n",
      "Epoch 116:  91%|█████████ | 708/780 [06:18<00:38,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.41it/s]\u001b[A\n",
      "Epoch 116:  91%|█████████ | 710/780 [06:19<00:37,  1.87it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 116:  91%|█████████▏| 712/780 [06:19<00:36,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.55it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 716/780 [06:20<00:34,  1.88it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 718/780 [06:20<00:32,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.61it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 720/780 [06:21<00:31,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.40it/s]\u001b[A\n",
      "Epoch 116:  93%|█████████▎| 722/780 [06:21<00:30,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.63it/s]\u001b[A\n",
      "Epoch 116:  93%|█████████▎| 724/780 [06:22<00:29,  1.89it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.58it/s]\u001b[A\n",
      "Epoch 116:  93%|█████████▎| 726/780 [06:22<00:28,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 116:  93%|█████████▎| 728/780 [06:23<00:27,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 116:  94%|█████████▎| 730/780 [06:23<00:26,  1.90it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.36it/s]\u001b[A\n",
      "Epoch 116:  94%|█████████▍| 732/780 [06:23<00:25,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.54it/s]\u001b[A\n",
      "Epoch 116:  94%|█████████▍| 734/780 [06:24<00:24,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:09,  4.65it/s]\u001b[A\n",
      "Epoch 116:  94%|█████████▍| 736/780 [06:24<00:23,  1.91it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.35it/s]\u001b[A\n",
      "Epoch 116:  95%|█████████▍| 738/780 [06:25<00:21,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.49it/s]\u001b[A\n",
      "Epoch 116:  95%|█████████▍| 740/780 [06:25<00:20,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 116:  95%|█████████▌| 742/780 [06:26<00:19,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.67it/s]\u001b[A\n",
      "Epoch 116:  95%|█████████▌| 744/780 [06:26<00:18,  1.92it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.49it/s]\u001b[A\n",
      "Epoch 116:  96%|█████████▌| 746/780 [06:27<00:17,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.68it/s]\u001b[A\n",
      "Epoch 116:  96%|█████████▌| 748/780 [06:27<00:16,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.70it/s]\u001b[A\n",
      "Epoch 116:  96%|█████████▌| 750/780 [06:27<00:15,  1.93it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.33it/s]\u001b[A\n",
      "Epoch 116:  96%|█████████▋| 752/780 [06:28<00:14,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.48it/s]\u001b[A\n",
      "Epoch 116:  97%|█████████▋| 754/780 [06:28<00:13,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.55it/s]\u001b[A\n",
      "Epoch 116:  97%|█████████▋| 756/780 [06:29<00:12,  1.94it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.34it/s]\u001b[A\n",
      "Epoch 116:  97%|█████████▋| 758/780 [06:29<00:11,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.50it/s]\u001b[A\n",
      "Epoch 116:  97%|█████████▋| 760/780 [06:30<00:10,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.62it/s]\u001b[A\n",
      "Epoch 116:  98%|█████████▊| 762/780 [06:30<00:09,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.29it/s]\u001b[A\n",
      "Epoch 116:  98%|█████████▊| 764/780 [06:31<00:08,  1.95it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.55it/s]\u001b[A\n",
      "Epoch 116:  98%|█████████▊| 766/780 [06:31<00:07,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.46it/s]\u001b[A\n",
      "Epoch 116:  98%|█████████▊| 768/780 [06:31<00:06,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.29it/s]\u001b[A\n",
      "Epoch 116:  99%|█████████▊| 770/780 [06:32<00:05,  1.96it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.33it/s]\u001b[A\n",
      "Epoch 116:  99%|█████████▉| 772/780 [06:32<00:04,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 116:  99%|█████████▉| 774/780 [06:33<00:03,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.50it/s]\u001b[A\n",
      "Epoch 116:  99%|█████████▉| 776/780 [06:33<00:02,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.31it/s]\u001b[A\n",
      "Epoch 116: 100%|█████████▉| 778/780 [06:34<00:01,  1.97it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 116: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.173, v_num=87, val_loss_epoch=0.550, train_loss_step=0.119, train_loss_epoch=0.164, val_loss_step=0.636]\n",
      "Epoch 116: 100%|██████████| 780/780 [06:34<00:00,  1.98it/s, loss=0.173, v_num=87, val_loss_epoch=0.447, train_loss_step=0.149, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Epoch 117:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 117:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:01,  1.97it/s]\u001b[A\n",
      "Epoch 117:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:36,  3.25it/s]\u001b[A\n",
      "Epoch 117:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.82it/s]\u001b[A\n",
      "Epoch 117:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.02it/s]\u001b[A\n",
      "Epoch 117:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.38it/s]\u001b[A\n",
      "Epoch 117:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.36it/s]\u001b[A\n",
      "Epoch 117:  86%|████████▌ | 670/780 [06:09<01:00,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 117:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.61it/s]\u001b[A\n",
      "Epoch 117:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.34it/s]\u001b[A\n",
      "Epoch 117:  87%|████████▋ | 676/780 [06:10<00:56,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:21,  4.75it/s]\u001b[A\n",
      "Epoch 117:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.57it/s]\u001b[A\n",
      "Epoch 117:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 117:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 117:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.41it/s]\u001b[A\n",
      "Epoch 117:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.57it/s]\u001b[A\n",
      "Epoch 117:  88%|████████▊ | 688/780 [06:12<00:49,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.45it/s]\u001b[A\n",
      "Epoch 117:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.66it/s]\u001b[A\n",
      "Epoch 117:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:18,  4.69it/s]\u001b[A\n",
      "Epoch 117:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.39it/s]\u001b[A\n",
      "Epoch 117:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:17,  4.73it/s]\u001b[A\n",
      "Epoch 117:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 117:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.35it/s]\u001b[A\n",
      "Epoch 117:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.47it/s]\u001b[A\n",
      "Epoch 117:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.62it/s]\u001b[A\n",
      "Epoch 117:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.33it/s]\u001b[A\n",
      "Epoch 117:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.54it/s]\u001b[A\n",
      "Epoch 117:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 117:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.31it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 714/780 [06:18<00:35,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.46it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.69it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.69it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.35it/s]\u001b[A\n",
      "Epoch 117:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.73it/s]\u001b[A\n",
      "Epoch 117:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.70it/s]\u001b[A\n",
      "Epoch 117:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.33it/s]\u001b[A\n",
      "Epoch 117:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.52it/s]\u001b[A\n",
      "Epoch 117:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.60it/s]\u001b[A\n",
      "Epoch 117:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.35it/s]\u001b[A\n",
      "Epoch 117:  94%|█████████▍| 734/780 [06:23<00:24,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.51it/s]\u001b[A\n",
      "Epoch 117:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.54it/s]\u001b[A\n",
      "Epoch 117:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 117:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.65it/s]\u001b[A\n",
      "Epoch 117:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.62it/s]\u001b[A\n",
      "Epoch 117:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.43it/s]\u001b[A\n",
      "Epoch 117:  96%|█████████▌| 746/780 [06:25<00:17,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.70it/s]\u001b[A\n",
      "Epoch 117:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.51it/s]\u001b[A\n",
      "Epoch 117:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.58it/s]\u001b[A\n",
      "Epoch 117:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.30it/s]\u001b[A\n",
      "Epoch 117:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.45it/s]\u001b[A\n",
      "Epoch 117:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 117:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:05,  4.37it/s]\u001b[A\n",
      "Epoch 117:  97%|█████████▋| 760/780 [06:28<00:10,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.64it/s]\u001b[A\n",
      "Epoch 117:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 117:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.41it/s]\u001b[A\n",
      "Epoch 117:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.70it/s]\u001b[A\n",
      "Epoch 117:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.61it/s]\u001b[A\n",
      "Epoch 117:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 117:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.77it/s]\u001b[A\n",
      "Epoch 117:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.69it/s]\u001b[A\n",
      "Epoch 117:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 117: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 117: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.447, train_loss_step=0.151, train_loss_epoch=0.163, val_loss_step=0.404]\n",
      "Epoch 117: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.477, train_loss_step=0.0929, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Epoch 118:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 118:  84%|████████▍ | 658/780 [06:04<01:07,  1.80it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.00it/s]\u001b[A\n",
      "Epoch 118:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 118:  85%|████████▍ | 662/780 [06:05<01:05,  1.81it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.86it/s]\u001b[A\n",
      "Epoch 118:  85%|████████▌ | 664/780 [06:06<01:03,  1.81it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.22it/s]\u001b[A\n",
      "Epoch 118:  85%|████████▌ | 666/780 [06:06<01:02,  1.82it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.24it/s]\u001b[A\n",
      "Epoch 118:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.46it/s]\u001b[A\n",
      "Epoch 118:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.29it/s]\u001b[A\n",
      "Epoch 118:  86%|████████▌ | 672/780 [06:08<00:59,  1.83it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:22,  4.76it/s]\u001b[A\n",
      "Epoch 118:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.65it/s]\u001b[A\n",
      "Epoch 118:  87%|████████▋ | 676/780 [06:08<00:56,  1.83it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 118:  87%|████████▋ | 678/780 [06:09<00:55,  1.84it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.46it/s]\u001b[A\n",
      "Epoch 118:  87%|████████▋ | 680/780 [06:09<00:54,  1.84it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.61it/s]\u001b[A\n",
      "Epoch 118:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.37it/s]\u001b[A\n",
      "Epoch 118:  88%|████████▊ | 684/780 [06:10<00:52,  1.84it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 118:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.63it/s]\u001b[A\n",
      "Epoch 118:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.34it/s]\u001b[A\n",
      "Epoch 118:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 118:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.49it/s]\u001b[A\n",
      "Epoch 118:  89%|████████▉ | 694/780 [06:12<00:46,  1.86it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.56it/s]\u001b[A\n",
      "Epoch 118:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 118:  89%|████████▉ | 698/780 [06:13<00:43,  1.87it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.53it/s]\u001b[A\n",
      "Epoch 118:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.60it/s]\u001b[A\n",
      "Epoch 118:  90%|█████████ | 702/780 [06:14<00:41,  1.87it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:18,  4.31it/s]\u001b[A\n",
      "Epoch 118:  90%|█████████ | 704/780 [06:15<00:40,  1.88it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.49it/s]\u001b[A\n",
      "Epoch 118:  91%|█████████ | 706/780 [06:15<00:39,  1.88it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.54it/s]\u001b[A\n",
      "Epoch 118:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.38it/s]\u001b[A\n",
      "Epoch 118:  91%|█████████ | 710/780 [06:16<00:37,  1.89it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 118:  91%|█████████▏| 712/780 [06:16<00:35,  1.89it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.62it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.40it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 716/780 [06:17<00:33,  1.90it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:13,  4.62it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 720/780 [06:18<00:31,  1.90it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 118:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 118:  93%|█████████▎| 724/780 [06:19<00:29,  1.91it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.48it/s]\u001b[A\n",
      "Epoch 118:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.51it/s]\u001b[A\n",
      "Epoch 118:  93%|█████████▎| 728/780 [06:20<00:27,  1.91it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.44it/s]\u001b[A\n",
      "Epoch 118:  94%|█████████▎| 730/780 [06:20<00:26,  1.92it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.71it/s]\u001b[A\n",
      "Epoch 118:  94%|█████████▍| 732/780 [06:21<00:25,  1.92it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.64it/s]\u001b[A\n",
      "Epoch 118:  94%|█████████▍| 734/780 [06:21<00:23,  1.92it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.42it/s]\u001b[A\n",
      "Epoch 118:  94%|█████████▍| 736/780 [06:22<00:22,  1.93it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 118:  95%|█████████▍| 738/780 [06:22<00:21,  1.93it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.58it/s]\u001b[A\n",
      "Epoch 118:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.44it/s]\u001b[A\n",
      "Epoch 118:  95%|█████████▌| 742/780 [06:23<00:19,  1.93it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 118:  95%|█████████▌| 744/780 [06:23<00:18,  1.94it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.56it/s]\u001b[A\n",
      "Epoch 118:  96%|█████████▌| 746/780 [06:24<00:17,  1.94it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.39it/s]\u001b[A\n",
      "Epoch 118:  96%|█████████▌| 748/780 [06:24<00:16,  1.94it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 118:  96%|█████████▌| 750/780 [06:25<00:15,  1.95it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 118:  96%|█████████▋| 752/780 [06:25<00:14,  1.95it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.62it/s]\u001b[A\n",
      "Epoch 118:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 118:  97%|█████████▋| 756/780 [06:26<00:12,  1.96it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.51it/s]\u001b[A\n",
      "Epoch 118:  97%|█████████▋| 758/780 [06:27<00:11,  1.96it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.60it/s]\u001b[A\n",
      "Epoch 118:  97%|█████████▋| 760/780 [06:27<00:10,  1.96it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.39it/s]\u001b[A\n",
      "Epoch 118:  98%|█████████▊| 762/780 [06:27<00:09,  1.96it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 118:  98%|█████████▊| 764/780 [06:28<00:08,  1.97it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.45it/s]\u001b[A\n",
      "Epoch 118:  98%|█████████▊| 766/780 [06:28<00:07,  1.97it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.61it/s]\u001b[A\n",
      "Epoch 118:  98%|█████████▊| 768/780 [06:29<00:06,  1.97it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.64it/s]\u001b[A\n",
      "Epoch 118:  99%|█████████▊| 770/780 [06:29<00:05,  1.98it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 118:  99%|█████████▉| 772/780 [06:30<00:04,  1.98it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.75it/s]\u001b[A\n",
      "Epoch 118:  99%|█████████▉| 774/780 [06:30<00:03,  1.98it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.80it/s]\u001b[A\n",
      "Epoch 118:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.38it/s]\u001b[A\n",
      "Epoch 118: 100%|█████████▉| 778/780 [06:31<00:01,  1.99it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.71it/s]\u001b[A\n",
      "Epoch 118: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.168, v_num=87, val_loss_epoch=0.477, train_loss_step=0.239, train_loss_epoch=0.160, val_loss_step=0.164]\n",
      "Epoch 118: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.168, v_num=87, val_loss_epoch=0.684, train_loss_step=0.286, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Epoch 119:  84%|████████▍ | 656/780 [06:05<01:09,  1.79it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 119:  84%|████████▍ | 658/780 [06:06<01:08,  1.79it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 119:  85%|████████▍ | 660/780 [06:07<01:06,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:39,  3.07it/s]\u001b[A\n",
      "Epoch 119:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.80it/s]\u001b[A\n",
      "Epoch 119:  85%|████████▌ | 664/780 [06:08<01:04,  1.80it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.35it/s]\u001b[A\n",
      "Epoch 119:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 119:  86%|████████▌ | 668/780 [06:09<01:01,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.39it/s]\u001b[A\n",
      "Epoch 119:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.71it/s]\u001b[A\n",
      "Epoch 119:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 119:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.27it/s]\u001b[A\n",
      "Epoch 119:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.52it/s]\u001b[A\n",
      "Epoch 119:  87%|████████▋ | 678/780 [06:11<00:55,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 119:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.38it/s]\u001b[A\n",
      "Epoch 119:  87%|████████▋ | 682/780 [06:12<00:53,  1.83it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.47it/s]\u001b[A\n",
      "Epoch 119:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.62it/s]\u001b[A\n",
      "Epoch 119:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.29it/s]\u001b[A\n",
      "Epoch 119:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.52it/s]\u001b[A\n",
      "Epoch 119:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.58it/s]\u001b[A\n",
      "Epoch 119:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.40it/s]\u001b[A\n",
      "Epoch 119:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 119:  89%|████████▉ | 696/780 [06:15<00:45,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.52it/s]\u001b[A\n",
      "Epoch 119:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.41it/s]\u001b[A\n",
      "Epoch 119:  90%|████████▉ | 700/780 [06:16<00:42,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.68it/s]\u001b[A\n",
      "Epoch 119:  90%|█████████ | 702/780 [06:16<00:41,  1.86it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 119:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.68it/s]\u001b[A\n",
      "Epoch 119:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.30it/s]\u001b[A\n",
      "Epoch 119:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.46it/s]\u001b[A\n",
      "Epoch 119:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.53it/s]\u001b[A\n",
      "Epoch 119:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.33it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 714/780 [06:19<00:35,  1.88it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Epoch 119:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:11,  5.56it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:11,  5.19it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.68it/s]\u001b[A\n",
      "Epoch 119:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.73it/s]\u001b[A\n",
      "Epoch 119:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.61it/s]\u001b[A\n",
      "Epoch 119:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  56%|█████▋    | 70/124 [00:15<00:12,  4.41it/s]\u001b[A\n",
      "Epoch 119:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.62it/s]\u001b[A\n",
      "Epoch 119:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.59it/s]\u001b[A\n",
      "Epoch 119:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.48it/s]\u001b[A\n",
      "Epoch 119:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.47it/s]\u001b[A\n",
      "Epoch 119:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 119:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.54it/s]\u001b[A\n",
      "Epoch 119:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.41it/s]\u001b[A\n",
      "Epoch 119:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 119:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  71%|███████   | 88/124 [00:19<00:07,  4.60it/s]\u001b[A\n",
      "Epoch 119:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.41it/s]\u001b[A\n",
      "Epoch 119:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.55it/s]\u001b[A\n",
      "Epoch 119:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.46it/s]\u001b[A\n",
      "Epoch 119:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.39it/s]\u001b[A\n",
      "Epoch 119:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.57it/s]\u001b[A\n",
      "Epoch 119:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.38it/s]\u001b[A\n",
      "Epoch 119:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.77it/s]\u001b[A\n",
      "Epoch 119:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.59it/s]\u001b[A\n",
      "Epoch 119:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  85%|████████▌ | 106/124 [00:23<00:04,  4.30it/s]\u001b[A\n",
      "Epoch 119:  98%|█████████▊| 764/780 [06:30<00:08,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.54it/s]\u001b[A\n",
      "Epoch 119:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.49it/s]\u001b[A\n",
      "Epoch 119:  98%|█████████▊| 768/780 [06:30<00:06,  1.96it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.56it/s]\u001b[A\n",
      "Epoch 119:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.30it/s]\u001b[A\n",
      "Epoch 119:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.49it/s]\u001b[A\n",
      "Epoch 119:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 119:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.36it/s]\u001b[A\n",
      "Epoch 119: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.56it/s]\u001b[A\n",
      "Epoch 119: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.169, v_num=87, val_loss_epoch=0.684, train_loss_step=0.198, train_loss_epoch=0.153, val_loss_step=0.329]\n",
      "Epoch 119: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.169, v_num=87, val_loss_epoch=0.618, train_loss_step=0.144, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Epoch 120:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 120:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:05,  1.85it/s]\u001b[A\n",
      "Epoch 120:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.08it/s]\u001b[A\n",
      "Epoch 120:  85%|████████▍ | 662/780 [06:06<01:05,  1.80it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.80it/s]\u001b[A\n",
      "Epoch 120:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.05it/s]\u001b[A\n",
      "Epoch 120:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.35it/s]\u001b[A\n",
      "Epoch 120:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.19it/s]\u001b[A\n",
      "Epoch 120:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.37it/s]\u001b[A\n",
      "Epoch 120:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 120:  86%|████████▋ | 674/780 [06:09<00:58,  1.82it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:24,  4.30it/s]\u001b[A\n",
      "Epoch 120:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.53it/s]\u001b[A\n",
      "Epoch 120:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.65it/s]\u001b[A\n",
      "Epoch 120:  87%|████████▋ | 680/780 [06:10<00:54,  1.83it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:23,  4.25it/s]\u001b[A\n",
      "Epoch 120:  87%|████████▋ | 682/780 [06:11<00:53,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:21,  4.55it/s]\u001b[A\n",
      "Epoch 120:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:21,  4.49it/s]\u001b[A\n",
      "Epoch 120:  88%|████████▊ | 686/780 [06:12<00:50,  1.84it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 120:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.33it/s]\u001b[A\n",
      "Epoch 120:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.44it/s]\u001b[A\n",
      "Epoch 120:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.56it/s]\u001b[A\n",
      "Epoch 120:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.32it/s]\u001b[A\n",
      "Epoch 120:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 120:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.51it/s]\u001b[A\n",
      "Epoch 120:  90%|████████▉ | 700/780 [06:15<00:42,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 120:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.67it/s]\u001b[A\n",
      "Epoch 120:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.71it/s]\u001b[A\n",
      "Epoch 120:  91%|█████████ | 706/780 [06:16<00:39,  1.87it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.44it/s]\u001b[A\n",
      "Epoch 120:  91%|█████████ | 708/780 [06:17<00:38,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.61it/s]\u001b[A\n",
      "Epoch 120:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.58it/s]\u001b[A\n",
      "Epoch 120:  91%|█████████▏| 712/780 [06:17<00:36,  1.88it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.40it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.49it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.54it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.32it/s]\u001b[A\n",
      "Epoch 120:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.49it/s]\u001b[A\n",
      "Epoch 120:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.57it/s]\u001b[A\n",
      "Epoch 120:  93%|█████████▎| 726/780 [06:21<00:28,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.46it/s]\u001b[A\n",
      "Epoch 120:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.53it/s]\u001b[A\n",
      "Epoch 120:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.63it/s]\u001b[A\n",
      "Epoch 120:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.39it/s]\u001b[A\n",
      "Epoch 120:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.58it/s]\u001b[A\n",
      "Epoch 120:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 120:  95%|█████████▍| 738/780 [06:23<00:21,  1.92it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.53it/s]\u001b[A\n",
      "Epoch 120:  95%|█████████▍| 740/780 [06:24<00:20,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.54it/s]\u001b[A\n",
      "Epoch 120:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.28it/s]\u001b[A\n",
      "Epoch 120:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 120:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.47it/s]\u001b[A\n",
      "Epoch 120:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.63it/s]\u001b[A\n",
      "Epoch 120:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:07,  4.26it/s]\u001b[A\n",
      "Epoch 120:  96%|█████████▋| 752/780 [06:26<00:14,  1.94it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.53it/s]\u001b[A\n",
      "Epoch 120:  97%|█████████▋| 754/780 [06:27<00:13,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.63it/s]\u001b[A\n",
      "Epoch 120:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.31it/s]\u001b[A\n",
      "Epoch 120:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 120:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.63it/s]\u001b[A\n",
      "Epoch 120:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.36it/s]\u001b[A\n",
      "Epoch 120:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 120:  98%|█████████▊| 766/780 [06:29<00:07,  1.96it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.47it/s]\u001b[A\n",
      "Epoch 120:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.37it/s]\u001b[A\n",
      "Epoch 120:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.50it/s]\u001b[A\n",
      "Epoch 120:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 120:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.42it/s]\u001b[A\n",
      "Epoch 120:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 120: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.65it/s]\u001b[A\n",
      "Epoch 120: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0807, train_loss_epoch=0.164, val_loss_step=0.653]\n",
      "Epoch 120: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.183, v_num=87, val_loss_epoch=0.558, train_loss_step=0.122, train_loss_epoch=0.163, val_loss_step=0.492] \n",
      "Epoch 121:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 121:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:   2%|▏         | 2/124 [00:01<00:59,  2.06it/s]\u001b[A\n",
      "Epoch 121:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.24it/s]\u001b[A\n",
      "Epoch 121:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:30,  3.91it/s]\u001b[A\n",
      "Epoch 121:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.24it/s]\u001b[A\n",
      "Epoch 121:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.21it/s]\u001b[A\n",
      "Epoch 121:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 121:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.42it/s]\u001b[A\n",
      "Epoch 121:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.64it/s]\u001b[A\n",
      "Epoch 121:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.67it/s]\u001b[A\n",
      "Epoch 121:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.39it/s]\u001b[A\n",
      "Epoch 121:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:21,  4.77it/s]\u001b[A\n",
      "Epoch 121:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.74it/s]\u001b[A\n",
      "Epoch 121:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 121:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.57it/s]\u001b[A\n",
      "Epoch 121:  88%|████████▊ | 686/780 [06:11<00:50,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.64it/s]\u001b[A\n",
      "Epoch 121:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.31it/s]\u001b[A\n",
      "Epoch 121:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:20,  4.42it/s]\u001b[A\n",
      "Epoch 121:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.61it/s]\u001b[A\n",
      "Epoch 121:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.69it/s]\u001b[A\n",
      "Epoch 121:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.33it/s]\u001b[A\n",
      "Epoch 121:  89%|████████▉ | 698/780 [06:14<00:44,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.40it/s]\u001b[A\n",
      "Epoch 121:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.59it/s]\u001b[A\n",
      "Epoch 121:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:18,  4.22it/s]\u001b[A\n",
      "Epoch 121:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.40it/s]\u001b[A\n",
      "Epoch 121:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.54it/s]\u001b[A\n",
      "Epoch 121:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.35it/s]\u001b[A\n",
      "Epoch 121:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.66it/s]\u001b[A\n",
      "Epoch 121:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.40it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.56it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.65it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.45it/s]\u001b[A\n",
      "Epoch 121:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.46it/s]\u001b[A\n",
      "Epoch 121:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.56it/s]\u001b[A\n",
      "Epoch 121:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.52it/s]\u001b[A\n",
      "Epoch 121:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.39it/s]\u001b[A\n",
      "Epoch 121:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.57it/s]\u001b[A\n",
      "Epoch 121:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.71it/s]\u001b[A\n",
      "Epoch 121:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.53it/s]\u001b[A\n",
      "Epoch 121:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.68it/s]\u001b[A\n",
      "Epoch 121:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 121:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.36it/s]\u001b[A\n",
      "Epoch 121:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.59it/s]\u001b[A\n",
      "Epoch 121:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 121:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.63it/s]\u001b[A\n",
      "Epoch 121:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:06,  4.65it/s]\u001b[A\n",
      "Epoch 121:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.38it/s]\u001b[A\n",
      "Epoch 121:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.73it/s]\u001b[A\n",
      "Epoch 121:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.61it/s]\u001b[A\n",
      "Epoch 121:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.58it/s]\u001b[A\n",
      "Epoch 121:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.65it/s]\u001b[A\n",
      "Epoch 121:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.37it/s]\u001b[A\n",
      "Epoch 121:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.51it/s]\u001b[A\n",
      "Epoch 121:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.35it/s]\u001b[A\n",
      "Epoch 121:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.65it/s]\u001b[A\n",
      "Epoch 121:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 121:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.34it/s]\u001b[A\n",
      "Epoch 121:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.51it/s]\u001b[A\n",
      "Epoch 121:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.59it/s]\u001b[A\n",
      "Epoch 121:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.36it/s]\u001b[A\n",
      "Epoch 121: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.49it/s]\u001b[A\n",
      "Epoch 121: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.135, v_num=87, val_loss_epoch=0.558, train_loss_step=0.0949, train_loss_epoch=0.163, val_loss_step=0.492]\n",
      "Epoch 121: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0852, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Epoch 122:  84%|████████▍ | 656/780 [06:04<01:08,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 122:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:03,  1.93it/s]\u001b[A\n",
      "Epoch 122:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.18it/s]\u001b[A\n",
      "Epoch 122:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.60it/s]\u001b[A\n",
      "Epoch 122:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.05it/s]\u001b[A\n",
      "Epoch 122:  85%|████████▌ | 666/780 [06:07<01:02,  1.81it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:25,  4.47it/s]\u001b[A\n",
      "Epoch 122:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.50it/s]\u001b[A\n",
      "Epoch 122:  86%|████████▌ | 670/780 [06:08<01:00,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.30it/s]\u001b[A\n",
      "Epoch 122:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.49it/s]\u001b[A\n",
      "Epoch 122:  86%|████████▋ | 674/780 [06:09<00:58,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 122:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.32it/s]\u001b[A\n",
      "Epoch 122:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:23,  4.42it/s]\u001b[A\n",
      "Epoch 122:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.50it/s]\u001b[A\n",
      "Epoch 122:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.31it/s]\u001b[A\n",
      "Epoch 122:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.61it/s]\u001b[A\n",
      "Epoch 122:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 122:  88%|████████▊ | 688/780 [06:12<00:49,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:20,  4.42it/s]\u001b[A\n",
      "Epoch 122:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.66it/s]\u001b[A\n",
      "Epoch 122:  89%|████████▊ | 692/780 [06:13<00:47,  1.85it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 122:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.42it/s]\u001b[A\n",
      "Epoch 122:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 122:  89%|████████▉ | 698/780 [06:14<00:43,  1.86it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.50it/s]\u001b[A\n",
      "Epoch 122:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.54it/s]\u001b[A\n",
      "Epoch 122:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.37it/s]\u001b[A\n",
      "Epoch 122:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:17,  4.42it/s]\u001b[A\n",
      "Epoch 122:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.52it/s]\u001b[A\n",
      "Epoch 122:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.30it/s]\u001b[A\n",
      "Epoch 122:  91%|█████████ | 710/780 [06:17<00:37,  1.88it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.49it/s]\u001b[A\n",
      "Epoch 122:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 714/780 [06:18<00:34,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.62it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.59it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 718/780 [06:18<00:32,  1.89it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:14,  4.41it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.54it/s]\u001b[A\n",
      "Epoch 122:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.60it/s]\u001b[A\n",
      "Epoch 122:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.34it/s]\u001b[A\n",
      "Epoch 122:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.55it/s]\u001b[A\n",
      "Epoch 122:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.52it/s]\u001b[A\n",
      "Epoch 122:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:10,  4.61it/s]\u001b[A\n",
      "Epoch 122:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.32it/s]\u001b[A\n",
      "Epoch 122:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:09,  4.72it/s]\u001b[A\n",
      "Epoch 122:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.67it/s]\u001b[A\n",
      "Epoch 122:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.32it/s]\u001b[A\n",
      "Epoch 122:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.65it/s]\u001b[A\n",
      "Epoch 122:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 122:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.36it/s]\u001b[A\n",
      "Epoch 122:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 122:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.60it/s]\u001b[A\n",
      "Epoch 122:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:07,  4.26it/s]\u001b[A\n",
      "Epoch 122:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.41it/s]\u001b[A\n",
      "Epoch 122:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 122:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.37it/s]\u001b[A\n",
      "Epoch 122:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 122:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 122:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.57it/s]\u001b[A\n",
      "Epoch 122:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.30it/s]\u001b[A\n",
      "Epoch 122:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.50it/s]\u001b[A\n",
      "Epoch 122:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.46it/s]\u001b[A\n",
      "Epoch 122:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.37it/s]\u001b[A\n",
      "Epoch 122:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.53it/s]\u001b[A\n",
      "Epoch 122:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 122:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.46it/s]\u001b[A\n",
      "Epoch 122: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 122: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.135, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0779, train_loss_epoch=0.158, val_loss_step=0.328]\n",
      "Epoch 122: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.135, v_num=87, val_loss_epoch=0.694, train_loss_step=0.123, train_loss_epoch=0.159, val_loss_step=0.363] \n",
      "Epoch 123:  84%|████████▍ | 656/780 [06:08<01:09,  1.78it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 123:  84%|████████▍ | 658/780 [06:09<01:08,  1.78it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.95it/s]\u001b[A\n",
      "Epoch 123:  85%|████████▍ | 660/780 [06:10<01:07,  1.78it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.12it/s]\u001b[A\n",
      "Epoch 123:  85%|████████▍ | 662/780 [06:10<01:06,  1.79it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:30,  3.86it/s]\u001b[A\n",
      "Epoch 123:  85%|████████▌ | 664/780 [06:10<01:04,  1.79it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.01it/s]\u001b[A\n",
      "Epoch 123:  85%|████████▌ | 666/780 [06:11<01:03,  1.79it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.32it/s]\u001b[A\n",
      "Epoch 123:  86%|████████▌ | 668/780 [06:11<01:02,  1.80it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.39it/s]\u001b[A\n",
      "Epoch 123:  86%|████████▌ | 670/780 [06:12<01:01,  1.80it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.34it/s]\u001b[A\n",
      "Epoch 123:  86%|████████▌ | 672/780 [06:12<00:59,  1.80it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 123:  86%|████████▋ | 674/780 [06:13<00:58,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.58it/s]\u001b[A\n",
      "Epoch 123:  87%|████████▋ | 676/780 [06:13<00:57,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.49it/s]\u001b[A\n",
      "Epoch 123:  87%|████████▋ | 678/780 [06:14<00:56,  1.81it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.58it/s]\u001b[A\n",
      "Epoch 123:  87%|████████▋ | 680/780 [06:14<00:55,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:21,  4.60it/s]\u001b[A\n",
      "Epoch 123:  87%|████████▋ | 682/780 [06:14<00:53,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.35it/s]\u001b[A\n",
      "Epoch 123:  88%|████████▊ | 684/780 [06:15<00:52,  1.82it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.61it/s]\u001b[A\n",
      "Epoch 123:  88%|████████▊ | 686/780 [06:15<00:51,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:21,  4.43it/s]\u001b[A\n",
      "Epoch 123:  88%|████████▊ | 688/780 [06:16<00:50,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 123:  88%|████████▊ | 690/780 [06:16<00:49,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.51it/s]\u001b[A\n",
      "Epoch 123:  89%|████████▊ | 692/780 [06:17<00:47,  1.83it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.48it/s]\u001b[A\n",
      "Epoch 123:  89%|████████▉ | 694/780 [06:17<00:46,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.57it/s]\u001b[A\n",
      "Epoch 123:  89%|████████▉ | 696/780 [06:18<00:45,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.37it/s]\u001b[A\n",
      "Epoch 123:  89%|████████▉ | 698/780 [06:18<00:44,  1.84it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.45it/s]\u001b[A\n",
      "Epoch 123:  90%|████████▉ | 700/780 [06:18<00:43,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.26it/s]\u001b[A\n",
      "Epoch 123:  90%|█████████ | 702/780 [06:19<00:42,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.41it/s]\u001b[A\n",
      "Epoch 123:  90%|█████████ | 704/780 [06:19<00:41,  1.85it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.50it/s]\u001b[A\n",
      "Epoch 123:  91%|█████████ | 706/780 [06:20<00:39,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:17,  4.29it/s]\u001b[A\n",
      "Epoch 123:  91%|█████████ | 708/780 [06:20<00:38,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.44it/s]\u001b[A\n",
      "Epoch 123:  91%|█████████ | 710/780 [06:21<00:37,  1.86it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 123:  91%|█████████▏| 712/780 [06:21<00:36,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:15,  4.29it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 714/780 [06:22<00:35,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.59it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 716/780 [06:22<00:34,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.57it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 718/780 [06:23<00:33,  1.87it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.44it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 720/780 [06:23<00:31,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:12,  4.70it/s]\u001b[A\n",
      "Epoch 123:  93%|█████████▎| 722/780 [06:23<00:30,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.55it/s]\u001b[A\n",
      "Epoch 123:  93%|█████████▎| 724/780 [06:24<00:29,  1.88it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.64it/s]\u001b[A\n",
      "Epoch 123:  93%|█████████▎| 726/780 [06:24<00:28,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:12,  4.34it/s]\u001b[A\n",
      "Epoch 123:  93%|█████████▎| 728/780 [06:25<00:27,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 123:  94%|█████████▎| 730/780 [06:25<00:26,  1.89it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.50it/s]\u001b[A\n",
      "Epoch 123:  94%|█████████▍| 732/780 [06:26<00:25,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:11,  4.29it/s]\u001b[A\n",
      "Epoch 123:  94%|█████████▍| 734/780 [06:26<00:24,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.52it/s]\u001b[A\n",
      "Epoch 123:  94%|█████████▍| 736/780 [06:27<00:23,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.57it/s]\u001b[A\n",
      "Epoch 123:  95%|█████████▍| 738/780 [06:27<00:22,  1.90it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.43it/s]\u001b[A\n",
      "Epoch 123:  95%|█████████▍| 740/780 [06:27<00:20,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.52it/s]\u001b[A\n",
      "Epoch 123:  95%|█████████▌| 742/780 [06:28<00:19,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.55it/s]\u001b[A\n",
      "Epoch 123:  95%|█████████▌| 744/780 [06:28<00:18,  1.91it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.33it/s]\u001b[A\n",
      "Epoch 123:  96%|█████████▌| 746/780 [06:29<00:17,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.50it/s]\u001b[A\n",
      "Epoch 123:  96%|█████████▌| 748/780 [06:29<00:16,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.43it/s]\u001b[A\n",
      "Epoch 123:  96%|█████████▌| 750/780 [06:30<00:15,  1.92it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.66it/s]\u001b[A\n",
      "Epoch 123:  96%|█████████▋| 752/780 [06:30<00:14,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 123:  97%|█████████▋| 754/780 [06:31<00:13,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.59it/s]\u001b[A\n",
      "Epoch 123:  97%|█████████▋| 756/780 [06:31<00:12,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.68it/s]\u001b[A\n",
      "Epoch 123:  97%|█████████▋| 758/780 [06:31<00:11,  1.93it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.48it/s]\u001b[A\n",
      "Epoch 123:  97%|█████████▋| 760/780 [06:32<00:10,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 123:  98%|█████████▊| 762/780 [06:32<00:09,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.45it/s]\u001b[A\n",
      "Epoch 123:  98%|█████████▊| 764/780 [06:33<00:08,  1.94it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.48it/s]\u001b[A\n",
      "Epoch 123:  98%|█████████▊| 766/780 [06:33<00:07,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.52it/s]\u001b[A\n",
      "Epoch 123:  98%|█████████▊| 768/780 [06:34<00:06,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.26it/s]\u001b[A\n",
      "Epoch 123:  99%|█████████▊| 770/780 [06:34<00:05,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.53it/s]\u001b[A\n",
      "Epoch 123:  99%|█████████▉| 772/780 [06:35<00:04,  1.95it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 123:  99%|█████████▉| 774/780 [06:35<00:03,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.30it/s]\u001b[A\n",
      "Epoch 123:  99%|█████████▉| 776/780 [06:35<00:02,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.52it/s]\u001b[A\n",
      "Epoch 123: 100%|█████████▉| 778/780 [06:36<00:01,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 123: 100%|██████████| 780/780 [06:36<00:00,  1.97it/s, loss=0.163, v_num=87, val_loss_epoch=0.694, train_loss_step=0.110, train_loss_epoch=0.159, val_loss_step=0.363]\n",
      "Epoch 123: 100%|██████████| 780/780 [06:37<00:00,  1.96it/s, loss=0.163, v_num=87, val_loss_epoch=0.567, train_loss_step=0.0436, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Epoch 124:  84%|████████▍ | 656/780 [06:03<01:08,  1.80it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 124:  84%|████████▍ | 658/780 [06:05<01:07,  1.80it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.03it/s]\u001b[A\n",
      "Epoch 124:  85%|████████▍ | 660/780 [06:05<01:06,  1.81it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:38,  3.10it/s]\u001b[A\n",
      "Epoch 124:  85%|████████▍ | 662/780 [06:06<01:05,  1.81it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:31,  3.73it/s]\u001b[A\n",
      "Epoch 124:  85%|████████▌ | 664/780 [06:06<01:04,  1.81it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:28,  4.06it/s]\u001b[A\n",
      "Epoch 124:  85%|████████▌ | 666/780 [06:06<01:02,  1.81it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:27,  4.10it/s]\u001b[A\n",
      "Epoch 124:  86%|████████▌ | 668/780 [06:07<01:01,  1.82it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:25,  4.43it/s]\u001b[A\n",
      "Epoch 124:  86%|████████▌ | 670/780 [06:07<01:00,  1.82it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:25,  4.26it/s]\u001b[A\n",
      "Epoch 124:  86%|████████▌ | 672/780 [06:08<00:59,  1.82it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.33it/s]\u001b[A\n",
      "Epoch 124:  86%|████████▋ | 674/780 [06:08<00:57,  1.83it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:23,  4.56it/s]\u001b[A\n",
      "Epoch 124:  87%|████████▋ | 676/780 [06:09<00:56,  1.83it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:24,  4.25it/s]\u001b[A\n",
      "Epoch 124:  87%|████████▋ | 678/780 [06:09<00:55,  1.83it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.47it/s]\u001b[A\n",
      "Epoch 124:  87%|████████▋ | 680/780 [06:10<00:54,  1.84it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.51it/s]\u001b[A\n",
      "Epoch 124:  87%|████████▋ | 682/780 [06:10<00:53,  1.84it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:23,  4.22it/s]\u001b[A\n",
      "Epoch 124:  88%|████████▊ | 684/780 [06:11<00:52,  1.84it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  23%|██▎       | 28/124 [00:07<00:21,  4.37it/s]\u001b[A\n",
      "Epoch 124:  88%|████████▊ | 686/780 [06:11<00:50,  1.85it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 124:  88%|████████▊ | 688/780 [06:11<00:49,  1.85it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:19,  4.60it/s]\u001b[A\n",
      "Epoch 124:  88%|████████▊ | 690/780 [06:12<00:48,  1.85it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:21,  4.19it/s]\u001b[A\n",
      "Epoch 124:  89%|████████▊ | 692/780 [06:12<00:47,  1.86it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:20,  4.35it/s]\u001b[A\n",
      "Epoch 124:  89%|████████▉ | 694/780 [06:13<00:46,  1.86it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.38it/s]\u001b[A\n",
      "Epoch 124:  89%|████████▉ | 696/780 [06:13<00:45,  1.86it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:19,  4.27it/s]\u001b[A\n",
      "Epoch 124:  89%|████████▉ | 698/780 [06:14<00:43,  1.87it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.46it/s]\u001b[A\n",
      "Epoch 124:  90%|████████▉ | 700/780 [06:14<00:42,  1.87it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.29it/s]\u001b[A\n",
      "Epoch 124:  90%|█████████ | 702/780 [06:15<00:41,  1.87it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  37%|███▋      | 46/124 [00:11<00:17,  4.50it/s]\u001b[A\n",
      "Epoch 124:  90%|█████████ | 704/780 [06:15<00:40,  1.87it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.59it/s]\u001b[A\n",
      "Epoch 124:  91%|█████████ | 706/780 [06:16<00:39,  1.88it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  40%|████      | 50/124 [00:12<00:17,  4.29it/s]\u001b[A\n",
      "Epoch 124:  91%|█████████ | 708/780 [06:16<00:38,  1.88it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.45it/s]\u001b[A\n",
      "Epoch 124:  91%|█████████ | 710/780 [06:16<00:37,  1.88it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.50it/s]\u001b[A\n",
      "Epoch 124:  91%|█████████▏| 712/780 [06:17<00:36,  1.89it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:16,  4.23it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 714/780 [06:17<00:34,  1.89it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 716/780 [06:18<00:33,  1.89it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:14,  4.39it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 718/780 [06:18<00:32,  1.90it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.48it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 720/780 [06:19<00:31,  1.90it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  52%|█████▏    | 64/124 [00:15<00:14,  4.20it/s]\u001b[A\n",
      "Epoch 124:  93%|█████████▎| 722/780 [06:19<00:30,  1.90it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:13,  4.36it/s]\u001b[A\n",
      "Epoch 124:  93%|█████████▎| 724/780 [06:20<00:29,  1.90it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  55%|█████▍    | 68/124 [00:16<00:12,  4.35it/s]\u001b[A\n",
      "Epoch 124:  93%|█████████▎| 726/780 [06:20<00:28,  1.91it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:13,  4.15it/s]\u001b[A\n",
      "Epoch 124:  93%|█████████▎| 728/780 [06:21<00:27,  1.91it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  58%|█████▊    | 72/124 [00:17<00:11,  4.39it/s]\u001b[A\n",
      "Epoch 124:  94%|█████████▎| 730/780 [06:21<00:26,  1.91it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.23it/s]\u001b[A\n",
      "Epoch 124:  94%|█████████▍| 732/780 [06:22<00:25,  1.92it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.69it/s]\u001b[A\n",
      "Epoch 124:  94%|█████████▍| 734/780 [06:22<00:23,  1.92it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:10,  4.46it/s]\u001b[A\n",
      "Epoch 124:  94%|█████████▍| 736/780 [06:22<00:22,  1.92it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.16it/s]\u001b[A\n",
      "Epoch 124:  95%|█████████▍| 738/780 [06:23<00:21,  1.93it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  66%|██████▌   | 82/124 [00:19<00:09,  4.51it/s]\u001b[A\n",
      "Epoch 124:  95%|█████████▍| 740/780 [06:23<00:20,  1.93it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.61it/s]\u001b[A\n",
      "Epoch 124:  95%|█████████▌| 742/780 [06:24<00:19,  1.93it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  69%|██████▉   | 86/124 [00:20<00:08,  4.25it/s]\u001b[A\n",
      "Epoch 124:  95%|█████████▌| 744/780 [06:24<00:18,  1.93it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.34it/s]\u001b[A\n",
      "Epoch 124:  96%|█████████▌| 746/780 [06:25<00:17,  1.94it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  73%|███████▎  | 90/124 [00:21<00:07,  4.49it/s]\u001b[A\n",
      "Epoch 124:  96%|█████████▌| 748/780 [06:25<00:16,  1.94it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:07,  4.44it/s]\u001b[A\n",
      "Epoch 124:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  76%|███████▌  | 94/124 [00:22<00:07,  4.24it/s]\u001b[A\n",
      "Epoch 124:  96%|█████████▋| 752/780 [06:26<00:14,  1.95it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  77%|███████▋  | 96/124 [00:22<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 124:  97%|█████████▋| 754/780 [06:26<00:13,  1.95it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.48it/s]\u001b[A\n",
      "Epoch 124:  97%|█████████▋| 756/780 [06:27<00:12,  1.95it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  81%|████████  | 100/124 [00:23<00:05,  4.29it/s]\u001b[A\n",
      "Epoch 124:  97%|█████████▋| 758/780 [06:27<00:11,  1.95it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.58it/s]\u001b[A\n",
      "Epoch 124:  97%|█████████▋| 760/780 [06:28<00:10,  1.96it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  84%|████████▍ | 104/124 [00:24<00:04,  4.36it/s]\u001b[A\n",
      "Epoch 124:  98%|█████████▊| 762/780 [06:28<00:09,  1.96it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:03,  4.58it/s]\u001b[A\n",
      "Epoch 124:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  87%|████████▋ | 108/124 [00:25<00:03,  4.60it/s]\u001b[A\n",
      "Epoch 124:  98%|█████████▊| 766/780 [06:29<00:07,  1.97it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  89%|████████▊ | 110/124 [00:25<00:03,  4.24it/s]\u001b[A\n",
      "Epoch 124:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  90%|█████████ | 112/124 [00:26<00:02,  4.42it/s]\u001b[A\n",
      "Epoch 124:  99%|█████████▊| 770/780 [06:30<00:05,  1.97it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  92%|█████████▏| 114/124 [00:26<00:02,  4.58it/s]\u001b[A\n",
      "Epoch 124:  99%|█████████▉| 772/780 [06:30<00:04,  1.97it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  94%|█████████▎| 116/124 [00:27<00:01,  4.26it/s]\u001b[A\n",
      "Epoch 124:  99%|█████████▉| 774/780 [06:31<00:03,  1.98it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  95%|█████████▌| 118/124 [00:27<00:01,  4.40it/s]\u001b[A\n",
      "Epoch 124:  99%|█████████▉| 776/780 [06:31<00:02,  1.98it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.83it/s]\u001b[A\n",
      "Epoch 124: 100%|█████████▉| 778/780 [06:32<00:01,  1.98it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Validating:  98%|█████████▊| 122/124 [00:28<00:00,  4.77it/s]\u001b[A\n",
      "Epoch 124: 100%|██████████| 780/780 [06:32<00:00,  1.99it/s, loss=0.128, v_num=87, val_loss_epoch=0.567, train_loss_step=0.158, train_loss_epoch=0.155, val_loss_step=1.120]\n",
      "Epoch 124: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.128, v_num=87, val_loss_epoch=0.618, train_loss_step=0.137, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Epoch 125:  84%|████████▍ | 656/780 [06:05<01:09,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 125:  84%|████████▍ | 658/780 [06:06<01:07,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:00,  2.02it/s]\u001b[A\n",
      "Epoch 125:  85%|████████▍ | 660/780 [06:06<01:06,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.23it/s]\u001b[A\n",
      "Epoch 125:  85%|████████▍ | 662/780 [06:07<01:05,  1.80it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:   5%|▍         | 6/124 [00:02<00:32,  3.67it/s]\u001b[A\n",
      "Epoch 125:  85%|████████▌ | 664/780 [06:07<01:04,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:27,  4.19it/s]\u001b[A\n",
      "Epoch 125:  85%|████████▌ | 666/780 [06:08<01:03,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.34it/s]\u001b[A\n",
      "Epoch 125:  86%|████████▌ | 668/780 [06:08<01:01,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:26,  4.18it/s]\u001b[A\n",
      "Epoch 125:  86%|████████▌ | 670/780 [06:09<01:00,  1.81it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:24,  4.42it/s]\u001b[A\n",
      "Epoch 125:  86%|████████▌ | 672/780 [06:09<00:59,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:23,  4.57it/s]\u001b[A\n",
      "Epoch 125:  86%|████████▋ | 674/780 [06:10<00:58,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:25,  4.23it/s]\u001b[A\n",
      "Epoch 125:  87%|████████▋ | 676/780 [06:10<00:57,  1.82it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:23,  4.44it/s]\u001b[A\n",
      "Epoch 125:  87%|████████▋ | 678/780 [06:10<00:55,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 125:  87%|████████▋ | 680/780 [06:11<00:54,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  19%|█▉        | 24/124 [00:06<00:22,  4.36it/s]\u001b[A\n",
      "Epoch 125:  87%|████████▋ | 682/780 [06:11<00:53,  1.83it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.44it/s]\u001b[A\n",
      "Epoch 125:  88%|████████▊ | 684/780 [06:12<00:52,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:21,  4.52it/s]\u001b[A\n",
      "Epoch 125:  88%|████████▊ | 686/780 [06:12<00:51,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.58it/s]\u001b[A\n",
      "Epoch 125:  88%|████████▊ | 688/780 [06:13<00:49,  1.84it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.35it/s]\u001b[A\n",
      "Epoch 125:  88%|████████▊ | 690/780 [06:13<00:48,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:19,  4.59it/s]\u001b[A\n",
      "Epoch 125:  89%|████████▊ | 692/780 [06:14<00:47,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.62it/s]\u001b[A\n",
      "Epoch 125:  89%|████████▉ | 694/780 [06:14<00:46,  1.85it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:19,  4.40it/s]\u001b[A\n",
      "Epoch 125:  89%|████████▉ | 696/780 [06:14<00:45,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.54it/s]\u001b[A\n",
      "Epoch 125:  89%|████████▉ | 698/780 [06:15<00:44,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  34%|███▍      | 42/124 [00:10<00:18,  4.55it/s]\u001b[A\n",
      "Epoch 125:  90%|████████▉ | 700/780 [06:15<00:42,  1.86it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:18,  4.33it/s]\u001b[A\n",
      "Epoch 125:  90%|█████████ | 702/780 [06:16<00:41,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:16,  4.60it/s]\u001b[A\n",
      "Epoch 125:  90%|█████████ | 704/780 [06:16<00:40,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.58it/s]\u001b[A\n",
      "Epoch 125:  91%|█████████ | 706/780 [06:17<00:39,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.52it/s]\u001b[A\n",
      "Epoch 125:  91%|█████████ | 708/780 [06:17<00:38,  1.87it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:15,  4.63it/s]\u001b[A\n",
      "Epoch 125:  91%|█████████ | 710/780 [06:18<00:37,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.44it/s]\u001b[A\n",
      "Epoch 125:  91%|█████████▏| 712/780 [06:18<00:36,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.67it/s]\u001b[A\n",
      "Epoch 125:  92%|█████████▏| 714/780 [06:18<00:35,  1.88it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:14,  4.54it/s]\u001b[A\n",
      "Epoch 125:  92%|█████████▏| 716/780 [06:19<00:33,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  48%|████▊     | 60/124 [00:14<00:13,  4.64it/s]\u001b[A\n",
      "Epoch 125:  92%|█████████▏| 718/780 [06:19<00:32,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.69it/s]\u001b[A\n",
      "Epoch 125:  92%|█████████▏| 720/780 [06:20<00:31,  1.89it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.43it/s]\u001b[A\n",
      "Epoch 125:  93%|█████████▎| 722/780 [06:20<00:30,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.51it/s]\u001b[A\n",
      "Epoch 125:  93%|█████████▎| 724/780 [06:21<00:29,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:12,  4.40it/s]\u001b[A\n",
      "Epoch 125:  93%|█████████▎| 726/780 [06:21<00:28,  1.90it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.58it/s]\u001b[A\n",
      "Epoch 125:  93%|█████████▎| 728/780 [06:22<00:27,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.70it/s]\u001b[A\n",
      "Epoch 125:  94%|█████████▎| 730/780 [06:22<00:26,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  60%|█████▉    | 74/124 [00:17<00:11,  4.40it/s]\u001b[A\n",
      "Epoch 125:  94%|█████████▍| 732/780 [06:22<00:25,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.74it/s]\u001b[A\n",
      "Epoch 125:  94%|█████████▍| 734/780 [06:23<00:24,  1.91it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  63%|██████▎   | 78/124 [00:18<00:09,  4.66it/s]\u001b[A\n",
      "Epoch 125:  94%|█████████▍| 736/780 [06:23<00:22,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:10,  4.38it/s]\u001b[A\n",
      "Epoch 125:  95%|█████████▍| 738/780 [06:24<00:21,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 125:  95%|█████████▍| 740/780 [06:24<00:20,  1.92it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:08,  4.60it/s]\u001b[A\n",
      "Epoch 125:  95%|█████████▌| 742/780 [06:25<00:19,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.29it/s]\u001b[A\n",
      "Epoch 125:  95%|█████████▌| 744/780 [06:25<00:18,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:08,  4.46it/s]\u001b[A\n",
      "Epoch 125:  96%|█████████▌| 746/780 [06:26<00:17,  1.93it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.61it/s]\u001b[A\n",
      "Epoch 125:  96%|█████████▌| 748/780 [06:26<00:16,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  74%|███████▍  | 92/124 [00:21<00:06,  4.74it/s]\u001b[A\n",
      "Epoch 125:  96%|█████████▌| 750/780 [06:26<00:15,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.47it/s]\u001b[A\n",
      "Epoch 125:  96%|█████████▋| 752/780 [06:27<00:14,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 125:  97%|█████████▋| 754/780 [06:27<00:13,  1.94it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.69it/s]\u001b[A\n",
      "Epoch 125:  97%|█████████▋| 756/780 [06:28<00:12,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.52it/s]\u001b[A\n",
      "Epoch 125:  97%|█████████▋| 758/780 [06:28<00:11,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.73it/s]\u001b[A\n",
      "Epoch 125:  97%|█████████▋| 760/780 [06:29<00:10,  1.95it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.76it/s]\u001b[A\n",
      "Epoch 125:  98%|█████████▊| 762/780 [06:29<00:09,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.37it/s]\u001b[A\n",
      "Epoch 125:  98%|█████████▊| 764/780 [06:29<00:08,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.72it/s]\u001b[A\n",
      "Epoch 125:  98%|█████████▊| 766/780 [06:30<00:07,  1.96it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:02,  4.76it/s]\u001b[A\n",
      "Epoch 125:  98%|█████████▊| 768/780 [06:30<00:06,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.38it/s]\u001b[A\n",
      "Epoch 125:  99%|█████████▊| 770/780 [06:31<00:05,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.51it/s]\u001b[A\n",
      "Epoch 125:  99%|█████████▉| 772/780 [06:31<00:04,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.62it/s]\u001b[A\n",
      "Epoch 125:  99%|█████████▉| 774/780 [06:32<00:03,  1.97it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.36it/s]\u001b[A\n",
      "Epoch 125:  99%|█████████▉| 776/780 [06:32<00:02,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.48it/s]\u001b[A\n",
      "Epoch 125: 100%|█████████▉| 778/780 [06:33<00:01,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 125: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.618, train_loss_step=0.0465, train_loss_epoch=0.161, val_loss_step=0.352]\n",
      "Epoch 125: 100%|██████████| 780/780 [06:33<00:00,  1.98it/s, loss=0.174, v_num=87, val_loss_epoch=0.516, train_loss_step=0.111, train_loss_epoch=0.160, val_loss_step=0.532] \n",
      "Epoch 126:  84%|████████▍ | 656/780 [06:02<01:08,  1.81it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 126:  84%|████████▍ | 658/780 [06:03<01:07,  1.81it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:   2%|▏         | 2/124 [00:01<01:02,  1.96it/s]\u001b[A\n",
      "Epoch 126:  85%|████████▍ | 660/780 [06:04<01:06,  1.81it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:   3%|▎         | 4/124 [00:01<00:37,  3.17it/s]\u001b[A\n",
      "Epoch 126:  85%|████████▍ | 662/780 [06:04<01:05,  1.81it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:   5%|▍         | 6/124 [00:01<00:29,  3.94it/s]\u001b[A\n",
      "Epoch 126:  85%|████████▌ | 664/780 [06:05<01:03,  1.82it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:   6%|▋         | 8/124 [00:02<00:26,  4.31it/s]\u001b[A\n",
      "Epoch 126:  85%|████████▌ | 666/780 [06:05<01:02,  1.82it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:   8%|▊         | 10/124 [00:02<00:26,  4.29it/s]\u001b[A\n",
      "Epoch 126:  86%|████████▌ | 668/780 [06:06<01:01,  1.82it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  10%|▉         | 12/124 [00:03<00:24,  4.55it/s]\u001b[A\n",
      "Epoch 126:  86%|████████▌ | 670/780 [06:06<01:00,  1.83it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  11%|█▏        | 14/124 [00:03<00:23,  4.59it/s]\u001b[A\n",
      "Epoch 126:  86%|████████▌ | 672/780 [06:07<00:58,  1.83it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  13%|█▎        | 16/124 [00:04<00:24,  4.41it/s]\u001b[A\n",
      "Epoch 126:  86%|████████▋ | 674/780 [06:07<00:57,  1.83it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  15%|█▍        | 18/124 [00:04<00:22,  4.62it/s]\u001b[A\n",
      "Epoch 126:  87%|████████▋ | 676/780 [06:07<00:56,  1.84it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  16%|█▌        | 20/124 [00:05<00:22,  4.56it/s]\u001b[A\n",
      "Epoch 126:  87%|████████▋ | 678/780 [06:08<00:55,  1.84it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  18%|█▊        | 22/124 [00:05<00:22,  4.59it/s]\u001b[A\n",
      "Epoch 126:  87%|████████▋ | 680/780 [06:08<00:54,  1.84it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  19%|█▉        | 24/124 [00:05<00:21,  4.68it/s]\u001b[A\n",
      "Epoch 126:  87%|████████▋ | 682/780 [06:09<00:53,  1.85it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  21%|██        | 26/124 [00:06<00:22,  4.45it/s]\u001b[A\n",
      "Epoch 126:  88%|████████▊ | 684/780 [06:09<00:51,  1.85it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  23%|██▎       | 28/124 [00:06<00:20,  4.66it/s]\u001b[A\n",
      "Epoch 126:  88%|████████▊ | 686/780 [06:10<00:50,  1.85it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  24%|██▍       | 30/124 [00:07<00:20,  4.62it/s]\u001b[A\n",
      "Epoch 126:  88%|████████▊ | 688/780 [06:10<00:49,  1.86it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  26%|██▌       | 32/124 [00:07<00:21,  4.36it/s]\u001b[A\n",
      "Epoch 126:  88%|████████▊ | 690/780 [06:11<00:48,  1.86it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  27%|██▋       | 34/124 [00:08<00:18,  4.76it/s]\u001b[A\n",
      "Epoch 126:  89%|████████▊ | 692/780 [06:11<00:47,  1.86it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  29%|██▉       | 36/124 [00:08<00:19,  4.56it/s]\u001b[A\n",
      "Epoch 126:  89%|████████▉ | 694/780 [06:11<00:46,  1.87it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  31%|███       | 38/124 [00:09<00:18,  4.61it/s]\u001b[A\n",
      "Epoch 126:  89%|████████▉ | 696/780 [06:12<00:44,  1.87it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  32%|███▏      | 40/124 [00:09<00:18,  4.59it/s]\u001b[A\n",
      "Epoch 126:  89%|████████▉ | 698/780 [06:12<00:43,  1.87it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  34%|███▍      | 42/124 [00:09<00:18,  4.36it/s]\u001b[A\n",
      "Epoch 126:  90%|████████▉ | 700/780 [06:13<00:42,  1.88it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  35%|███▌      | 44/124 [00:10<00:17,  4.58it/s]\u001b[A\n",
      "Epoch 126:  90%|█████████ | 702/780 [06:13<00:41,  1.88it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  37%|███▋      | 46/124 [00:10<00:17,  4.46it/s]\u001b[A\n",
      "Epoch 126:  90%|█████████ | 704/780 [06:14<00:40,  1.88it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  39%|███▊      | 48/124 [00:11<00:16,  4.69it/s]\u001b[A\n",
      "Epoch 126:  91%|█████████ | 706/780 [06:14<00:39,  1.89it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  40%|████      | 50/124 [00:11<00:16,  4.61it/s]\u001b[A\n",
      "Epoch 126:  91%|█████████ | 708/780 [06:14<00:38,  1.89it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  42%|████▏     | 52/124 [00:12<00:16,  4.30it/s]\u001b[A\n",
      "Epoch 126:  91%|█████████ | 710/780 [06:15<00:37,  1.89it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  44%|████▎     | 54/124 [00:12<00:15,  4.52it/s]\u001b[A\n",
      "Epoch 126:  91%|█████████▏| 712/780 [06:15<00:35,  1.89it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  45%|████▌     | 56/124 [00:13<00:14,  4.63it/s]\u001b[A\n",
      "Epoch 126:  92%|█████████▏| 714/780 [06:16<00:34,  1.90it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  47%|████▋     | 58/124 [00:13<00:15,  4.35it/s]\u001b[A\n",
      "Epoch 126:  92%|█████████▏| 716/780 [06:16<00:33,  1.90it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  48%|████▊     | 60/124 [00:13<00:14,  4.51it/s]\u001b[A\n",
      "Epoch 126:  92%|█████████▏| 718/780 [06:17<00:32,  1.90it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  50%|█████     | 62/124 [00:14<00:13,  4.68it/s]\u001b[A\n",
      "Epoch 126:  92%|█████████▏| 720/780 [06:17<00:31,  1.91it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  52%|█████▏    | 64/124 [00:14<00:13,  4.38it/s]\u001b[A\n",
      "Epoch 126:  93%|█████████▎| 722/780 [06:18<00:30,  1.91it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  53%|█████▎    | 66/124 [00:15<00:12,  4.51it/s]\u001b[A\n",
      "Epoch 126:  93%|█████████▎| 724/780 [06:18<00:29,  1.91it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  55%|█████▍    | 68/124 [00:15<00:11,  4.72it/s]\u001b[A\n",
      "Epoch 126:  93%|█████████▎| 726/780 [06:18<00:28,  1.92it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  56%|█████▋    | 70/124 [00:16<00:11,  4.69it/s]\u001b[A\n",
      "Epoch 126:  93%|█████████▎| 728/780 [06:19<00:27,  1.92it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  58%|█████▊    | 72/124 [00:16<00:11,  4.42it/s]\u001b[A\n",
      "Epoch 126:  94%|█████████▎| 730/780 [06:19<00:26,  1.92it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  60%|█████▉    | 74/124 [00:16<00:10,  4.76it/s]\u001b[A\n",
      "Epoch 126:  94%|█████████▍| 732/780 [06:20<00:24,  1.93it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  61%|██████▏   | 76/124 [00:17<00:10,  4.70it/s]\u001b[A\n",
      "Epoch 126:  94%|█████████▍| 734/780 [06:20<00:23,  1.93it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  63%|██████▎   | 78/124 [00:17<00:10,  4.41it/s]\u001b[A\n",
      "Epoch 126:  94%|█████████▍| 736/780 [06:21<00:22,  1.93it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  65%|██████▍   | 80/124 [00:18<00:09,  4.52it/s]\u001b[A\n",
      "Epoch 126:  95%|█████████▍| 738/780 [06:21<00:21,  1.93it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  66%|██████▌   | 82/124 [00:18<00:09,  4.59it/s]\u001b[A\n",
      "Epoch 126:  95%|█████████▍| 740/780 [06:21<00:20,  1.94it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  68%|██████▊   | 84/124 [00:19<00:09,  4.33it/s]\u001b[A\n",
      "Epoch 126:  95%|█████████▌| 742/780 [06:22<00:19,  1.94it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  69%|██████▉   | 86/124 [00:19<00:08,  4.51it/s]\u001b[A\n",
      "Epoch 126:  95%|█████████▌| 744/780 [06:22<00:18,  1.94it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  71%|███████   | 88/124 [00:20<00:07,  4.65it/s]\u001b[A\n",
      "Epoch 126:  96%|█████████▌| 746/780 [06:23<00:17,  1.95it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  73%|███████▎  | 90/124 [00:20<00:07,  4.36it/s]\u001b[A\n",
      "Epoch 126:  96%|█████████▌| 748/780 [06:23<00:16,  1.95it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  74%|███████▍  | 92/124 [00:20<00:07,  4.53it/s]\u001b[A\n",
      "Epoch 126:  96%|█████████▌| 750/780 [06:24<00:15,  1.95it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  76%|███████▌  | 94/124 [00:21<00:06,  4.65it/s]\u001b[A\n",
      "Epoch 126:  96%|█████████▋| 752/780 [06:24<00:14,  1.96it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  77%|███████▋  | 96/124 [00:21<00:06,  4.42it/s]\u001b[A\n",
      "Epoch 126:  97%|█████████▋| 754/780 [06:25<00:13,  1.96it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  79%|███████▉  | 98/124 [00:22<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 126:  97%|█████████▋| 756/780 [06:25<00:12,  1.96it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  81%|████████  | 100/124 [00:22<00:05,  4.50it/s]\u001b[A\n",
      "Epoch 126:  97%|█████████▋| 758/780 [06:25<00:11,  1.96it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  82%|████████▏ | 102/124 [00:23<00:04,  4.65it/s]\u001b[A\n",
      "Epoch 126:  97%|█████████▋| 760/780 [06:26<00:10,  1.97it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  84%|████████▍ | 104/124 [00:23<00:04,  4.34it/s]\u001b[A\n",
      "Epoch 126:  98%|█████████▊| 762/780 [06:26<00:09,  1.97it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  85%|████████▌ | 106/124 [00:24<00:04,  4.49it/s]\u001b[A\n",
      "Epoch 126:  98%|█████████▊| 764/780 [06:27<00:08,  1.97it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  87%|████████▋ | 108/124 [00:24<00:03,  4.56it/s]\u001b[A\n",
      "Epoch 126:  98%|█████████▊| 766/780 [06:27<00:07,  1.98it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  89%|████████▊ | 110/124 [00:24<00:03,  4.38it/s]\u001b[A\n",
      "Epoch 126:  98%|█████████▊| 768/780 [06:28<00:06,  1.98it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  90%|█████████ | 112/124 [00:25<00:02,  4.59it/s]\u001b[A\n",
      "Epoch 126:  99%|█████████▊| 770/780 [06:28<00:05,  1.98it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  92%|█████████▏| 114/124 [00:25<00:02,  4.62it/s]\u001b[A\n",
      "Epoch 126:  99%|█████████▉| 772/780 [06:29<00:04,  1.98it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  94%|█████████▎| 116/124 [00:26<00:01,  4.44it/s]\u001b[A\n",
      "Epoch 126:  99%|█████████▉| 774/780 [06:29<00:03,  1.99it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  95%|█████████▌| 118/124 [00:26<00:01,  4.61it/s]\u001b[A\n",
      "Epoch 126:  99%|█████████▉| 776/780 [06:29<00:02,  1.99it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  97%|█████████▋| 120/124 [00:27<00:00,  4.64it/s]\u001b[A\n",
      "Epoch 126: 100%|█████████▉| 778/780 [06:30<00:01,  1.99it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Validating:  98%|█████████▊| 122/124 [00:27<00:00,  4.46it/s]\u001b[A\n",
      "Epoch 126: 100%|██████████| 780/780 [06:30<00:00,  2.00it/s, loss=0.166, v_num=87, val_loss_epoch=0.516, train_loss_step=0.113, train_loss_epoch=0.160, val_loss_step=0.532]\n",
      "Epoch 126: 100%|██████████| 780/780 [06:31<00:00,  1.99it/s, loss=0.166, v_num=87, val_loss_epoch=0.702, train_loss_step=0.201, train_loss_epoch=0.154, val_loss_step=0.804]\n",
      "Epoch 127:  83%|████████▎ | 647/780 [06:16<01:17,  1.72it/s, loss=0.201, v_num=87, val_loss_epoch=0.702, train_loss_step=0.251, train_loss_epoch=0.154, val_loss_step=0.804] "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 128\n",
    "CHANNELS_IMG = 1\n",
    "FEATURES_CRITIC = 32 #64\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = ForecastClassifier(DSDiscriminator, CHANNELS_IMG, \n",
    "                           NUM_CLASSES, IMG_SIZE, FEATURES_CRITIC, \n",
    "                           lr = LEARNING_RATE)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1)\n",
    "trainer.fit(model, dl_train, dl_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-billy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilan",
   "language": "python",
   "name": "ilan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
