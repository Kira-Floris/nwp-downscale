{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atmospheric-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import *\n",
    "from axial_attention import AxialAttention\n",
    "from self_attention_cv import ViT\n",
    "\n",
    "import pickle\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from src.dataloader import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-breakfast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "owned-lease",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cooperative-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADRIVE = '/datadrive_ssd/'\n",
    "dl_train = pickle.load(open(DATADRIVE+\"saved_datasets/trainloader_single_forecast_only_log_trans_full_padded_24.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-laser",
   "metadata": {},
   "source": [
    "# Testing broad field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "material-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadLeinGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BroadLeinGen, self).__init__()\n",
    "        self.embed = nn.Conv2d(1,255, kernel_size=3, padding=1)\n",
    "        self.process = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=2,  nonlin = 'relu'), \n",
    "                                     LeinResBlock(in_planes=256, planes=256, stride=2, nonlin = 'relu'), \n",
    "#                                      LeinResBlock(in_planes=256, planes=256, stride=2, nonlin = 'relu')\n",
    "                            #         self.b4 = BasicBlock(in_planes=256, planes=256, stride=1, nonlin = 'leaky_relu')\n",
    "                                        )\n",
    "        self.upscale = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=256, planes=128, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=128, planes=64, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=64, planes=32, stride=1,  nonlin = 'leaky_relu'))\n",
    "        \n",
    "        self.final = nn.Conv2d(32,1, kernel_size=3, padding=1)\n",
    "         \n",
    "    def forward(self, x, noise):\n",
    "        x = F.relu(self.embed(x))\n",
    "        x = torch.cat((x,noise), axis=1)\n",
    "        x = self.process(x)\n",
    "#         print(x.shape)\n",
    "        x = self.upscale(x)\n",
    "        x = torch.sigmoid(self.final(x))\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):#, nn.BatchNorm2d)):\n",
    "#                 nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "            \n",
    "                                     \n",
    "class BroadLeinDisc(nn.Module):\n",
    "    def __init__(self, nonlin = 'leaky_relu'):\n",
    "        super(BroadLeinDisc, self).__init__()\n",
    "        self.hr_block1 = nn.Sequential(LeinResBlock(in_planes = 1, planes=64, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 64, planes=128, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 128, planes=256, stride=2, nonlin = nonlin))\n",
    "        \n",
    "        self.lr_block1 = nn.Sequential(LeinResBlock(in_planes = 1, planes=64, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 64, planes=128, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 128, planes=256, stride=1, nonlin = nonlin))\n",
    "        \n",
    "        self.hr_block2 = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=1, nonlin = nonlin))#, block(in_planes=256, planes=256, stride=1, nonlin = nonlin))\n",
    "        self.lr_block2 = nn.Sequential(LeinResBlock(in_planes=512, planes=256, stride=1, nonlin = nonlin))#,block(in_planes=256, planes=256, stride=1, nonlin = nonlin))\n",
    "        self.dense1 = nn.Linear(512, 256)\n",
    "        self.dense2 = nn.Linear(256, 1)\n",
    "        nn.init.kaiming_normal_(self.dense1.weight, nonlinearity='leaky_relu')\n",
    "        nn.init.kaiming_normal_(self.dense2.weight, nonlinearity = 'linear')\n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, X, y):\n",
    "        hr = self.hr_block1(y)\n",
    "        lr = self.lr_block1(X)\n",
    "        lr = torch.cat((lr,hr), axis=1)\n",
    "        hr = self.hr_block2(hr)\n",
    "        lr = self.lr_block2(lr)\n",
    "        hr = nn.AvgPool2d(16)(hr)\n",
    "        lr = nn.AvgPool2d(16)(lr)\n",
    "        out = torch.cat((torch.squeeze(hr), torch.squeeze(lr)), axis=1)\n",
    "        out = F.leaky_relu(self.dense1(out), negative_slope=0.02)\n",
    "        out = self.dense2(out)\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):#, nn.BatchNorm2d)):\n",
    "#                 nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "golden-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "high_res_size = 128\n",
    "image_channels = 1\n",
    "noise_shape = (1, 64, 64)\n",
    "discriminator_features = 64\n",
    "generator_features = 64\n",
    "lambda_gp = 10\n",
    "num_classes = 2\n",
    "num_embedding_channels = 10\n",
    "\n",
    "\n",
    "model = BroadLeinGANGP(BroadLeinGen, BroadLeinDisc, \n",
    "                  noise_shape, image_channels, \n",
    "                  high_res_size, num_embedding_channels, \n",
    "                  lr = learning_rate,\n",
    "                  lambda_gp=lambda_gp, \n",
    "                  disc_spectral_norm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "measured-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d5344f820>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x,y = next(iter(dl_train))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "ax.imshow(x[0][0])\n",
    "rect = patches.Rectangle((24, 24), 16, 16, linewidth=1, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "finnish-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "run_number = 'test'\n",
    "model_name = 'broadleingan'\n",
    "run_folder = '../models/'+model_name+'/' + run_number\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=run_folder)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dutch-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | gen  | BroadLeinGen  | 4.2 M \n",
      "1 | disc | BroadLeinDisc | 5.6 M \n",
      "---------------------------------------\n",
      "9.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 M     Total params\n",
      "39.008    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b8b9a92f5046ebb8859b08ba56429e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "martial-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 123840), started 0:01:14 ago. (Use '!kill 123840' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9f5edd62630bb32c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9f5edd62630bb32c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "material-warning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-manchester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "capable-rally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(16,128,16,16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "corresponding-occupation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f33af21f550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "attn = AxialAttention(\n",
    "                    dim=128,\n",
    "                    dim_index = 1, \n",
    "                    dim_heads = 32, \n",
    "                    heads = 16,\n",
    "                    num_dimensions = 2, \n",
    "                    sum_axial_out=True)\n",
    "\n",
    "vit = ViT(img_dim=16, heads = 16, in_channels=1, \n",
    "          patch_dim=1, num_classes=10,dim=512, blocks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "understood-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 16, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attn(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-cancellation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-links",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-enterprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-repair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-manchester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-provincial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-upset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "requested-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxialGenerator(nn.Module):\n",
    "    def __init__(self, noise_shape, channels_img, features_g, num_classes, img_size, embed_size):\n",
    "        super(AxialGenerator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.embed = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=embed_size, kernel_size=3, padding=1), \n",
    "                                   AxialAttention(\n",
    "                                    dim=embed_size,\n",
    "                                    dim_index = 1, \n",
    "                                    dim_heads = 32, \n",
    "                                    heads = 4,\n",
    "                                    num_dimensions = 2, \n",
    "                                    sum_axial_out=True)\n",
    "                                  )\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 16 x 16\n",
    "            self._block(noise_shape[0] + embed_size, features_g * 16, 1, 1, 0),  # img: 16x16\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 32x32\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 64x64\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 4, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 128 x 128\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, labels, x):\n",
    "        embedding  = self.embed(labels)\n",
    "        x = torch.cat([x, embedding], dim = 1)\n",
    "        x = self.net(x)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "absent-chick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | gen  | AxialGenerator  | 2.7 M \n",
      "1 | disc | DSDiscriminator | 4.0 M \n",
      "-----------------------------------------\n",
      "6.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 M     Total params\n",
      "26.604    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [32:11<?, ?it/s]  1.19s/it, loss=-78.8, v_num=65, discriminator_loss_step=-103., generator_loss_step=80.50] \n",
      "Epoch 1:  92%|█████████▏| 1209/1312 [24:03<02:03,  1.19s/it, loss=-32.4, v_num=65, discriminator_loss_step=-50.9, generator_loss_step=18.80, discriminator_loss_epoch=-74.7, generator_loss_epoch=66.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 128\n",
    "CHANNELS_IMG = 1\n",
    "NOISE_SHAPE = (1, 16, 16)\n",
    "FEATURES_CRITIC = 32 #64\n",
    "FEATURES_GEN = 32 # 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "NUM_CLASSES = 10\n",
    "GEN_EMBEDDING = 32\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1)\n",
    "model = WGANGP(AxialGenerator, DSDiscriminator, NOISE_SHAPE, CHANNELS_IMG, \n",
    "               FEATURES_GEN, NUM_CLASSES, IMG_SIZE, \n",
    "               GEN_EMBEDDING, FEATURES_CRITIC, lr = LEARNING_RATE)\n",
    "\n",
    "trainer.fit(model, dl_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thrown-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type           | Params\n",
      "----------------------------------------\n",
      "0 | gen  | AxialAttention | 262 K \n",
      "----------------------------------------\n",
      "262 K     Trainable params\n",
      "0         Non-trainable params\n",
      "262 K     Total params\n",
      "1.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "input tensor does not have the correct input dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a9c77f30e3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                             \u001b[0;31m# revert back to previous state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     ) -> None:\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    733\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                             )\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4d8b05eaa520>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4d8b05eaa520>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/axial_attention/axial_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input tensor does not have the correct number of dimensions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input tensor does not have the correct input dimension'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_axial_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: input tensor does not have the correct input dimension"
     ]
    }
   ],
   "source": [
    "# trainer = pl.Trainer(gpus = 0)\n",
    "# trainer.fit(model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "voluntary-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(dl_train, open(\"./dataset/trainloader_single_forecast_only.pkl\", \"wb\"))\n",
    "# pickle.dump(dl_valid, open(\"./dataset/validloader_single_forecast_only.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetNetGenerator(nn.Module):\n",
    "    def __init__(self, noise_shape, channels_img, features_g, num_classes, img_size, embed_size):\n",
    "        super(DSGenerator, self).__init__()\n",
    "        self.spatial\n",
    "        self.embed = nn.Conv2d(in_channels=1, out_channels=embed_size, kernel_size=3, padding=1)\n",
    "        self.attention = \n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 16 x 16\n",
    "            self._block(noise_shape[0] + embed_size, features_g * 16, 1, 1, 0),  # img: 16x16\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 32x32\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 64x64\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 4, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 128 x 128\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, labels, x):\n",
    "        embedding  = self.embed(labels)\n",
    "        x = torch.cat([x, embedding], dim = 1)\n",
    "        x = self.net(x)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-tyler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilan",
   "language": "python",
   "name": "conda-env-ilan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
