{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import *\n",
    "from axial_attention import AxialAttention\n",
    "from self_attention_cv import ViT\n",
    "\n",
    "import pickle\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from src.dataloader import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-convention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "systematic-repository",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADRIVE = '/datadrive_ssd/'\n",
    "dl_train = pickle.load(open(DATADRIVE+\"saved_datasets/trainloader_single_forecast_only_log_trans_full_padded_24.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-junior",
   "metadata": {},
   "source": [
    "# Testing broad field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noble-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadLeinGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BroadLeinGen, self).__init__()\n",
    "        self.embed = nn.Conv2d(1,255, kernel_size=3, padding=1)\n",
    "        self.process = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=2,  nonlin = 'relu'), \n",
    "                                     LeinResBlock(in_planes=256, planes=256, stride=2, nonlin = 'relu'), \n",
    "#                                      LeinResBlock(in_planes=256, planes=256, stride=2, nonlin = 'relu')\n",
    "                            #         self.b4 = BasicBlock(in_planes=256, planes=256, stride=1, nonlin = 'leaky_relu')\n",
    "                                        )\n",
    "        self.upscale = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=256, planes=128, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=128, planes=64, stride=1,  nonlin = 'leaky_relu'),\n",
    "                                     UpSample(2, 'bilinear'),\n",
    "                                     LeinResBlock(in_planes=64, planes=32, stride=1,  nonlin = 'leaky_relu'))\n",
    "        \n",
    "        self.final = nn.Conv2d(32,1, kernel_size=3, padding=1)\n",
    "         \n",
    "    def forward(self, x, noise):\n",
    "        x = F.relu(self.embed(x))\n",
    "        x = torch.cat((x,noise), axis=1)\n",
    "        x = self.process(x)\n",
    "#         print(x.shape)\n",
    "        x = self.upscale(x)\n",
    "        x = torch.sigmoid(self.final(x))\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):#, nn.BatchNorm2d)):\n",
    "#                 nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "            \n",
    "                                     \n",
    "class BroadLeinDisc(nn.Module):\n",
    "    def __init__(self, nonlin = 'leaky_relu'):\n",
    "        super(BroadLeinDisc, self).__init__()\n",
    "        self.hr_block1 = nn.Sequential(LeinResBlock(in_planes = 1, planes=64, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 64, planes=128, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 128, planes=256, stride=2, nonlin = nonlin))\n",
    "        \n",
    "        self.lr_block1 = nn.Sequential(LeinResBlock(in_planes = 1, planes=64, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 64, planes=128, stride=2, nonlin = nonlin), \n",
    "                                       LeinResBlock(in_planes = 128, planes=256, stride=1, nonlin = nonlin))\n",
    "        \n",
    "        self.hr_block2 = nn.Sequential(LeinResBlock(in_planes=256, planes=256, stride=1, nonlin = nonlin))#, block(in_planes=256, planes=256, stride=1, nonlin = nonlin))\n",
    "        self.lr_block2 = nn.Sequential(LeinResBlock(in_planes=512, planes=256, stride=1, nonlin = nonlin))#,block(in_planes=256, planes=256, stride=1, nonlin = nonlin))\n",
    "        self.dense1 = nn.Linear(512, 256)\n",
    "        self.dense2 = nn.Linear(256, 1)\n",
    "        nn.init.kaiming_normal_(self.dense1.weight, nonlinearity='leaky_relu')\n",
    "        nn.init.kaiming_normal_(self.dense2.weight, nonlinearity = 'linear')\n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, X, y):\n",
    "        hr = self.hr_block1(y)\n",
    "        lr = self.lr_block1(X)\n",
    "        lr = torch.cat((lr,hr), axis=1)\n",
    "        hr = self.hr_block2(hr)\n",
    "        lr = self.lr_block2(lr)\n",
    "        hr = nn.AvgPool2d(16)(hr)\n",
    "        lr = nn.AvgPool2d(16)(lr)\n",
    "        out = torch.cat((torch.squeeze(hr), torch.squeeze(lr)), axis=1)\n",
    "        out = F.leaky_relu(self.dense1(out), negative_slope=0.02)\n",
    "        out = self.dense2(out)\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):#, nn.BatchNorm2d)):\n",
    "#                 nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surgical-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "high_res_size = 128\n",
    "image_channels = 1\n",
    "noise_shape = (1, 64, 64)\n",
    "discriminator_features = 64\n",
    "generator_features = 64\n",
    "lambda_gp = 10\n",
    "num_classes = 2\n",
    "num_embedding_channels = 10\n",
    "\n",
    "\n",
    "model = BaseGAN(BroadLeinSAGen, BroadLeinSADisc, \n",
    "                noise_shape, \n",
    "                disc_lr = learning_rate,\n",
    "                lambda_gp=lambda_gp, \n",
    "                disc_spectral_norm = True, \n",
    "                gen_spectral_norm= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "universal-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 64, 64])\n",
      "torch.Size([16, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b24db16d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPOElEQVR4nO3dfYxV9Z3H8feHeaKglAEFh4cUzM76uPVhpz7UTdeUWqlrhP5hFnfdTLokZLPu1jZNurD+YfYPE5M1xv6x7YaolWwRQqi7ENNV6fTBdDdax2JaYESoVBgZGawWEGScYb77xz1sr3inA/fcc++Mv88rIfee3znnno/M9TPnnLnMTxGBmaVrSqMDmFljuQTMEucSMEucS8AscS4Bs8S5BMwSV1gJSFoqabekvZJWF3UcM8tHRXxOQFIT8BpwC9APvATcFRG7an4wM8uluaDXvQ7YGxGvA0jaCCwDKpZAq9piKtMLimJmAMd49+2IuPDM8aJKYD5woGy5H7i+fANJq4BVAFOZxvVaUlAUMwP4YWx+o9J4UfcEVGHsQ9cdEbE2IroioquFtoJimNl4iiqBfmBh2fIC4GBBxzKzHIoqgZeATkmLJbUCK4CtBR3LzHIo5J5ARIxI+gfgWaAJeDwidhZxLDPLp6gbg0TED4AfFPX6ZlYb/sSgWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniXAJmiXMJmCXOJWCWOJeAWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniXAJmiXMJmCXOJWCWOJeAWeKqLgFJCyX9WFKfpJ2S7s3GZ0naJmlP9theu7hmVmt5zgRGgG9ExGXADcA9ki4HVgM9EdEJ9GTLZjZBVV0CETEQEb/Inh8D+oD5wDJgXbbZOmB5zoxmVqCa3BOQtAi4BngRmBsRA1AqCmDOGPusktQrqXeYoVrEMLMq5C4BSecB3we+FhFHz3a/iFgbEV0R0dVCW94YZlalXCUgqYVSAayPiKey4UOSOrL1HcBgvohmVqQ8Px0Q8BjQFxEPl63aCnRnz7uBLdXHM7OiNefY9ybgb4BfSXolG/tn4EFgk6SVwH7gzlwJzaxQVZdARPwM0Birl1T7umZWX/7EoFniXAJmiXMJmCXOJWCWOJeAWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniXAJmiXMJmCXOJWCWOJeAWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniajErcZOk7ZKezpZnSdomaU/22J4/ppkVpRZnAvcCfWXLq4GeiOgEerJlM5ug8k5NvgD4C+DRsuFlwLrs+TpgeZ5jmFmx8p4JPAJ8ExgtG5sbEQMA2eOcSjtKWiWpV1LvMEM5Y5hZtaouAUm3A4MR8XI1+0fE2ojoioiuFtqqjWFmOVU9NTlwE3CHpNuAqcAMSd8DDknqiIgBSR3AYC2Cmlkxqj4TiIg1EbEgIhYBK4AfRcTdwFagO9usG9iSO6WZFaaIzwk8CNwiaQ9wS7ZsZhNUnsuB/xcRPwF+kj3/LbCkFq9rZsXzJwbNEucSMEucS8AscS4Bs8S5BMwS5xIwS5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEucSMEucS8AscS4Bs8S5BMwS5xIwS5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEperBCTNlLRZ0quS+iTdKGmWpG2S9mSP7bUKa2a1l/dM4FvAMxFxKXAV0AesBnoiohPoyZbNbIKqugQkzQA+BzwGEBEfRMTvgGXAumyzdcDyfBHNrEh5zgQuBg4D35W0XdKjkqYDcyNiACB7nFNpZ0mrJPVK6h1mKEcMM8sjTwk0A9cC34mIa4DjnMOpf0SsjYiuiOhqoS1HDDPLI08J9AP9EfFitryZUikcktQBkD0O5otoZkWqugQi4i3ggKRLsqElwC5gK9CdjXUDW3IlNLNCNefc/x+B9ZJagdeBr1Aqlk2SVgL7gTtzHsPMCpSrBCLiFaCrwqoleV7XzOrHnxg0S5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEucSMEucS8AscS4Bs8S5BMwS5xIwS5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEucSMEucS8AscS4Bs8S5BMwS5xIwS1yuEpD0dUk7Je2QtEHSVEmzJG2TtCd7bK9VWDOrvapLQNJ84KtAV0RcCTQBKyhNT94TEZ1AD+cwXbmZ1V/ey4Fm4BOSmoFpwEFgGbAuW78OWJ7zGGZWoDxTk78JPERp5uEB4EhEPAfMjYiBbJsBYE6l/SWtktQrqXeYoWpjmFlOeS4H2il9118MzAOmS7r7bPePiLUR0RURXS20VRvDzHLKcznwBWBfRByOiGHgKeCzwCFJHQDZ42D+mGZWlDwlsB+4QdI0SQKWAH3AVqA726Yb2JIvopkVqbnaHSPiRUmbgV8AI8B2YC1wHrBJ0kpKRXFnLYKaWTGqLgGAiLgfuP+M4SFKZwVmNgn4E4NmiXMJmCXOJWCWOJeAWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniXAJmiXMJmCXOJWCWOJeAWeJcAmaJcwmYJc4lYJY4l4BZ4lwCZolzCZglziVgljiXgFniXAJmiRu3BCQ9LmlQ0o6ysVmStknakz22l61bI2mvpN2Sbi0quJnVxtmcCTwBLD1jbDXQExGdQE+2jKTLgRXAFdk+35bUVLO0ZlZz45ZARDwPvHPG8DJgXfZ8HbC8bHxjRAxFxD5gL3BdbaKaWRGqvScwNyIGALLHOdn4fOBA2Xb92dhHSFolqVdS7zBDVcYws7xqfWNQFcai0oYRsTYiuiKiq4W2Gscws7NVbQkcktQBkD0OZuP9wMKy7RYAB6uPZ2ZFq7YEtgLd2fNuYEvZ+ApJbZIWA53Az/NFNLMiNY+3gaQNwM3ABZL6gfuBB4FNklYC+4E7ASJip6RNwC5gBLgnIk4VlN3MamDcEoiIu8ZYtWSM7R8AHsgTyszqx58YNEucS8AscS4Bs8S5BMwS5xIwS5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEucSMEucS8AscS4Bs8S5BMwS5xIwS5xLwCxxLgGzxLkEzBLnEjBLnEvALHEuAbPEuQTMEucSMEvcuCUg6XFJg5J2lI39q6RXJf1S0n9Kmlm2bo2kvZJ2S7q1oNxmViNncybwBLD0jLFtwJUR8WngNWANgKTLgRXAFdk+35bUVLO0ZlZz45ZARDwPvHPG2HMRMZItvkBpCnKAZcDGiBiKiH3AXuC6GuY1sxqrxT2BvwX+O3s+HzhQtq4/G/sISask9UrqHWaoBjFsMlJzM02zZ6G2tvwvNqWp9DrS2MdraUXN487Dm5RcJSDpPkpTkK8/PVRhs6i0b0SsjYiuiOhqoQZvAJuUhj93Fe89+Une/ctrc7/WlE9fwnu3X03T7FmV10+bxvtLr2b0+itzH+vjpOoSkNQN3A78dUSc/h+9H1hYttkC4GD18ezjSs3NNF3WycnZzRx8eyYtx0fPaf/mhQtouuIS1NL6+9f8YITmE6NwaozXGh2l6f1TTBkaqbw+UVWdF0laCvwT8OcRcaJs1VbgSUkPA/OATuDnuVPax86U86bz67+6gE8cFn/U/Svi1Klz2v/QrQs50gl//MgRRgbeAuDUrtdo6xOnouLJJ6MnT9Lyw5crn5ombNwSkLQBuBm4QFI/cD+lnwa0AdtUuv56ISL+LiJ2StoE7KJ0mXBPRJzbV9eSMPr+Seb9zwgtx4aJkXP/znziItF88TFoa/3wijEKwMY2bglExF0Vhh/7A9s/ADyQJ5R9/MXQEK3PvFT1/kOzR/nMvDc52jKzdqES5dukNild9L/BzoOXsvDd3Y2OMun5Y8M2KbUeG6XtnRj7JqCdNZeATUrH5jdzpBM01T9ezsuXAzYpte89SevxNuL4Caacfz58aj6/+5OZHF00hUVPHmDkjQPjv4gBPhOwSWrKT7dz/sYXOHX0KFNmfpLf/mk7U7oH+dnfP8T7l8xtdLxJxWcCNumNHn6bC59v4o2L5rPkg68wd/AEmjGDoc900jZwjFO7Xmt0xAnNZwI26Y2ePMnIvjeY8ZtRjrzejk4MQWsL781rZaR9WqPjTXiKCfDhCkmHgePA243OAlyAc5Rzjg+bzDk+FREXnjk4IUoAQFJvRHQ5h3M4R31z+HLALHEuAbPETaQSWNvoABnn+DDn+LCPXY4Jc0/AzBpjIp0JmFkDuATMEjchSkDS0myegr2SVtfxuAsl/VhSn6Sdku7NxmdJ2iZpT/bYXocsTZK2S3q6gRlmStqczSnRJ+nGBuX4evb12CFpg6Sp9coxxjwbYx67qHk26jnfR8NLIJuX4N+ALwGXA3dl8xfUwwjwjYi4DLgBuCc79mqgJyI6gZ5suWj3An1ly43I8C3gmYi4FLgqy1PXHJLmA18FuiLiSqCJ0lwW9crxBB+dZ6PisQueZ6NSjmLm+4iIhv4BbgSeLVteA6xpUJYtwC3AbqAjG+sAdhd83AWU3lyfB57OxuqdYQawj+xmcdl4vXOc/rX1syj925angS/WMwewCNgx3t/Bme9V4FngxqJynLHuy8D6WuRo+JkA5zBXQZEkLQKuAV4E5kbEAED2OKfgwz8CfBMo/w0Z9c5wMXAY+G52WfKopOn1zhERbwIPAfuBAeBIRDxX7xxnGOvYjXzvVjXfRyUToQTOeq6CwgJI5wHfB74WEUfrfOzbgcGIeLmex62gGbgW+E5EXEPp33LU7f7Madn19jJgMaXfWD1d0t31znGWGvLezTPfRyUToQQaOleBpBZKBbA+Ip7Khg9J6sjWdwCDBUa4CbhD0m+AjcDnJX2vzhmg9HXoj4gXs+XNlEqh3jm+AOyLiMMRMQw8BXy2ATnKjXXsur93i5jvYyKUwEtAp6TFklop3eDYWo8Dq/T70h8D+iLi4bJVW4Hu7Hk3pXsFhYiINRGxICIWUfpv/1FE3F3PDFmOt4ADki7JhpZQ+tXxdc1B6TLgBknTsq/PEko3KOudo9xYx94KrJDUJmkxBc+zUTbfxx3x0fk+qs9R5E2ec7gBchulu52/Bu6r43H/jNJp0y+BV7I/twGzKd2o25M9zqpTnpv5/Y3BumcArgZ6s7+P/wLaG5TjX4BXgR3Af1Ca46IuOYANlO5FDFP6DrvyDx0buC973+4GvlRwjr2Urv1Pv1f/vRY5/LFhs8RNhMsBM2sgl4BZ4lwCZolzCZglziVgljiXgFniXAJmifs/u3fybiQdiP4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x,y = next(iter(dl_train))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "ax.imshow(x[0][0])\n",
    "rect = patches.Rectangle((24, 24), 16, 16, linewidth=1, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exotic-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "run_number = 'test'\n",
    "model_name = 'broadleingan'\n",
    "run_folder = '../models/'+model_name+'/' + run_number\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=run_folder)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lined-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | gen  | BroadLeinSAGen  | 4.2 M \n",
      "1 | disc | BroadLeinSADisc | 5.6 M \n",
      "-----------------------------------------\n",
      "9.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 M     Total params\n",
      "39.503    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b164d608ad4ed9859f5968542b1d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developing-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 86319), started 1:30:43 ago. (Use '!kill 86319' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d8e32e7fa0481b46\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d8e32e7fa0481b46\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "warming-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: kill: (86319) - No such process\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-shower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "informational-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(16,128,16,16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "focused-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f33af21f550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ilan/.conda/envs/ilan/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "attn = AxialAttention(\n",
    "                    dim=128,\n",
    "                    dim_index = 1, \n",
    "                    dim_heads = 32, \n",
    "                    heads = 16,\n",
    "                    num_dimensions = 2, \n",
    "                    sum_axial_out=True)\n",
    "\n",
    "vit = ViT(img_dim=16, heads = 16, in_channels=1, \n",
    "          patch_dim=1, num_classes=10,dim=512, blocks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "raising-bench",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 16, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attn(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-colleague",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-baptist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-interim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-place",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-booking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-works",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-perry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "worthy-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxialGenerator(nn.Module):\n",
    "    def __init__(self, noise_shape, channels_img, features_g, num_classes, img_size, embed_size):\n",
    "        super(AxialGenerator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.embed = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=embed_size, kernel_size=3, padding=1), \n",
    "                                   AxialAttention(\n",
    "                                    dim=embed_size,\n",
    "                                    dim_index = 1, \n",
    "                                    dim_heads = 32, \n",
    "                                    heads = 4,\n",
    "                                    num_dimensions = 2, \n",
    "                                    sum_axial_out=True)\n",
    "                                  )\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 16 x 16\n",
    "            self._block(noise_shape[0] + embed_size, features_g * 16, 1, 1, 0),  # img: 16x16\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 32x32\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 64x64\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 4, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 128 x 128\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, labels, x):\n",
    "        embedding  = self.embed(labels)\n",
    "        x = torch.cat([x, embedding], dim = 1)\n",
    "        x = self.net(x)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ancient-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | gen  | AxialGenerator  | 2.7 M \n",
      "1 | disc | DSDiscriminator | 4.0 M \n",
      "-----------------------------------------\n",
      "6.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 M     Total params\n",
      "26.604    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [32:11<?, ?it/s]  1.19s/it, loss=-78.8, v_num=65, discriminator_loss_step=-103., generator_loss_step=80.50] \n",
      "Epoch 1:  92%|█████████▏| 1209/1312 [24:03<02:03,  1.19s/it, loss=-32.4, v_num=65, discriminator_loss_step=-50.9, generator_loss_step=18.80, discriminator_loss_epoch=-74.7, generator_loss_epoch=66.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilan/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 128\n",
    "CHANNELS_IMG = 1\n",
    "NOISE_SHAPE = (1, 16, 16)\n",
    "FEATURES_CRITIC = 32 #64\n",
    "FEATURES_GEN = 32 # 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "NUM_CLASSES = 10\n",
    "GEN_EMBEDDING = 32\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1)\n",
    "model = WGANGP(AxialGenerator, DSDiscriminator, NOISE_SHAPE, CHANNELS_IMG, \n",
    "               FEATURES_GEN, NUM_CLASSES, IMG_SIZE, \n",
    "               GEN_EMBEDDING, FEATURES_CRITIC, lr = LEARNING_RATE)\n",
    "\n",
    "trainer.fit(model, dl_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "comparable-geneva",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type           | Params\n",
      "----------------------------------------\n",
      "0 | gen  | AxialAttention | 262 K \n",
      "----------------------------------------\n",
      "262 K     Trainable params\n",
      "0         Non-trainable params\n",
      "262 K     Total params\n",
      "1.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1312 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "input tensor does not have the correct input dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a9c77f30e3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                             \u001b[0;31m# revert back to previous state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     ) -> None:\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    733\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                             )\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4d8b05eaa520>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4d8b05eaa520>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ilan/lib/python3.9/site-packages/axial_attention/axial_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input tensor does not have the correct number of dimensions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input tensor does not have the correct input dimension'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_axial_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: input tensor does not have the correct input dimension"
     ]
    }
   ],
   "source": [
    "# trainer = pl.Trainer(gpus = 0)\n",
    "# trainer.fit(model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defensive-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(dl_train, open(\"./dataset/trainloader_single_forecast_only.pkl\", \"wb\"))\n",
    "# pickle.dump(dl_valid, open(\"./dataset/validloader_single_forecast_only.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetNetGenerator(nn.Module):\n",
    "    def __init__(self, noise_shape, channels_img, features_g, num_classes, img_size, embed_size):\n",
    "        super(DSGenerator, self).__init__()\n",
    "        self.spatial\n",
    "        self.embed = nn.Conv2d(in_channels=1, out_channels=embed_size, kernel_size=3, padding=1)\n",
    "        self.attention = \n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 16 x 16\n",
    "            self._block(noise_shape[0] + embed_size, features_g * 16, 1, 1, 0),  # img: 16x16\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 32x32\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 64x64\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 4, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 128 x 128\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, labels, x):\n",
    "        embedding  = self.embed(labels)\n",
    "        x = torch.cat([x, embedding], dim = 1)\n",
    "        x = self.net(x)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initializes weights according to the DCGAN paper\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-encounter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilan",
   "language": "python",
   "name": "conda-env-ilan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
